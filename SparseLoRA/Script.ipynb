{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147d36d3-f569-4f31-bd71-311c8332d83f",
   "metadata": {},
   "source": [
    "## Group Project LLM\n",
    "\n",
    "- r=2,4,8,16, epoch=10\n",
    "- seed=42\n",
    "- evaluation:\n",
    "    - accuracy, f1, precision, recall\n",
    "    - efficiency (time, trainable parameters, trainable paramters ratio, convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9402eeb1-9507-4fd7-98ee-f5e80a71de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"default\", module=\"__main__\")\n",
    "warnings.filterwarnings(\"ignore\", module=\".*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de0fe4-12ab-49a1-82bf-76d233877bf9",
   "metadata": {},
   "source": [
    "### Base Model: DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9beb58e-f6ab-4a7f-b213-61f66d3dcc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2836370/2350084452.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: total=66955010, trainable=66955010, ratio=100.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 27:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>0.175075</td>\n",
       "      <td>0.941203</td>\n",
       "      <td>0.945409</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.946976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.178515</td>\n",
       "      <td>0.944024</td>\n",
       "      <td>0.947704</td>\n",
       "      <td>0.952062</td>\n",
       "      <td>0.943386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.206909</td>\n",
       "      <td>0.944172</td>\n",
       "      <td>0.948521</td>\n",
       "      <td>0.940538</td>\n",
       "      <td>0.956642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.221665</td>\n",
       "      <td>0.944469</td>\n",
       "      <td>0.948385</td>\n",
       "      <td>0.947862</td>\n",
       "      <td>0.948909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.239832</td>\n",
       "      <td>0.947587</td>\n",
       "      <td>0.950979</td>\n",
       "      <td>0.956425</td>\n",
       "      <td>0.945595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.305291</td>\n",
       "      <td>0.945805</td>\n",
       "      <td>0.949759</td>\n",
       "      <td>0.946762</td>\n",
       "      <td>0.952775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.310512</td>\n",
       "      <td>0.946102</td>\n",
       "      <td>0.949966</td>\n",
       "      <td>0.948266</td>\n",
       "      <td>0.951671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.368410</td>\n",
       "      <td>0.946102</td>\n",
       "      <td>0.949924</td>\n",
       "      <td>0.949008</td>\n",
       "      <td>0.950842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.406172</td>\n",
       "      <td>0.946845</td>\n",
       "      <td>0.950580</td>\n",
       "      <td>0.950317</td>\n",
       "      <td>0.950842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.424868</td>\n",
       "      <td>0.946993</td>\n",
       "      <td>0.950670</td>\n",
       "      <td>0.951327</td>\n",
       "      <td>0.950014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline training time: 1624.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1055' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 08:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: {'eval_loss': 0.23587322235107422, 'eval_accuracy': 0.9452115812917594, 'eval_f1': 0.9513513513513514, 'eval_precision': 0.9504741833508957, 'eval_recall': 0.952230139878596, 'eval_runtime': 8.7337, 'eval_samples_per_second': 771.149, 'eval_steps_per_second': 24.159, 'epoch': 10.0}\n",
      "Convergence history: [{'loss': 0.2387, 'grad_norm': 10.51264762878418, 'learning_rate': 1.800118764845606e-05, 'epoch': 1.0, 'step': 1684}, {'eval_loss': 0.17507508397102356, 'eval_accuracy': 0.9412026726057906, 'eval_f1': 0.9454094292803971, 'eval_precision': 0.9438480594549958, 'eval_recall': 0.9469759734879868, 'eval_runtime': 9.6709, 'eval_samples_per_second': 696.421, 'eval_steps_per_second': 21.818, 'epoch': 1.0, 'step': 1684}, {'loss': 0.1251, 'grad_norm': 5.240935325622559, 'learning_rate': 1.6001187648456057e-05, 'epoch': 2.0, 'step': 3368}, {'eval_loss': 0.1785149723291397, 'eval_accuracy': 0.9440237564959169, 'eval_f1': 0.9477042585656817, 'eval_precision': 0.9520624303232998, 'eval_recall': 0.9433858050262358, 'eval_runtime': 9.4749, 'eval_samples_per_second': 710.827, 'eval_steps_per_second': 22.269, 'epoch': 2.0, 'step': 3368}, {'loss': 0.0886, 'grad_norm': 11.543757438659668, 'learning_rate': 1.4001187648456058e-05, 'epoch': 3.0, 'step': 5052}, {'eval_loss': 0.2069089114665985, 'eval_accuracy': 0.9441722345953972, 'eval_f1': 0.9485213581599123, 'eval_precision': 0.9405376052131414, 'eval_recall': 0.9566418116542391, 'eval_runtime': 9.5145, 'eval_samples_per_second': 707.863, 'eval_steps_per_second': 22.177, 'epoch': 3.0, 'step': 5052}, {'loss': 0.0615, 'grad_norm': 0.22485654056072235, 'learning_rate': 1.2001187648456058e-05, 'epoch': 4.0, 'step': 6736}, {'eval_loss': 0.22166526317596436, 'eval_accuracy': 0.9444691907943579, 'eval_f1': 0.948385316036434, 'eval_precision': 0.9478620689655173, 'eval_recall': 0.9489091411212373, 'eval_runtime': 9.9979, 'eval_samples_per_second': 673.64, 'eval_steps_per_second': 21.104, 'epoch': 4.0, 'step': 6736}, {'loss': 0.0475, 'grad_norm': 0.09435376524925232, 'learning_rate': 1.0001187648456059e-05, 'epoch': 5.0, 'step': 8420}, {'eval_loss': 0.2398320436477661, 'eval_accuracy': 0.9475872308834447, 'eval_f1': 0.950979030690182, 'eval_precision': 0.9564245810055866, 'eval_recall': 0.9455951394642363, 'eval_runtime': 9.6024, 'eval_samples_per_second': 701.39, 'eval_steps_per_second': 21.974, 'epoch': 5.0, 'step': 8420}, {'loss': 0.0335, 'grad_norm': 0.45556309819221497, 'learning_rate': 8.001187648456058e-06, 'epoch': 6.0, 'step': 10104}, {'eval_loss': 0.3052908778190613, 'eval_accuracy': 0.9458054936896808, 'eval_f1': 0.9497591190640055, 'eval_precision': 0.9467618002195389, 'eval_recall': 0.9527754763877382, 'eval_runtime': 9.7726, 'eval_samples_per_second': 689.169, 'eval_steps_per_second': 21.591, 'epoch': 6.0, 'step': 10104}, {'loss': 0.0275, 'grad_norm': 8.011517524719238, 'learning_rate': 6.001187648456057e-06, 'epoch': 7.0, 'step': 11788}, {'eval_loss': 0.3105123043060303, 'eval_accuracy': 0.9461024498886415, 'eval_f1': 0.9499655410062027, 'eval_precision': 0.9482663731425427, 'eval_recall': 0.9516708091687379, 'eval_runtime': 9.3925, 'eval_samples_per_second': 717.063, 'eval_steps_per_second': 22.465, 'epoch': 7.0, 'step': 11788}, {'loss': 0.0182, 'grad_norm': 6.816328525543213, 'learning_rate': 4.001187648456058e-06, 'epoch': 8.0, 'step': 13472}, {'eval_loss': 0.36840957403182983, 'eval_accuracy': 0.9461024498886415, 'eval_f1': 0.9499241274658573, 'eval_precision': 0.9490077177508269, 'eval_recall': 0.9508423087544877, 'eval_runtime': 9.4225, 'eval_samples_per_second': 714.781, 'eval_steps_per_second': 22.393, 'epoch': 8.0, 'step': 13472}, {'loss': 0.0126, 'grad_norm': 2.9003257751464844, 'learning_rate': 2.001187648456057e-06, 'epoch': 9.0, 'step': 15156}, {'eval_loss': 0.4061717391014099, 'eval_accuracy': 0.9468448403860431, 'eval_f1': 0.9505797901711761, 'eval_precision': 0.9503174165056583, 'eval_recall': 0.9508423087544877, 'eval_runtime': 9.7566, 'eval_samples_per_second': 690.301, 'eval_steps_per_second': 21.626, 'epoch': 9.0, 'step': 15156}, {'loss': 0.0109, 'grad_norm': 0.011784575879573822, 'learning_rate': 1.1876484560570071e-09, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.4248684048652649, 'eval_accuracy': 0.9469933184855234, 'eval_f1': 0.9506701671963521, 'eval_precision': 0.9513274336283186, 'eval_recall': 0.9500138083402375, 'eval_runtime': 9.4631, 'eval_samples_per_second': 711.713, 'eval_steps_per_second': 22.297, 'epoch': 10.0, 'step': 16840}, {'train_runtime': 1624.274, 'train_samples_per_second': 331.711, 'train_steps_per_second': 10.368, 'total_flos': 5586612026141100.0, 'train_loss': 0.06640054981385728, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.23587322235107422, 'eval_accuracy': 0.9452115812917594, 'eval_f1': 0.9513513513513514, 'eval_precision': 0.9504741833508957, 'eval_recall': 0.952230139878596, 'eval_runtime': 8.7337, 'eval_samples_per_second': 771.149, 'eval_steps_per_second': 24.159, 'epoch': 10.0, 'step': 16840}]\n"
     ]
    }
   ],
   "source": [
    "# ================== BASELINE DISTILBERT ================\n",
    "\n",
    "import os, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATASET = \"stanfordnlp/sst2\"\n",
    "TEXT_COL = \"sentence\"\n",
    "LABEL_COL = \"label\"\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-5\n",
    "\n",
    "'''\n",
    "for IMDB dataset:\n",
    "DATASET = \"imdb\"\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"\n",
    "'''\n",
    "\n",
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "set_all_seeds(SEED)\n",
    "\n",
    "# -------- Load dataset and split (8:1:1) --------\n",
    "raw = load_dataset(DATASET)\n",
    "train_full = raw[\"train\"]\n",
    "\n",
    "train_temp = train_full.train_test_split(test_size=0.2, seed=SEED)\n",
    "train_ds = train_temp[\"train\"]\n",
    "temp = train_temp[\"test\"]\n",
    "\n",
    "val_test = temp.train_test_split(test_size=0.5, seed=SEED)\n",
    "val_ds = val_test[\"train\"]\n",
    "test_ds = val_test[\"test\"]\n",
    "\n",
    "\n",
    "# -------- Tokenization --------\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "def preprocess(x):\n",
    "    return tokenizer(x[TEXT_COL], truncation=True, max_length=128)\n",
    "\n",
    "train_ds = train_ds.map(preprocess, batched=True)\n",
    "val_ds   = val_ds.map(preprocess, batched=True)\n",
    "test_ds  = test_ds.map(preprocess, batched=True)\n",
    "\n",
    "train_ds = train_ds.rename_column(LABEL_COL, \"labels\")\n",
    "val_ds   = val_ds.rename_column(LABEL_COL, \"labels\")\n",
    "test_ds  = test_ds.rename_column(LABEL_COL, \"labels\")\n",
    "\n",
    "cols = [\"input_ids\",\"attention_mask\",\"labels\"]\n",
    "train_ds.set_format(type=\"torch\", columns=cols)\n",
    "val_ds.set_format(type=\"torch\", columns=cols)\n",
    "test_ds.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# -------- Metrics --------\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "prec = evaluate.load(\"precision\")\n",
    "rec = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"],\n",
    "        \"precision\": prec.compute(predictions=preds, references=labels, average=\"binary\")[\"precision\"],\n",
    "        \"recall\": rec.compute(predictions=preds, references=labels, average=\"binary\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "# -------- Model --------\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2\n",
    ").to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "ratio = trainable_params / total_params\n",
    "\n",
    "print(f\"Baseline: total={total_params}, trainable={trainable_params}, ratio={ratio:.4%}\")\n",
    "\n",
    "# -------- Train --------\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./baseline_distilbert\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    seed=SEED,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Baseline training time: {end-start:.2f}s\")\n",
    "print(\"Eval:\", trainer.evaluate(test_ds))\n",
    "print(\"Convergence history:\", trainer.state.log_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b955f22-3fde-4792-a715-06f14bc6ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final metrics to baseline_distilbert/final_metrics.json\n",
      "Saved model to baseline_distilbert/final_model\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# -------- Final Evaluation --------\n",
    "final_metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "# -------- Save metrics --------\n",
    "os.makedirs(\"./baseline_distilbert\", exist_ok=True)\n",
    "with open(\"./baseline_distilbert/final_metrics.json\", \"w\") as f:\n",
    "    json.dump(final_metrics, f, indent=4)\n",
    "\n",
    "print(\"Saved final metrics to baseline_distilbert/final_metrics.json\")\n",
    "\n",
    "# -------- Save model --------\n",
    "trainer.save_model(\"./baseline_distilbert/final_model\")\n",
    "print(\"Saved model to baseline_distilbert/final_model\")\n",
    "\n",
    "# -------- Convergence history --------\n",
    "log_history = trainer.state.log_history\n",
    "df_logs = pd.DataFrame(trainer.state.log_history)\n",
    "# Separate clean tables\n",
    "df_train = df_logs[df_logs[\"loss\"].notnull()].reset_index(drop=True)\n",
    "df_eval  = df_logs[df_logs[\"eval_loss\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "df_train.to_csv(\"./baseline_distilbert/train_log.csv\", index=False)\n",
    "df_eval.to_csv(\"./baseline_distilbert/eval_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19b5f110-1f56-40f2-9b8a-d72926786bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_eval_clean = df_eval.groupby(\"epoch\").last().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(df_train[\"epoch\"], df_train[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(df_eval_clean[\"epoch\"], df_eval_clean[\"eval_loss\"], label=\"Eval Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Convergence: Train vs Eval Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"./baseline_distilbert/loss_curve.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(df_eval_clean[\"epoch\"], df_eval_clean[\"eval_accuracy\"], label=\"Eval Accuracy\")\n",
    "plt.plot(df_eval_clean[\"epoch\"], df_eval_clean[\"eval_f1\"], label=\"Eval F1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.title(\"Evaluation: Accuracy & F1\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"./baseline_distilbert/metric_curve.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3c60d-a93c-4673-8988-ff0c91314b0c",
   "metadata": {},
   "source": [
    "### Sparse LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6443518b-f642-46e0-916f-f25e646d6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 2, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 2] total params: 67,620,868\n",
      "[Rank 2] trainable params: 665,858\n",
      "[Rank 2] trainable params ratio (trainable / total): 0.9847%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2836370/731623691.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SparseLoraTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 34:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>0.296121</td>\n",
       "      <td>0.876466</td>\n",
       "      <td>0.882320</td>\n",
       "      <td>0.904320</td>\n",
       "      <td>0.861364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.280038</td>\n",
       "      <td>0.885375</td>\n",
       "      <td>0.892867</td>\n",
       "      <td>0.897350</td>\n",
       "      <td>0.888429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.270784</td>\n",
       "      <td>0.891314</td>\n",
       "      <td>0.898951</td>\n",
       "      <td>0.898703</td>\n",
       "      <td>0.899199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.262972</td>\n",
       "      <td>0.894432</td>\n",
       "      <td>0.900989</td>\n",
       "      <td>0.908708</td>\n",
       "      <td>0.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.261988</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.904422</td>\n",
       "      <td>0.899481</td>\n",
       "      <td>0.909417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.254590</td>\n",
       "      <td>0.897847</td>\n",
       "      <td>0.904205</td>\n",
       "      <td>0.911823</td>\n",
       "      <td>0.896714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.252679</td>\n",
       "      <td>0.899183</td>\n",
       "      <td>0.904995</td>\n",
       "      <td>0.917187</td>\n",
       "      <td>0.893123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.251038</td>\n",
       "      <td>0.899926</td>\n",
       "      <td>0.906957</td>\n",
       "      <td>0.906707</td>\n",
       "      <td>0.907208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>0.250182</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.907231</td>\n",
       "      <td>0.908361</td>\n",
       "      <td>0.906103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.249398</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.906793</td>\n",
       "      <td>0.912241</td>\n",
       "      <td>0.901408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 2] Training time: 2040.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 2] Validation metrics: {'eval_loss': 0.25018182396888733, 'eval_accuracy': 0.9003711952487008, 'eval_f1': 0.9072307479607356, 'eval_precision': 0.9083610188261351, 'eval_recall': 0.9061032863849765, 'eval_runtime': 10.8933, 'eval_samples_per_second': 618.271, 'eval_steps_per_second': 19.37, 'epoch': 10.0}\n",
      "[Rank 2] Test metrics: {'eval_loss': 0.26539742946624756, 'eval_accuracy': 0.8914625092798812, 'eval_f1': 0.9028313172936329, 'eval_precision': 0.9094804499196572, 'eval_recall': 0.8962787015043547, 'eval_runtime': 11.0689, 'eval_samples_per_second': 608.46, 'eval_steps_per_second': 19.062, 'epoch': 10.0}\n",
      "[Rank 2] LoRA sparsity (<1e-3): 15.55%\n",
      "[Rank 2] Convergence log_history:\n",
      "[{'loss': 0.3939, 'grad_norm': 3.0737977027893066, 'learning_rate': 1.800118764845606e-05, 'epoch': 1.0, 'step': 1684}, {'eval_loss': 0.2961207926273346, 'eval_accuracy': 0.8764662212323683, 'eval_f1': 0.8823196605374823, 'eval_precision': 0.9043200927805161, 'eval_recall': 0.8613642640154653, 'eval_runtime': 11.1684, 'eval_samples_per_second': 603.042, 'eval_steps_per_second': 18.893, 'epoch': 1.0, 'step': 1684}, {'loss': 0.316, 'grad_norm': 1.479843258857727, 'learning_rate': 1.6001187648456057e-05, 'epoch': 2.0, 'step': 3368}, {'eval_loss': 0.28003761172294617, 'eval_accuracy': 0.8853749072011878, 'eval_f1': 0.8928670552317514, 'eval_precision': 0.897350069735007, 'eval_recall': 0.8884286108809721, 'eval_runtime': 11.0601, 'eval_samples_per_second': 608.944, 'eval_steps_per_second': 19.078, 'epoch': 2.0, 'step': 3368}, {'loss': 0.3028, 'grad_norm': 1.9990397691726685, 'learning_rate': 1.4001187648456058e-05, 'epoch': 3.0, 'step': 5052}, {'eval_loss': 0.27078408002853394, 'eval_accuracy': 0.8913140311804009, 'eval_f1': 0.8989508558807289, 'eval_precision': 0.8987027325420922, 'eval_recall': 0.8991991162662248, 'eval_runtime': 11.7675, 'eval_samples_per_second': 572.341, 'eval_steps_per_second': 17.931, 'epoch': 3.0, 'step': 5052}, {'loss': 0.2924, 'grad_norm': 3.801942825317383, 'learning_rate': 1.2001187648456058e-05, 'epoch': 4.0, 'step': 6736}, {'eval_loss': 0.26297202706336975, 'eval_accuracy': 0.8944320712694878, 'eval_f1': 0.9009887202339507, 'eval_precision': 0.9087078651685393, 'eval_recall': 0.8933996133664733, 'eval_runtime': 12.6223, 'eval_samples_per_second': 533.581, 'eval_steps_per_second': 16.716, 'epoch': 4.0, 'step': 6736}, {'loss': 0.2859, 'grad_norm': 1.7913497686386108, 'learning_rate': 1.0001187648456059e-05, 'epoch': 5.0, 'step': 8420}, {'eval_loss': 0.26198816299438477, 'eval_accuracy': 0.8966592427616926, 'eval_f1': 0.9044218621257896, 'eval_precision': 0.8994810161158153, 'eval_recall': 0.9094172880419773, 'eval_runtime': 12.471, 'eval_samples_per_second': 540.054, 'eval_steps_per_second': 16.919, 'epoch': 5.0, 'step': 8420}, {'loss': 0.2815, 'grad_norm': 1.631085991859436, 'learning_rate': 8.001187648456058e-06, 'epoch': 6.0, 'step': 10104}, {'eval_loss': 0.25459036231040955, 'eval_accuracy': 0.8978470675575353, 'eval_f1': 0.9042049568365358, 'eval_precision': 0.9118225217635496, 'eval_recall': 0.8967136150234741, 'eval_runtime': 11.6626, 'eval_samples_per_second': 577.485, 'eval_steps_per_second': 18.092, 'epoch': 6.0, 'step': 10104}, {'loss': 0.2779, 'grad_norm': 2.9907469749450684, 'learning_rate': 6.001187648456057e-06, 'epoch': 7.0, 'step': 11788}, {'eval_loss': 0.2526792883872986, 'eval_accuracy': 0.8991833704528582, 'eval_f1': 0.9049951028403526, 'eval_precision': 0.9171866137266024, 'eval_recall': 0.8931234465617233, 'eval_runtime': 11.6393, 'eval_samples_per_second': 578.645, 'eval_steps_per_second': 18.128, 'epoch': 7.0, 'step': 11788}, {'loss': 0.2759, 'grad_norm': 3.077967643737793, 'learning_rate': 4.001187648456058e-06, 'epoch': 8.0, 'step': 13472}, {'eval_loss': 0.2510381042957306, 'eval_accuracy': 0.8999257609502599, 'eval_f1': 0.9069574820541138, 'eval_precision': 0.9067071487717361, 'eval_recall': 0.9072079536039768, 'eval_runtime': 12.0695, 'eval_samples_per_second': 558.018, 'eval_steps_per_second': 17.482, 'epoch': 8.0, 'step': 13472}, {'loss': 0.2727, 'grad_norm': 1.2240530252456665, 'learning_rate': 2.001187648456057e-06, 'epoch': 9.0, 'step': 15156}, {'eval_loss': 0.25018182396888733, 'eval_accuracy': 0.9003711952487008, 'eval_f1': 0.9072307479607356, 'eval_precision': 0.9083610188261351, 'eval_recall': 0.9061032863849765, 'eval_runtime': 12.2437, 'eval_samples_per_second': 550.079, 'eval_steps_per_second': 17.233, 'epoch': 9.0, 'step': 15156}, {'loss': 0.2716, 'grad_norm': 2.7022695541381836, 'learning_rate': 1.1876484560570071e-09, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.24939800798892975, 'eval_accuracy': 0.9003711952487008, 'eval_f1': 0.906792610084734, 'eval_precision': 0.9122414756847401, 'eval_recall': 0.9014084507042254, 'eval_runtime': 11.4602, 'eval_samples_per_second': 587.685, 'eval_steps_per_second': 18.412, 'epoch': 10.0, 'step': 16840}, {'train_runtime': 2040.4051, 'train_samples_per_second': 264.06, 'train_steps_per_second': 8.253, 'total_flos': 5672878557754200.0, 'train_loss': 0.29705528204911114, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.25018182396888733, 'eval_accuracy': 0.9003711952487008, 'eval_f1': 0.9072307479607356, 'eval_precision': 0.9083610188261351, 'eval_recall': 0.9061032863849765, 'eval_runtime': 10.8933, 'eval_samples_per_second': 618.271, 'eval_steps_per_second': 19.37, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.26539742946624756, 'eval_accuracy': 0.8914625092798812, 'eval_f1': 0.9028313172936329, 'eval_precision': 0.9094804499196572, 'eval_recall': 0.8962787015043547, 'eval_runtime': 11.0689, 'eval_samples_per_second': 608.46, 'eval_steps_per_second': 19.062, 'epoch': 10.0, 'step': 16840}]\n",
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 4, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 4] total params: 67,694,596\n",
      "[Rank 4] trainable params: 739,586\n",
      "[Rank 4] trainable params ratio (trainable / total): 1.0925%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2836370/731623691.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SparseLoraTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 33:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386300</td>\n",
       "      <td>0.294177</td>\n",
       "      <td>0.879733</td>\n",
       "      <td>0.885915</td>\n",
       "      <td>0.903995</td>\n",
       "      <td>0.868545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.276367</td>\n",
       "      <td>0.890275</td>\n",
       "      <td>0.897801</td>\n",
       "      <td>0.899169</td>\n",
       "      <td>0.896437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.267596</td>\n",
       "      <td>0.894878</td>\n",
       "      <td>0.902399</td>\n",
       "      <td>0.900908</td>\n",
       "      <td>0.903894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.258988</td>\n",
       "      <td>0.899926</td>\n",
       "      <td>0.905761</td>\n",
       "      <td>0.917304</td>\n",
       "      <td>0.894504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.258202</td>\n",
       "      <td>0.902004</td>\n",
       "      <td>0.909564</td>\n",
       "      <td>0.902638</td>\n",
       "      <td>0.916598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.249693</td>\n",
       "      <td>0.904083</td>\n",
       "      <td>0.910103</td>\n",
       "      <td>0.917251</td>\n",
       "      <td>0.903065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.247551</td>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.911477</td>\n",
       "      <td>0.921774</td>\n",
       "      <td>0.901408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.245857</td>\n",
       "      <td>0.906756</td>\n",
       "      <td>0.913451</td>\n",
       "      <td>0.911692</td>\n",
       "      <td>0.915217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.244966</td>\n",
       "      <td>0.906607</td>\n",
       "      <td>0.913062</td>\n",
       "      <td>0.913946</td>\n",
       "      <td>0.912179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.244083</td>\n",
       "      <td>0.907053</td>\n",
       "      <td>0.913152</td>\n",
       "      <td>0.917480</td>\n",
       "      <td>0.908865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 4] Training time: 2031.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 4] Validation metrics: {'eval_loss': 0.245857372879982, 'eval_accuracy': 0.9067557535263548, 'eval_f1': 0.9134509371554576, 'eval_precision': 0.9116918844566713, 'eval_recall': 0.9152167909417288, 'eval_runtime': 11.4858, 'eval_samples_per_second': 586.376, 'eval_steps_per_second': 18.371, 'epoch': 10.0}\n",
      "[Rank 4] Test metrics: {'eval_loss': 0.2627865672111511, 'eval_accuracy': 0.895025983667409, 'eval_f1': 0.9063948100092678, 'eval_precision': 0.9094048884165781, 'eval_recall': 0.9034045922406968, 'eval_runtime': 11.0578, 'eval_samples_per_second': 609.073, 'eval_steps_per_second': 19.082, 'epoch': 10.0}\n",
      "[Rank 4] LoRA sparsity (<1e-3): 21.52%\n",
      "[Rank 4] Convergence log_history:\n",
      "[{'loss': 0.3863, 'grad_norm': 3.1279044151306152, 'learning_rate': 1.800118764845606e-05, 'epoch': 1.0, 'step': 1684}, {'eval_loss': 0.2941770851612091, 'eval_accuracy': 0.8797327394209354, 'eval_f1': 0.8859154929577465, 'eval_precision': 0.9039954009772924, 'eval_recall': 0.8685446009389671, 'eval_runtime': 11.3424, 'eval_samples_per_second': 593.791, 'eval_steps_per_second': 18.603, 'epoch': 1.0, 'step': 1684}, {'loss': 0.3125, 'grad_norm': 1.6540402173995972, 'learning_rate': 1.6001187648456057e-05, 'epoch': 2.0, 'step': 3368}, {'eval_loss': 0.27636703848838806, 'eval_accuracy': 0.8902746844840386, 'eval_f1': 0.8978011340063615, 'eval_precision': 0.8991689750692521, 'eval_recall': 0.8964374482187241, 'eval_runtime': 11.4461, 'eval_samples_per_second': 588.41, 'eval_steps_per_second': 18.434, 'epoch': 2.0, 'step': 3368}, {'loss': 0.2987, 'grad_norm': 1.5005635023117065, 'learning_rate': 1.4001187648456058e-05, 'epoch': 3.0, 'step': 5052}, {'eval_loss': 0.26759597659111023, 'eval_accuracy': 0.8948775055679288, 'eval_f1': 0.902398676592225, 'eval_precision': 0.9009083402146986, 'eval_recall': 0.903893951946976, 'eval_runtime': 11.6671, 'eval_samples_per_second': 577.264, 'eval_steps_per_second': 18.085, 'epoch': 3.0, 'step': 5052}, {'loss': 0.2876, 'grad_norm': 4.587261199951172, 'learning_rate': 1.2001187648456058e-05, 'epoch': 4.0, 'step': 6736}, {'eval_loss': 0.25898805260658264, 'eval_accuracy': 0.8999257609502599, 'eval_f1': 0.9057606263982103, 'eval_precision': 0.9173038799207024, 'eval_recall': 0.8945042805854736, 'eval_runtime': 11.796, 'eval_samples_per_second': 570.957, 'eval_steps_per_second': 17.887, 'epoch': 4.0, 'step': 6736}, {'loss': 0.2805, 'grad_norm': 1.8961390256881714, 'learning_rate': 1.0001187648456059e-05, 'epoch': 5.0, 'step': 8420}, {'eval_loss': 0.2582024335861206, 'eval_accuracy': 0.9020044543429844, 'eval_f1': 0.9095642641819677, 'eval_precision': 0.902638020125102, 'eval_recall': 0.9165976249654791, 'eval_runtime': 11.2974, 'eval_samples_per_second': 596.155, 'eval_steps_per_second': 18.677, 'epoch': 5.0, 'step': 8420}, {'loss': 0.2754, 'grad_norm': 1.8083791732788086, 'learning_rate': 8.001187648456058e-06, 'epoch': 6.0, 'step': 10104}, {'eval_loss': 0.24969258904457092, 'eval_accuracy': 0.904083147735709, 'eval_f1': 0.9101029780128027, 'eval_precision': 0.9172510518934082, 'eval_recall': 0.9030654515327258, 'eval_runtime': 11.8729, 'eval_samples_per_second': 567.259, 'eval_steps_per_second': 17.772, 'epoch': 6.0, 'step': 10104}, {'loss': 0.2716, 'grad_norm': 3.006859302520752, 'learning_rate': 6.001187648456057e-06, 'epoch': 7.0, 'step': 11788}, {'eval_loss': 0.24755080044269562, 'eval_accuracy': 0.9058648849294729, 'eval_f1': 0.9114772409941357, 'eval_precision': 0.9217735103078226, 'eval_recall': 0.9014084507042254, 'eval_runtime': 11.7975, 'eval_samples_per_second': 570.885, 'eval_steps_per_second': 17.885, 'epoch': 7.0, 'step': 11788}, {'loss': 0.2688, 'grad_norm': 3.449216842651367, 'learning_rate': 4.001187648456058e-06, 'epoch': 8.0, 'step': 13472}, {'eval_loss': 0.245857372879982, 'eval_accuracy': 0.9067557535263548, 'eval_f1': 0.9134509371554576, 'eval_precision': 0.9116918844566713, 'eval_recall': 0.9152167909417288, 'eval_runtime': 11.4212, 'eval_samples_per_second': 589.692, 'eval_steps_per_second': 18.474, 'epoch': 8.0, 'step': 13472}, {'loss': 0.2658, 'grad_norm': 1.5881074666976929, 'learning_rate': 2.001187648456057e-06, 'epoch': 9.0, 'step': 15156}, {'eval_loss': 0.2449660748243332, 'eval_accuracy': 0.9066072754268746, 'eval_f1': 0.9130615065653075, 'eval_precision': 0.913945766463752, 'eval_recall': 0.9121789560894781, 'eval_runtime': 12.0478, 'eval_samples_per_second': 559.024, 'eval_steps_per_second': 17.514, 'epoch': 9.0, 'step': 15156}, {'loss': 0.2651, 'grad_norm': 2.6178510189056396, 'learning_rate': 1.1876484560570071e-09, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.24408331513404846, 'eval_accuracy': 0.9070527097253155, 'eval_f1': 0.9131520532741398, 'eval_precision': 0.9174797881237803, 'eval_recall': 0.9088649544324772, 'eval_runtime': 11.513, 'eval_samples_per_second': 584.993, 'eval_steps_per_second': 18.327, 'epoch': 10.0, 'step': 16840}, {'train_runtime': 2030.95, 'train_samples_per_second': 265.29, 'train_steps_per_second': 8.292, 'total_flos': 5682430532563800.0, 'train_loss': 0.29122069986302607, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.245857372879982, 'eval_accuracy': 0.9067557535263548, 'eval_f1': 0.9134509371554576, 'eval_precision': 0.9116918844566713, 'eval_recall': 0.9152167909417288, 'eval_runtime': 11.4858, 'eval_samples_per_second': 586.376, 'eval_steps_per_second': 18.371, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.2627865672111511, 'eval_accuracy': 0.895025983667409, 'eval_f1': 0.9063948100092678, 'eval_precision': 0.9094048884165781, 'eval_recall': 0.9034045922406968, 'eval_runtime': 11.0578, 'eval_samples_per_second': 609.073, 'eval_steps_per_second': 19.082, 'epoch': 10.0, 'step': 16840}]\n",
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 8, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2836370/731623691.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SparseLoraTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 8] total params: 67,842,052\n",
      "[Rank 8] trainable params: 887,042\n",
      "[Rank 8] trainable params ratio (trainable / total): 1.3075%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 34:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>0.295880</td>\n",
       "      <td>0.884781</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>0.905617</td>\n",
       "      <td>0.877106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.277604</td>\n",
       "      <td>0.894878</td>\n",
       "      <td>0.902237</td>\n",
       "      <td>0.902237</td>\n",
       "      <td>0.902237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.268710</td>\n",
       "      <td>0.897847</td>\n",
       "      <td>0.905546</td>\n",
       "      <td>0.900355</td>\n",
       "      <td>0.910798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>0.259213</td>\n",
       "      <td>0.904826</td>\n",
       "      <td>0.910362</td>\n",
       "      <td>0.922096</td>\n",
       "      <td>0.898923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.259396</td>\n",
       "      <td>0.904380</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.901754</td>\n",
       "      <td>0.922673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.249641</td>\n",
       "      <td>0.908389</td>\n",
       "      <td>0.914222</td>\n",
       "      <td>0.920493</td>\n",
       "      <td>0.908036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.247296</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.928815</td>\n",
       "      <td>0.904446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.245347</td>\n",
       "      <td>0.910171</td>\n",
       "      <td>0.916632</td>\n",
       "      <td>0.914741</td>\n",
       "      <td>0.918531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.244415</td>\n",
       "      <td>0.911210</td>\n",
       "      <td>0.917220</td>\n",
       "      <td>0.919512</td>\n",
       "      <td>0.914941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>0.243555</td>\n",
       "      <td>0.912101</td>\n",
       "      <td>0.917823</td>\n",
       "      <td>0.922690</td>\n",
       "      <td>0.913007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 8] Training time: 2055.44 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 8] Validation metrics: {'eval_loss': 0.24355515837669373, 'eval_accuracy': 0.9121009651076466, 'eval_f1': 0.917823431426985, 'eval_precision': 0.9226904828356126, 'eval_recall': 0.9130074565037283, 'eval_runtime': 11.4322, 'eval_samples_per_second': 589.124, 'eval_steps_per_second': 18.457, 'epoch': 10.0}\n",
      "[Rank 8] Test metrics: {'eval_loss': 0.25989142060279846, 'eval_accuracy': 0.9017074981440237, 'eval_f1': 0.9122015915119364, 'eval_precision': 0.9168221807517996, 'eval_recall': 0.9076273423066772, 'eval_runtime': 11.906, 'eval_samples_per_second': 565.682, 'eval_steps_per_second': 17.722, 'epoch': 10.0}\n",
      "[Rank 8] LoRA sparsity (<1e-3): 27.88%\n",
      "[Rank 8] Convergence log_history:\n",
      "[{'loss': 0.3862, 'grad_norm': 2.9998624324798584, 'learning_rate': 1.800118764845606e-05, 'epoch': 1.0, 'step': 1684}, {'eval_loss': 0.2958800792694092, 'eval_accuracy': 0.8847809948032666, 'eval_f1': 0.8911335578002245, 'eval_precision': 0.9056173367550613, 'eval_recall': 0.8771057718862193, 'eval_runtime': 11.3446, 'eval_samples_per_second': 593.675, 'eval_steps_per_second': 18.599, 'epoch': 1.0, 'step': 1684}, {'loss': 0.3138, 'grad_norm': 1.8658512830734253, 'learning_rate': 1.6001187648456057e-05, 'epoch': 2.0, 'step': 3368}, {'eval_loss': 0.27760350704193115, 'eval_accuracy': 0.8948775055679288, 'eval_f1': 0.9022369511184756, 'eval_precision': 0.9022369511184756, 'eval_recall': 0.9022369511184756, 'eval_runtime': 11.4885, 'eval_samples_per_second': 586.24, 'eval_steps_per_second': 18.366, 'epoch': 2.0, 'step': 3368}, {'loss': 0.2993, 'grad_norm': 1.4917348623275757, 'learning_rate': 1.4001187648456058e-05, 'epoch': 3.0, 'step': 5052}, {'eval_loss': 0.268709659576416, 'eval_accuracy': 0.8978470675575353, 'eval_f1': 0.9055464030752334, 'eval_precision': 0.9003549003549004, 'eval_recall': 0.9107981220657277, 'eval_runtime': 12.9269, 'eval_samples_per_second': 521.007, 'eval_steps_per_second': 16.323, 'epoch': 3.0, 'step': 5052}, {'loss': 0.2878, 'grad_norm': 4.908908843994141, 'learning_rate': 1.2001187648456058e-05, 'epoch': 4.0, 'step': 6736}, {'eval_loss': 0.25921282172203064, 'eval_accuracy': 0.9048255382331106, 'eval_f1': 0.9103621871066984, 'eval_precision': 0.9220963172804533, 'eval_recall': 0.8989229494614748, 'eval_runtime': 11.5367, 'eval_samples_per_second': 583.789, 'eval_steps_per_second': 18.289, 'epoch': 4.0, 'step': 6736}, {'loss': 0.2802, 'grad_norm': 2.5097811222076416, 'learning_rate': 1.0001187648456059e-05, 'epoch': 5.0, 'step': 8420}, {'eval_loss': 0.25939592719078064, 'eval_accuracy': 0.9043801039346696, 'eval_f1': 0.9120939120939121, 'eval_precision': 0.9017543859649123, 'eval_recall': 0.9226732946699807, 'eval_runtime': 12.1457, 'eval_samples_per_second': 554.515, 'eval_steps_per_second': 17.372, 'epoch': 5.0, 'step': 8420}, {'loss': 0.2737, 'grad_norm': 2.011146068572998, 'learning_rate': 8.001187648456058e-06, 'epoch': 6.0, 'step': 10104}, {'eval_loss': 0.2496410608291626, 'eval_accuracy': 0.9083890126206384, 'eval_f1': 0.914222160433755, 'eval_precision': 0.9204927211646137, 'eval_recall': 0.908036454018227, 'eval_runtime': 11.4293, 'eval_samples_per_second': 589.274, 'eval_steps_per_second': 18.461, 'epoch': 6.0, 'step': 10104}, {'loss': 0.2696, 'grad_norm': 3.028676748275757, 'learning_rate': 6.001187648456057e-06, 'epoch': 7.0, 'step': 11788}, {'eval_loss': 0.24729610979557037, 'eval_accuracy': 0.9113585746102449, 'eval_f1': 0.916468448299986, 'eval_precision': 0.9288145207033466, 'eval_recall': 0.9044462855564761, 'eval_runtime': 12.4119, 'eval_samples_per_second': 542.626, 'eval_steps_per_second': 17.0, 'epoch': 7.0, 'step': 11788}, {'loss': 0.2667, 'grad_norm': 3.6933021545410156, 'learning_rate': 4.001187648456058e-06, 'epoch': 8.0, 'step': 13472}, {'eval_loss': 0.24534666538238525, 'eval_accuracy': 0.9101707498144024, 'eval_f1': 0.9166322171696293, 'eval_precision': 0.9147414741474147, 'eval_recall': 0.9185307925987296, 'eval_runtime': 11.6864, 'eval_samples_per_second': 576.312, 'eval_steps_per_second': 18.055, 'epoch': 8.0, 'step': 13472}, {'loss': 0.2635, 'grad_norm': 1.674749732017517, 'learning_rate': 2.001187648456057e-06, 'epoch': 9.0, 'step': 15156}, {'eval_loss': 0.24441498517990112, 'eval_accuracy': 0.9112100965107647, 'eval_f1': 0.917220376522702, 'eval_precision': 0.919511518179295, 'eval_recall': 0.9149406241369787, 'eval_runtime': 11.3226, 'eval_samples_per_second': 594.826, 'eval_steps_per_second': 18.635, 'epoch': 9.0, 'step': 15156}, {'loss': 0.2627, 'grad_norm': 2.0971415042877197, 'learning_rate': 1.1876484560570071e-09, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.24355515837669373, 'eval_accuracy': 0.9121009651076466, 'eval_f1': 0.917823431426985, 'eval_precision': 0.9226904828356126, 'eval_recall': 0.9130074565037283, 'eval_runtime': 12.0692, 'eval_samples_per_second': 558.032, 'eval_steps_per_second': 17.483, 'epoch': 10.0, 'step': 16840}, {'train_runtime': 2055.0752, 'train_samples_per_second': 262.175, 'train_steps_per_second': 8.194, 'total_flos': 5701534482183000.0, 'train_loss': 0.290355515649936, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.24355515837669373, 'eval_accuracy': 0.9121009651076466, 'eval_f1': 0.917823431426985, 'eval_precision': 0.9226904828356126, 'eval_recall': 0.9130074565037283, 'eval_runtime': 11.4322, 'eval_samples_per_second': 589.124, 'eval_steps_per_second': 18.457, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.25989142060279846, 'eval_accuracy': 0.9017074981440237, 'eval_f1': 0.9122015915119364, 'eval_precision': 0.9168221807517996, 'eval_recall': 0.9076273423066772, 'eval_runtime': 11.906, 'eval_samples_per_second': 565.682, 'eval_steps_per_second': 17.722, 'epoch': 10.0, 'step': 16840}]\n",
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 16, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2836370/731623691.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SparseLoraTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 16] total params: 68,136,964\n",
      "[Rank 16] trainable params: 1,181,954\n",
      "[Rank 16] trainable params ratio (trainable / total): 1.7347%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 33:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.309513</td>\n",
       "      <td>0.889087</td>\n",
       "      <td>0.895363</td>\n",
       "      <td>0.908471</td>\n",
       "      <td>0.882629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.288913</td>\n",
       "      <td>0.897996</td>\n",
       "      <td>0.905228</td>\n",
       "      <td>0.904355</td>\n",
       "      <td>0.906103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.277806</td>\n",
       "      <td>0.905419</td>\n",
       "      <td>0.912368</td>\n",
       "      <td>0.908991</td>\n",
       "      <td>0.915769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.267853</td>\n",
       "      <td>0.910022</td>\n",
       "      <td>0.914864</td>\n",
       "      <td>0.931084</td>\n",
       "      <td>0.899199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.267210</td>\n",
       "      <td>0.910022</td>\n",
       "      <td>0.916872</td>\n",
       "      <td>0.910875</td>\n",
       "      <td>0.922949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.257248</td>\n",
       "      <td>0.913289</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.925947</td>\n",
       "      <td>0.911627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.254617</td>\n",
       "      <td>0.915516</td>\n",
       "      <td>0.920319</td>\n",
       "      <td>0.933523</td>\n",
       "      <td>0.907484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.252295</td>\n",
       "      <td>0.915071</td>\n",
       "      <td>0.920885</td>\n",
       "      <td>0.922416</td>\n",
       "      <td>0.919359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.251517</td>\n",
       "      <td>0.917001</td>\n",
       "      <td>0.922393</td>\n",
       "      <td>0.927415</td>\n",
       "      <td>0.917426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.250823</td>\n",
       "      <td>0.916852</td>\n",
       "      <td>0.922092</td>\n",
       "      <td>0.929072</td>\n",
       "      <td>0.915217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 16] Training time: 2037.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/yizhanglab/yh151/miniconda3/envs/my-conda-env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 16] Validation metrics: {'eval_loss': 0.25151702761650085, 'eval_accuracy': 0.9170007423904974, 'eval_f1': 0.9223934471747883, 'eval_precision': 0.9274148520379676, 'eval_recall': 0.9174261253797293, 'eval_runtime': 11.2976, 'eval_samples_per_second': 596.147, 'eval_steps_per_second': 18.677, 'epoch': 10.0}\n",
      "[Rank 16] Test metrics: {'eval_loss': 0.2650555968284607, 'eval_accuracy': 0.9097253155159614, 'eval_f1': 0.9195128408790045, 'eval_precision': 0.9224435590969455, 'eval_recall': 0.9166006861968857, 'eval_runtime': 12.1809, 'eval_samples_per_second': 552.916, 'eval_steps_per_second': 17.322, 'epoch': 10.0}\n",
      "[Rank 16] LoRA sparsity (<1e-3): 35.68%\n",
      "[Rank 16] Convergence log_history:\n",
      "[{'loss': 0.3971, 'grad_norm': 3.299694776535034, 'learning_rate': 1.800118764845606e-05, 'epoch': 1.0, 'step': 1684}, {'eval_loss': 0.3095133304595947, 'eval_accuracy': 0.889086859688196, 'eval_f1': 0.8953634962879955, 'eval_precision': 0.908470722001137, 'eval_recall': 0.8826291079812206, 'eval_runtime': 11.8989, 'eval_samples_per_second': 566.018, 'eval_steps_per_second': 17.733, 'epoch': 1.0, 'step': 1684}, {'loss': 0.3246, 'grad_norm': 2.1254234313964844, 'learning_rate': 1.6001187648456057e-05, 'epoch': 2.0, 'step': 3368}, {'eval_loss': 0.28891271352767944, 'eval_accuracy': 0.8979955456570156, 'eval_f1': 0.9052283073527383, 'eval_precision': 0.9043550165380375, 'eval_recall': 0.9061032863849765, 'eval_runtime': 11.686, 'eval_samples_per_second': 576.329, 'eval_steps_per_second': 18.056, 'epoch': 2.0, 'step': 3368}, {'loss': 0.3073, 'grad_norm': 1.5638595819473267, 'learning_rate': 1.4001187648456058e-05, 'epoch': 3.0, 'step': 5052}, {'eval_loss': 0.2778060734272003, 'eval_accuracy': 0.9054194506310319, 'eval_f1': 0.9123675883890494, 'eval_precision': 0.9089912280701754, 'eval_recall': 0.9157691245512289, 'eval_runtime': 11.6003, 'eval_samples_per_second': 580.589, 'eval_steps_per_second': 18.189, 'epoch': 3.0, 'step': 5052}, {'loss': 0.2943, 'grad_norm': 5.23865270614624, 'learning_rate': 1.2001187648456058e-05, 'epoch': 4.0, 'step': 6736}, {'eval_loss': 0.2678532004356384, 'eval_accuracy': 0.910022271714922, 'eval_f1': 0.9148637257656645, 'eval_precision': 0.9310837861023734, 'eval_recall': 0.8991991162662248, 'eval_runtime': 11.9067, 'eval_samples_per_second': 565.646, 'eval_steps_per_second': 17.721, 'epoch': 4.0, 'step': 6736}, {'loss': 0.2848, 'grad_norm': 3.4130496978759766, 'learning_rate': 1.0001187648456059e-05, 'epoch': 5.0, 'step': 8420}, {'eval_loss': 0.267210453748703, 'eval_accuracy': 0.910022271714922, 'eval_f1': 0.9168724279835391, 'eval_precision': 0.910874897792314, 'eval_recall': 0.9229494614747308, 'eval_runtime': 12.0494, 'eval_samples_per_second': 558.951, 'eval_steps_per_second': 17.511, 'epoch': 5.0, 'step': 8420}, {'loss': 0.2775, 'grad_norm': 2.2386434078216553, 'learning_rate': 8.001187648456058e-06, 'epoch': 6.0, 'step': 10104}, {'eval_loss': 0.2572481632232666, 'eval_accuracy': 0.9132887899034893, 'eval_f1': 0.9187308655719455, 'eval_precision': 0.9259467040673212, 'eval_recall': 0.9116266224799779, 'eval_runtime': 12.0053, 'eval_samples_per_second': 561.001, 'eval_steps_per_second': 17.576, 'epoch': 6.0, 'step': 10104}, {'loss': 0.2723, 'grad_norm': 2.5065760612487793, 'learning_rate': 6.001187648456057e-06, 'epoch': 7.0, 'step': 11788}, {'eval_loss': 0.2546166479587555, 'eval_accuracy': 0.9155159613956941, 'eval_f1': 0.9203192830135836, 'eval_precision': 0.9335227272727272, 'eval_recall': 0.9074841204087268, 'eval_runtime': 11.6744, 'eval_samples_per_second': 576.901, 'eval_steps_per_second': 18.074, 'epoch': 7.0, 'step': 11788}, {'loss': 0.2687, 'grad_norm': 3.593709945678711, 'learning_rate': 4.001187648456058e-06, 'epoch': 8.0, 'step': 13472}, {'eval_loss': 0.25229528546333313, 'eval_accuracy': 0.9150705270972531, 'eval_f1': 0.9208852005532503, 'eval_precision': 0.9224161817678027, 'eval_recall': 0.9193592930129798, 'eval_runtime': 11.7728, 'eval_samples_per_second': 572.083, 'eval_steps_per_second': 17.923, 'epoch': 8.0, 'step': 13472}, {'loss': 0.2655, 'grad_norm': 2.035546064376831, 'learning_rate': 2.001187648456057e-06, 'epoch': 9.0, 'step': 15156}, {'eval_loss': 0.25151702761650085, 'eval_accuracy': 0.9170007423904974, 'eval_f1': 0.9223934471747883, 'eval_precision': 0.9274148520379676, 'eval_recall': 0.9174261253797293, 'eval_runtime': 11.6479, 'eval_samples_per_second': 578.218, 'eval_steps_per_second': 18.115, 'epoch': 9.0, 'step': 15156}, {'loss': 0.2635, 'grad_norm': 2.518160581588745, 'learning_rate': 1.1876484560570071e-09, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.25082287192344666, 'eval_accuracy': 0.9168522642910171, 'eval_f1': 0.9220923761825265, 'eval_precision': 0.929072049341183, 'eval_recall': 0.9152167909417288, 'eval_runtime': 11.5215, 'eval_samples_per_second': 584.56, 'eval_steps_per_second': 18.314, 'epoch': 10.0, 'step': 16840}, {'train_runtime': 2036.7204, 'train_samples_per_second': 264.538, 'train_steps_per_second': 8.268, 'total_flos': 5739742381421400.0, 'train_loss': 0.2955606945336856, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.25151702761650085, 'eval_accuracy': 0.9170007423904974, 'eval_f1': 0.9223934471747883, 'eval_precision': 0.9274148520379676, 'eval_recall': 0.9174261253797293, 'eval_runtime': 11.2976, 'eval_samples_per_second': 596.147, 'eval_steps_per_second': 18.677, 'epoch': 10.0, 'step': 16840}, {'eval_loss': 0.2650555968284607, 'eval_accuracy': 0.9097253155159614, 'eval_f1': 0.9195128408790045, 'eval_precision': 0.9224435590969455, 'eval_recall': 0.9166006861968857, 'eval_runtime': 12.1809, 'eval_samples_per_second': 552.916, 'eval_steps_per_second': 17.322, 'epoch': 10.0, 'step': 16840}]\n",
      "\n",
      "\n",
      "=== Summary over ranks (Sparse LoRA) ===\n",
      "\n",
      "Rank 2:\n",
      "  Params: 665,858 / 67,620,868 (0.98%)\n",
      "  Train time: 2040.75 s\n",
      "  Val F1:  0.9072, Acc: 0.9004\n",
      "  Test F1: 0.9028, Acc: 0.8915\n",
      "  LoRA sparsity (<1e-3): 15.55%\n",
      "\n",
      "Rank 4:\n",
      "  Params: 739,586 / 67,694,596 (1.09%)\n",
      "  Train time: 2031.34 s\n",
      "  Val F1:  0.9135, Acc: 0.9068\n",
      "  Test F1: 0.9064, Acc: 0.8950\n",
      "  LoRA sparsity (<1e-3): 21.52%\n",
      "\n",
      "Rank 8:\n",
      "  Params: 887,042 / 67,842,052 (1.31%)\n",
      "  Train time: 2055.44 s\n",
      "  Val F1:  0.9178, Acc: 0.9121\n",
      "  Test F1: 0.9122, Acc: 0.9017\n",
      "  LoRA sparsity (<1e-3): 27.88%\n",
      "\n",
      "Rank 16:\n",
      "  Params: 1,181,954 / 68,136,964 (1.73%)\n",
      "  Train time: 2037.07 s\n",
      "  Val F1:  0.9224, Acc: 0.9170\n",
      "  Test F1: 0.9195, Acc: 0.9097\n",
      "  LoRA sparsity (<1e-3): 35.68%\n"
     ]
    }
   ],
   "source": [
    "# ================== SPARSE LoRA MODEL =================\n",
    "\n",
    "from typing import Dict, Any, List, Optional\n",
    "import math\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# -------- Sparse LoRA config --------\n",
    "RANKS: List[int] = [2, 4, 8, 16]\n",
    "L1_LAMBDA = 1e-5   # sparsity strength for LoRA weights\n",
    "\n",
    "\n",
    "def count_trainable_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def count_total_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def compute_lora_sparsity(model: torch.nn.Module, threshold: float = 1e-3) -> float:\n",
    "    \"\"\"\n",
    "    Approximate sparsity: fraction of LoRA parameters with |w| < threshold.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    near_zero = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"lora_\" in name and param.requires_grad:\n",
    "            data = param.detach().abs()\n",
    "            total += data.numel()\n",
    "            near_zero += (data < threshold).sum().item()\n",
    "    return near_zero / total if total > 0 else math.nan\n",
    "\n",
    "\n",
    "class SparseLoraTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Trainer with L1 penalty only on LoRA parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, l1_lambda: float = 0.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.l1_lambda = l1_lambda\n",
    "\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        model,\n",
    "        inputs,\n",
    "        return_outputs: bool = False,\n",
    "        num_items_in_batch: Optional[int] = None,  # NEW ARG\n",
    "    ):\n",
    "        # standard HF behavior\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # add L1 penalty on LoRA weights\n",
    "        if self.l1_lambda > 0:\n",
    "            l1_reg = 0.0\n",
    "            for name, param in model.named_parameters():\n",
    "                if \"lora_\" in name and param.requires_grad:\n",
    "                    l1_reg = l1_reg + param.abs().sum()\n",
    "            loss = loss + self.l1_lambda * l1_reg\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "results_per_rank: List[Dict[str, Any]] = []\n",
    "\n",
    "\n",
    "for r in RANKS:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Training Sparse LoRA DistilBERT with rank = {r}, epochs = {NUM_EPOCHS}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    set_all_seeds(SEED)\n",
    "\n",
    "    # Base DistilBERT for this rank\n",
    "    base_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=2,\n",
    "    )\n",
    "\n",
    "    # LoRA config: attention projections in DistilBERT\n",
    "    lora_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=2 * r,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\",    # sequence classification\n",
    "        target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"],\n",
    "    )\n",
    "\n",
    "    lora_model = get_peft_model(base_model, lora_config)\n",
    "    lora_model.to(DEVICE)\n",
    "\n",
    "    total_params = count_total_params(lora_model)\n",
    "    trainable_params = count_trainable_params(lora_model)\n",
    "    param_ratio = trainable_params / total_params\n",
    "\n",
    "    print(f\"[Rank {r}] total params: {total_params:,}\")\n",
    "    print(f\"[Rank {r}] trainable params: {trainable_params:,}\")\n",
    "    print(f\"[Rank {r}] trainable params ratio (trainable / total): {param_ratio:.4%}\")\n",
    "\n",
    "    training_args_lora = TrainingArguments(\n",
    "        output_dir=f\"./sparse_lora_rank{r}\",\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        learning_rate=LR,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        seed=SEED,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = SparseLoraTrainer(\n",
    "        l1_lambda=L1_LAMBDA,\n",
    "        model=lora_model,\n",
    "        args=training_args_lora,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_output = trainer.train()\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    print(f\"[Rank {r}] Training time: {train_time:.2f} seconds\")\n",
    "\n",
    "    val_metrics = trainer.evaluate(eval_dataset=val_ds)\n",
    "    test_metrics = trainer.evaluate(eval_dataset=test_ds)\n",
    "\n",
    "    lora_sparsity = compute_lora_sparsity(lora_model, threshold=1e-3)\n",
    "    print(f\"[Rank {r}] Validation metrics: {val_metrics}\")\n",
    "    print(f\"[Rank {r}] Test metrics: {test_metrics}\")\n",
    "    print(f\"[Rank {r}] LoRA sparsity (<1e-3): {lora_sparsity:.2%}\")\n",
    "    print(f\"[Rank {r}] Convergence log_history:\")\n",
    "    print(trainer.state.log_history)\n",
    "\n",
    "    results_per_rank.append(\n",
    "        {\n",
    "            \"rank\": r,\n",
    "            \"total_params\": total_params,\n",
    "            \"trainable_params\": trainable_params,\n",
    "            \"param_ratio\": param_ratio,\n",
    "            \"train_time_sec\": train_time,\n",
    "            \"val_metrics\": val_metrics,\n",
    "            \"test_metrics\": test_metrics,\n",
    "            \"lora_sparsity(<1e-3)\": lora_sparsity,\n",
    "            \"log_history\": trainer.state.log_history,  # convergence\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n=== Summary over ranks (Sparse LoRA) ===\")\n",
    "for res in results_per_rank:\n",
    "    r = res[\"rank\"]\n",
    "    print(f\"\\nRank {r}:\")\n",
    "    print(f\"  Params: {res['trainable_params']:,} / {res['total_params']:,} \"\n",
    "          f\"({res['param_ratio']:.2%})\")\n",
    "    print(f\"  Train time: {res['train_time_sec']:.2f} s\")\n",
    "    print(f\"  Val F1:  {res['val_metrics'].get('eval_f1', float('nan')):.4f}, \"\n",
    "          f\"Acc: {res['val_metrics'].get('eval_accuracy', float('nan')):.4f}\")\n",
    "    print(f\"  Test F1: {res['test_metrics'].get('eval_f1', float('nan')):.4f}, \"\n",
    "          f\"Acc: {res['test_metrics'].get('eval_accuracy', float('nan')):.4f}\")\n",
    "    print(f\"  LoRA sparsity (<1e-3): {res['lora_sparsity(<1e-3)']:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b148015-5dab-49fd-af46-4a0061408da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 2, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 2] total params: 67,620,868\n",
      "[Rank 2] trainable params: 665,858\n",
      "[Rank 2] trainable params ratio (trainable / total): 0.9847%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 33:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>0.296121</td>\n",
       "      <td>0.876466</td>\n",
       "      <td>0.882320</td>\n",
       "      <td>0.904320</td>\n",
       "      <td>0.861364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.280038</td>\n",
       "      <td>0.885375</td>\n",
       "      <td>0.892867</td>\n",
       "      <td>0.897350</td>\n",
       "      <td>0.888429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.270784</td>\n",
       "      <td>0.891314</td>\n",
       "      <td>0.898951</td>\n",
       "      <td>0.898703</td>\n",
       "      <td>0.899199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.262972</td>\n",
       "      <td>0.894432</td>\n",
       "      <td>0.900989</td>\n",
       "      <td>0.908708</td>\n",
       "      <td>0.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.261988</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.904422</td>\n",
       "      <td>0.899481</td>\n",
       "      <td>0.909417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.254590</td>\n",
       "      <td>0.897847</td>\n",
       "      <td>0.904205</td>\n",
       "      <td>0.911823</td>\n",
       "      <td>0.896714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.252679</td>\n",
       "      <td>0.899183</td>\n",
       "      <td>0.904995</td>\n",
       "      <td>0.917187</td>\n",
       "      <td>0.893123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.251038</td>\n",
       "      <td>0.899926</td>\n",
       "      <td>0.906957</td>\n",
       "      <td>0.906707</td>\n",
       "      <td>0.907208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.272700</td>\n",
       "      <td>0.250182</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.907231</td>\n",
       "      <td>0.908361</td>\n",
       "      <td>0.906103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.249398</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.906793</td>\n",
       "      <td>0.912241</td>\n",
       "      <td>0.901408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 2] Training time: 2000.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 2] Validation metrics: {'eval_loss': 0.25018182396888733, 'eval_accuracy': 0.9003711952487008, 'eval_f1': 0.9072307479607356, 'eval_precision': 0.9083610188261351, 'eval_recall': 0.9061032863849765, 'eval_runtime': 11.2932, 'eval_samples_per_second': 596.375, 'eval_steps_per_second': 18.684, 'epoch': 10.0}\n",
      "[Rank 2] Test metrics: {'eval_loss': 0.26539742946624756, 'eval_accuracy': 0.8914625092798812, 'eval_f1': 0.9028313172936329, 'eval_precision': 0.9094804499196572, 'eval_recall': 0.8962787015043547, 'eval_runtime': 10.8577, 'eval_samples_per_second': 620.299, 'eval_steps_per_second': 19.433, 'epoch': 10.0}\n",
      "[Rank 2] LoRA sparsity (<1e-3): 15.55%\n",
      "[Rank 2] Saved model to ./sparse_lora_rank2/final_model\n",
      "[Rank 2] Saved log history to log_history.json\n",
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 4, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 4] total params: 67,694,596\n",
      "[Rank 4] trainable params: 739,586\n",
      "[Rank 4] trainable params ratio (trainable / total): 1.0925%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 34:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386300</td>\n",
       "      <td>0.294177</td>\n",
       "      <td>0.879733</td>\n",
       "      <td>0.885915</td>\n",
       "      <td>0.903995</td>\n",
       "      <td>0.868545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.276367</td>\n",
       "      <td>0.890275</td>\n",
       "      <td>0.897801</td>\n",
       "      <td>0.899169</td>\n",
       "      <td>0.896437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.267596</td>\n",
       "      <td>0.894878</td>\n",
       "      <td>0.902399</td>\n",
       "      <td>0.900908</td>\n",
       "      <td>0.903894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.258988</td>\n",
       "      <td>0.899926</td>\n",
       "      <td>0.905761</td>\n",
       "      <td>0.917304</td>\n",
       "      <td>0.894504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.258202</td>\n",
       "      <td>0.902004</td>\n",
       "      <td>0.909564</td>\n",
       "      <td>0.902638</td>\n",
       "      <td>0.916598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.249693</td>\n",
       "      <td>0.904083</td>\n",
       "      <td>0.910103</td>\n",
       "      <td>0.917251</td>\n",
       "      <td>0.903065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.247551</td>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.911477</td>\n",
       "      <td>0.921774</td>\n",
       "      <td>0.901408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.245857</td>\n",
       "      <td>0.906756</td>\n",
       "      <td>0.913451</td>\n",
       "      <td>0.911692</td>\n",
       "      <td>0.915217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.244966</td>\n",
       "      <td>0.906607</td>\n",
       "      <td>0.913062</td>\n",
       "      <td>0.913946</td>\n",
       "      <td>0.912179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.244083</td>\n",
       "      <td>0.907053</td>\n",
       "      <td>0.913152</td>\n",
       "      <td>0.917480</td>\n",
       "      <td>0.908865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 4] Training time: 2051.59 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 4] Validation metrics: {'eval_loss': 0.245857372879982, 'eval_accuracy': 0.9067557535263548, 'eval_f1': 0.9134509371554576, 'eval_precision': 0.9116918844566713, 'eval_recall': 0.9152167909417288, 'eval_runtime': 11.4603, 'eval_samples_per_second': 587.683, 'eval_steps_per_second': 18.411, 'epoch': 10.0}\n",
      "[Rank 4] Test metrics: {'eval_loss': 0.2627865672111511, 'eval_accuracy': 0.895025983667409, 'eval_f1': 0.9063948100092678, 'eval_precision': 0.9094048884165781, 'eval_recall': 0.9034045922406968, 'eval_runtime': 11.9928, 'eval_samples_per_second': 561.588, 'eval_steps_per_second': 17.594, 'epoch': 10.0}\n",
      "[Rank 4] LoRA sparsity (<1e-3): 21.52%\n",
      "[Rank 4] Saved model to ./sparse_lora_rank4/final_model\n",
      "[Rank 4] Saved log history to log_history.json\n",
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 8, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 8] total params: 67,842,052\n",
      "[Rank 8] trainable params: 887,042\n",
      "[Rank 8] trainable params ratio (trainable / total): 1.3075%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 33:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>0.295880</td>\n",
       "      <td>0.884781</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>0.905617</td>\n",
       "      <td>0.877106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.277604</td>\n",
       "      <td>0.894878</td>\n",
       "      <td>0.902237</td>\n",
       "      <td>0.902237</td>\n",
       "      <td>0.902237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.268710</td>\n",
       "      <td>0.897847</td>\n",
       "      <td>0.905546</td>\n",
       "      <td>0.900355</td>\n",
       "      <td>0.910798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>0.259213</td>\n",
       "      <td>0.904826</td>\n",
       "      <td>0.910362</td>\n",
       "      <td>0.922096</td>\n",
       "      <td>0.898923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.259396</td>\n",
       "      <td>0.904380</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.901754</td>\n",
       "      <td>0.922673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.249641</td>\n",
       "      <td>0.908389</td>\n",
       "      <td>0.914222</td>\n",
       "      <td>0.920493</td>\n",
       "      <td>0.908036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.247296</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.928815</td>\n",
       "      <td>0.904446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.245347</td>\n",
       "      <td>0.910171</td>\n",
       "      <td>0.916632</td>\n",
       "      <td>0.914741</td>\n",
       "      <td>0.918531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.244415</td>\n",
       "      <td>0.911210</td>\n",
       "      <td>0.917220</td>\n",
       "      <td>0.919512</td>\n",
       "      <td>0.914941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>0.243555</td>\n",
       "      <td>0.912101</td>\n",
       "      <td>0.917823</td>\n",
       "      <td>0.922690</td>\n",
       "      <td>0.913007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 8] Training time: 2036.44 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 8] Validation metrics: {'eval_loss': 0.24355515837669373, 'eval_accuracy': 0.9121009651076466, 'eval_f1': 0.917823431426985, 'eval_precision': 0.9226904828356126, 'eval_recall': 0.9130074565037283, 'eval_runtime': 11.7129, 'eval_samples_per_second': 575.007, 'eval_steps_per_second': 18.014, 'epoch': 10.0}\n",
      "[Rank 8] Test metrics: {'eval_loss': 0.25989142060279846, 'eval_accuracy': 0.9017074981440237, 'eval_f1': 0.9122015915119364, 'eval_precision': 0.9168221807517996, 'eval_recall': 0.9076273423066772, 'eval_runtime': 11.2317, 'eval_samples_per_second': 599.641, 'eval_steps_per_second': 18.786, 'epoch': 10.0}\n",
      "[Rank 8] LoRA sparsity (<1e-3): 27.88%\n",
      "[Rank 8] Saved model to ./sparse_lora_rank8/final_model\n",
      "[Rank 8] Saved log history to log_history.json\n",
      "\n",
      "================================================================================\n",
      "Training Sparse LoRA DistilBERT with rank = 16, epochs = 10\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 16] total params: 68,136,964\n",
      "[Rank 16] trainable params: 1,181,954\n",
      "[Rank 16] trainable params ratio (trainable / total): 1.7347%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16840/16840 33:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.309513</td>\n",
       "      <td>0.889087</td>\n",
       "      <td>0.895363</td>\n",
       "      <td>0.908471</td>\n",
       "      <td>0.882629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.288913</td>\n",
       "      <td>0.897996</td>\n",
       "      <td>0.905228</td>\n",
       "      <td>0.904355</td>\n",
       "      <td>0.906103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.277806</td>\n",
       "      <td>0.905419</td>\n",
       "      <td>0.912368</td>\n",
       "      <td>0.908991</td>\n",
       "      <td>0.915769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.267853</td>\n",
       "      <td>0.910022</td>\n",
       "      <td>0.914864</td>\n",
       "      <td>0.931084</td>\n",
       "      <td>0.899199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.267210</td>\n",
       "      <td>0.910022</td>\n",
       "      <td>0.916872</td>\n",
       "      <td>0.910875</td>\n",
       "      <td>0.922949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.257248</td>\n",
       "      <td>0.913289</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.925947</td>\n",
       "      <td>0.911627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.254617</td>\n",
       "      <td>0.915516</td>\n",
       "      <td>0.920319</td>\n",
       "      <td>0.933523</td>\n",
       "      <td>0.907484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.252295</td>\n",
       "      <td>0.915071</td>\n",
       "      <td>0.920885</td>\n",
       "      <td>0.922416</td>\n",
       "      <td>0.919359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.251517</td>\n",
       "      <td>0.917001</td>\n",
       "      <td>0.922393</td>\n",
       "      <td>0.927415</td>\n",
       "      <td>0.917426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.250823</td>\n",
       "      <td>0.916852</td>\n",
       "      <td>0.922092</td>\n",
       "      <td>0.929072</td>\n",
       "      <td>0.915217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 16] Training time: 2026.30 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='422' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 16] Validation metrics: {'eval_loss': 0.25151702761650085, 'eval_accuracy': 0.9170007423904974, 'eval_f1': 0.9223934471747883, 'eval_precision': 0.9274148520379676, 'eval_recall': 0.9174261253797293, 'eval_runtime': 11.2259, 'eval_samples_per_second': 599.952, 'eval_steps_per_second': 18.796, 'epoch': 10.0}\n",
      "[Rank 16] Test metrics: {'eval_loss': 0.2650555968284607, 'eval_accuracy': 0.9097253155159614, 'eval_f1': 0.9195128408790045, 'eval_precision': 0.9224435590969455, 'eval_recall': 0.9166006861968857, 'eval_runtime': 10.8663, 'eval_samples_per_second': 619.804, 'eval_steps_per_second': 19.418, 'epoch': 10.0}\n",
      "[Rank 16] LoRA sparsity (<1e-3): 35.68%\n",
      "[Rank 16] Saved model to ./sparse_lora_rank16/final_model\n",
      "[Rank 16] Saved log history to log_history.json\n",
      "\n",
      "\n",
      "=== Summary over ranks (Sparse LoRA) ===\n",
      "\n",
      "Rank 2:\n",
      "  Params: 665,858 / 67,620,868 (0.98%)\n",
      "  Train time: 2000.22 s\n",
      "  Val F1:  0.9072, Acc: 0.9004\n",
      "  Test F1: 0.9028, Acc: 0.8915\n",
      "  LoRA sparsity (<1e-3): 15.55%\n",
      "\n",
      "Rank 4:\n",
      "  Params: 739,586 / 67,694,596 (1.09%)\n",
      "  Train time: 2051.59 s\n",
      "  Val F1:  0.9135, Acc: 0.9068\n",
      "  Test F1: 0.9064, Acc: 0.8950\n",
      "  LoRA sparsity (<1e-3): 21.52%\n",
      "\n",
      "Rank 8:\n",
      "  Params: 887,042 / 67,842,052 (1.31%)\n",
      "  Train time: 2036.44 s\n",
      "  Val F1:  0.9178, Acc: 0.9121\n",
      "  Test F1: 0.9122, Acc: 0.9017\n",
      "  LoRA sparsity (<1e-3): 27.88%\n",
      "\n",
      "Rank 16:\n",
      "  Params: 1,181,954 / 68,136,964 (1.73%)\n",
      "  Train time: 2026.30 s\n",
      "  Val F1:  0.9224, Acc: 0.9170\n",
      "  Test F1: 0.9195, Acc: 0.9097\n",
      "  LoRA sparsity (<1e-3): 35.68%\n"
     ]
    }
   ],
   "source": [
    "# ================== SPARSE LoRA MODEL =================\n",
    "\n",
    "from typing import Dict, Any, List, Optional\n",
    "import math\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# -------- Sparse LoRA config --------\n",
    "RANKS: List[int] = [2, 4, 8, 16]\n",
    "L1_LAMBDA = 1e-5   # sparsity strength for LoRA weights\n",
    "\n",
    "\n",
    "def count_trainable_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def count_total_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def compute_lora_sparsity(model: torch.nn.Module, threshold: float = 1e-3) -> float:\n",
    "    \"\"\"\n",
    "    Approximate sparsity: fraction of LoRA parameters with |w| < threshold.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    near_zero = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"lora_\" in name and param.requires_grad:\n",
    "            data = param.detach().abs()\n",
    "            total += data.numel()\n",
    "            near_zero += (data < threshold).sum().item()\n",
    "    return near_zero / total if total > 0 else math.nan\n",
    "\n",
    "\n",
    "class SparseLoraTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Trainer with L1 penalty only on LoRA parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, l1_lambda: float = 0.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.l1_lambda = l1_lambda\n",
    "\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        model,\n",
    "        inputs,\n",
    "        return_outputs: bool = False,\n",
    "        num_items_in_batch: Optional[int] = None,\n",
    "    ):\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        if self.l1_lambda > 0:\n",
    "            l1_reg = 0.0\n",
    "            for name, param in model.named_parameters():\n",
    "                if \"lora_\" in name and param.requires_grad:\n",
    "                    l1_reg = l1_reg + param.abs().sum()\n",
    "            loss = loss + self.l1_lambda * l1_reg\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "results_per_rank: List[Dict[str, Any]] = []\n",
    "\n",
    "for r in RANKS:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Training Sparse LoRA DistilBERT with rank = {r}, epochs = {NUM_EPOCHS}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    set_all_seeds(SEED)\n",
    "\n",
    "    # Base DistilBERT for this rank\n",
    "    base_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=2,\n",
    "    )\n",
    "\n",
    "    # LoRA config: attention projections in DistilBERT\n",
    "    lora_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=2 * r,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\",    # sequence classification\n",
    "        target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"],\n",
    "    )\n",
    "\n",
    "    lora_model = get_peft_model(base_model, lora_config)\n",
    "    lora_model.to(DEVICE)\n",
    "\n",
    "    total_params = count_total_params(lora_model)\n",
    "    trainable_params = count_trainable_params(lora_model)\n",
    "    param_ratio = trainable_params / total_params\n",
    "\n",
    "    print(f\"[Rank {r}] total params: {total_params:,}\")\n",
    "    print(f\"[Rank {r}] trainable params: {trainable_params:,}\")\n",
    "    print(f\"[Rank {r}] trainable params ratio (trainable / total): {param_ratio:.4%}\")\n",
    "\n",
    "    output_dir = f\"./sparse_lora_rank{r}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    training_args_lora = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        learning_rate=LR,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        seed=SEED,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = SparseLoraTrainer(\n",
    "        l1_lambda=L1_LAMBDA,\n",
    "        model=lora_model,\n",
    "        args=training_args_lora,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    print(f\"[Rank {r}] Training time: {train_time:.2f} seconds\")\n",
    "\n",
    "    # --- final evals ---\n",
    "    val_metrics = trainer.evaluate(eval_dataset=val_ds)\n",
    "    test_metrics = trainer.evaluate(eval_dataset=test_ds)\n",
    "    lora_sparsity = compute_lora_sparsity(lora_model, threshold=1e-3)\n",
    "\n",
    "    print(f\"[Rank {r}] Validation metrics: {val_metrics}\")\n",
    "    print(f\"[Rank {r}] Test metrics: {test_metrics}\")\n",
    "    print(f\"[Rank {r}] LoRA sparsity (<1e-3): {lora_sparsity:.2%}\")\n",
    "\n",
    "    # ==========================\n",
    "    # SAVE METRICS / MODEL / LOG\n",
    "    # ==========================\n",
    "    # 1) save metrics\n",
    "    metrics_payload = {\n",
    "        \"rank\": r,\n",
    "        \"train_time_sec\": train_time,\n",
    "        \"total_params\": int(total_params),\n",
    "        \"trainable_params\": int(trainable_params),\n",
    "        \"param_ratio\": float(param_ratio),\n",
    "        \"lora_sparsity_<1e-3\": float(lora_sparsity),\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"final_metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics_payload, f, indent=4)\n",
    "\n",
    "    # 2) save final model (best checkpoint)\n",
    "    final_model_dir = os.path.join(output_dir, \"final_model\")\n",
    "    trainer.save_model(final_model_dir)  # saves model + config\n",
    "    tokenizer.save_pretrained(final_model_dir)  # save tokenizer too\n",
    "    print(f\"[Rank {r}] Saved model to {final_model_dir}\")\n",
    "\n",
    "    # 3) save convergence history\n",
    "    log_history = trainer.state.log_history\n",
    "    with open(os.path.join(output_dir, \"log_history.json\"), \"w\") as f:\n",
    "        json.dump(log_history, f, indent=4)\n",
    "    print(f\"[Rank {r}] Saved log history to log_history.json\")\n",
    "\n",
    "    # --- store in-memory summary for printing ---\n",
    "    results_per_rank.append(\n",
    "        {\n",
    "            \"rank\": r,\n",
    "            \"total_params\": total_params,\n",
    "            \"trainable_params\": trainable_params,\n",
    "            \"param_ratio\": param_ratio,\n",
    "            \"train_time_sec\": train_time,\n",
    "            \"val_metrics\": val_metrics,\n",
    "            \"test_metrics\": test_metrics,\n",
    "            \"lora_sparsity(<1e-3)\": lora_sparsity,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n=== Summary over ranks (Sparse LoRA) ===\")\n",
    "for res in results_per_rank:\n",
    "    r = res[\"rank\"]\n",
    "    print(f\"\\nRank {r}:\")\n",
    "    print(f\"  Params: {res['trainable_params']:,} / {res['total_params']:,} \"\n",
    "          f\"({res['param_ratio']:.2%})\")\n",
    "    print(f\"  Train time: {res['train_time_sec']:.2f} s\")\n",
    "    print(f\"  Val F1:  {res['val_metrics'].get('eval_f1', float('nan')):.4f}, \"\n",
    "          f\"Acc: {res['val_metrics'].get('eval_accuracy', float('nan')):.4f}\")\n",
    "    print(f\"  Test F1: {res['test_metrics'].get('eval_f1', float('nan')):.4f}, \"\n",
    "          f\"Acc: {res['test_metrics'].get('eval_accuracy', float('nan')):.4f}\")\n",
    "    print(f\"  LoRA sparsity (<1e-3): {res['lora_sparsity(<1e-3)']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d6b99-1ac4-43c4-9fad-55a184209bd8",
   "metadata": {},
   "source": [
    "### IMDB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b7334-2fdd-4959-ba29-f97654cf3c01",
   "metadata": {},
   "source": [
    "Have commented out in the corresponding section \\\n",
    "Just to replace the loaded dataset accordingly:\n",
    "- DATASET = \"imdb\"\n",
    "- TEXT_COL = \"text\"\n",
    "- LABEL_COL = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317de448-2bfd-4546-ad32-565dd04594f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

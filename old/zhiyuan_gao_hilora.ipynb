{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46eecf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch>=2.0.0 (from -r requirements.txt (line 1))\n",
      "  Downloading torch-2.9.1-cp314-cp314-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting transformers>=4.30.0 (from -r requirements.txt (line 2))\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets (from -r requirements.txt (line 3))\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft (from -r requirements.txt (line 4))\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting accelerate (from -r requirements.txt (line 5))\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate (from -r requirements.txt (line 6))\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 7))\n",
      "  Downloading scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting tqdm (from -r requirements.txt (line 8))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 9))\n",
      "  Downloading numpy-2.3.5-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 10))\n",
      "  Downloading pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting matplotlib (from -r requirements.txt (line 11))\n",
      "  Downloading matplotlib-3.10.7-cp314-cp314-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting seaborn (from -r requirements.txt (line 12))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting filelock (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting setuptools (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.14/site-packages (from transformers>=4.30.0->-r requirements.txt (line 2)) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Downloading pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Downloading regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets->-r requirements.txt (line 3))\n",
      "  Downloading pyarrow-22.0.0-cp314-cp314-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets->-r requirements.txt (line 3))\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting httpx<1.0.0 (from datasets->-r requirements.txt (line 3))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 3))\n",
      "  Downloading xxhash-3.6.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets->-r requirements.txt (line 3))\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.13.2-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets->-r requirements.txt (line 3))\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets->-r requirements.txt (line 3))\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets->-r requirements.txt (line 3))\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets->-r requirements.txt (line 3))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: psutil in ./.conda/lib/python3.14/site-packages (from peft->-r requirements.txt (line 4)) (7.0.0)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn->-r requirements.txt (line 7))\n",
      "  Downloading scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 7))\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 7))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.14/site-packages (from pandas->-r requirements.txt (line 10)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 10))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 10))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 11))\n",
      "  Downloading contourpy-1.3.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 11))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 11))\n",
      "  Downloading fonttools-4.60.1-cp314-cp314-macosx_10_13_universal2.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 11))\n",
      "  Downloading kiwisolver-1.4.9-cp314-cp314-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib->-r requirements.txt (line 11))\n",
      "  Downloading pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->-r requirements.txt (line 11))\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading frozenlist-1.8.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading multidict-6.7.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading propcache-0.4.1-cp314-cp314-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
      "  Downloading yarl-1.22.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 10)) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Downloading charset_normalizer-3.4.4-cp314-cp314-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers>=4.30.0->-r requirements.txt (line 2))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1.0.0->datasets->-r requirements.txt (line 3))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading markupsafe-3.0.3-cp314-cp314-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Downloading torch-2.9.1-cp314-cp314-macosx_11_0_arm64.whl (74.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading scikit_learn-1.7.2-cp314-cp314-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading numpy-2.3.5-cp314-cp314-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp314-cp314-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.7-cp314-cp314-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading aiohttp-3.13.2-cp314-cp314-macosx_11_0_arm64.whl (491 kB)\n",
      "Downloading multidict-6.7.0-cp314-cp314-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading yarl-1.22.0-cp314-cp314-macosx_11_0_arm64.whl (94 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading contourpy-1.3.3-cp314-cp314-macosx_11_0_arm64.whl (273 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp314-cp314-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.8.0-cp314-cp314-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading kiwisolver-1.4.9-cp314-cp314-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp314-cp314-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp314-cp314-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading pyarrow-22.0.0-cp314-cp314-macosx_12_0_arm64.whl (34.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.2/34.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading pyyaml-6.0.3-cp314-cp314-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading regex-2025.11.3-cp314-cp314-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp314-cp314-macosx_10_13_universal2.whl (207 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Downloading scipy-1.16.3-cp314-cp314-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp314-cp314-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading xxhash-3.6.0-cp314-cp314-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: pytz, mpmath, xxhash, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, sniffio, setuptools, safetensors, regex, pyyaml, pyparsing, pyarrow, propcache, pillow, numpy, networkx, multidict, MarkupSafe, kiwisolver, joblib, idna, hf-xet, h11, fsspec, frozenlist, fonttools, filelock, dill, cycler, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, scipy, requests, pandas, multiprocess, jinja2, httpcore, contourpy, anyio, aiosignal, torch, scikit-learn, matplotlib, huggingface-hub, httpx, aiohttp, tokenizers, seaborn, accelerate, transformers, datasets, peft, evaluate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60/60\u001b[0m [evaluate]/60\u001b[0m [peft]ets]ers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.11.0 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 datasets-4.4.1 dill-0.4.0 evaluate-0.4.6 filelock-3.20.0 fonttools-4.60.1 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.7 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.6 numpy-2.3.5 pandas-2.3.3 peft-0.18.0 pillow-12.0.0 propcache-0.4.1 pyarrow-22.0.0 pyparsing-3.2.5 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.16.3 seaborn-0.13.2 setuptools-80.9.0 sniffio-1.3.1 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2120ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     torch.backends.cudnn.deterministic = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     11\u001b[39m     torch.backends.cudnn.benchmark = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m      5\u001b[39m random.seed(seed)\n\u001b[32m      6\u001b[39m np.random.seed(seed)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtorch\u001b[49m.manual_seed(seed)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m      9\u001b[39m     torch.cuda.manual_seed_all(seed)\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19244fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "class HiRALayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        r: int = 32,\n",
    "        lora_alpha: int = 32,\n",
    "        lora_dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "        self.lora_alpha = lora_alpha\n",
    "        self.scaling = lora_alpha / r\n",
    "        \n",
    "        self.lora_A = nn.Parameter(torch.zeros(in_features, r))\n",
    "        self.lora_B = nn.Parameter(torch.randn(r, out_features))\n",
    "        \n",
    "        nn.init.zeros_(self.lora_A)\n",
    "        nn.init.kaiming_uniform_(self.lora_B, a=0)\n",
    "        \n",
    "        self.lora_dropout = nn.Dropout(p=lora_dropout) if lora_dropout > 0 else nn.Identity()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, W0: torch.Tensor) -> torch.Tensor:\n",
    "        result = F.linear(x, W0)\n",
    "        \n",
    "        lora_update = self.lora_A @ self.lora_B  # [in_features, out_features]\n",
    "        \n",
    "        hadamard_update = W0.T * lora_update  # [in_features, out_features]\n",
    "        \n",
    "        result += self.lora_dropout(x @ hadamard_update) * self.scaling\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class HiRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer: nn.Linear, r: int = 32, lora_alpha: int = 32):\n",
    "        super().__init__()\n",
    "        self.linear = linear_layer\n",
    "        self.hira = HiRALayer(\n",
    "            in_features=linear_layer.in_features,\n",
    "            out_features=linear_layer.out_features,\n",
    "            r=r,\n",
    "            lora_alpha=lora_alpha\n",
    "        )\n",
    "        self.linear.weight.requires_grad = False\n",
    "        if self.linear.bias is not None:\n",
    "            self.linear.bias.requires_grad = False\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.hira(x, self.linear.weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc10860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaozhiyuan/ECE685_Final_Project/.conda/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "import torch.nn as nn\n",
    "\n",
    "def apply_hira_to_model(model, r=32, lora_alpha=32, target_modules=['q_lin', 'k_lin', 'v_lin', 'out_lin', 'ffn.lin1', 'ffn.lin2']):\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if any(target in name for target in target_modules):\n",
    "                parent_name = '.'.join(name.split('.')[:-1])\n",
    "                attr_name = name.split('.')[-1]\n",
    "                \n",
    "                if parent_name:\n",
    "                    parent_module = model.get_submodule(parent_name)\n",
    "                else:\n",
    "                    parent_module = model\n",
    "                \n",
    "                hira_layer = HiRALinear(module, r=r, lora_alpha=lora_alpha)\n",
    "                setattr(parent_module, attr_name, hira_layer)\n",
    "                \n",
    "                print(f\"Applied HiRA to: {name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    return trainable_params, all_params, 100 * trainable_params / all_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c764b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def load_sst2_data(tokenizer, max_length=128):\n",
    "    \"\"\"8:1:1 \"\"\"\n",
    "    raw = load_dataset(\"glue\", \"sst2\")  # 有 train / validation / test[web:110]\n",
    "\n",
    "    train_valid = raw[\"train\"]\n",
    "    train_valid = train_valid.shuffle(seed=42)\n",
    "    n = len(train_valid)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val = int(0.1 * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_dataset = train_valid.select(range(n_train))\n",
    "    val_dataset   = train_valid.select(range(n_train, n_train + n_val))\n",
    "    test_dataset  = train_valid.select(range(n_train + n_val, n))\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        enc = tokenizer(\n",
    "            examples[\"sentence\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        enc[\"labels\"] = examples[\"label\"]\n",
    "        return enc\n",
    "\n",
    "    train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "    val_dataset   = val_dataset.map(preprocess_function,   batched=True, remove_columns=val_dataset.column_names)\n",
    "    test_dataset  = test_dataset.map(preprocess_function,  batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "    return {\n",
    "        \"train\": train_dataset,\n",
    "        \"validation\": val_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def load_imdb_data(tokenizer, max_length=256):\n",
    "\n",
    "    raw = load_dataset(\"imdb\")  \n",
    "\n",
    "    train_full = raw[\"train\"]               \n",
    "    train_full = train_full.shuffle(seed=42)\n",
    "    n = len(train_full)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val = int(0.1 * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_dataset = train_full.select(range(n_train))\n",
    "    val_dataset   = train_full.select(range(n_train, n_train + n_val))\n",
    "    test_dataset  = train_full.select(range(n_train + n_val, n))\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        enc = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        enc[\"labels\"] = examples[\"label\"]\n",
    "        return enc\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=train_dataset.column_names,\n",
    "    )\n",
    "    val_dataset = val_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=val_dataset.column_names,\n",
    "    )\n",
    "    test_dataset = test_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=test_dataset.column_names,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train\": train_dataset,\n",
    "        \"validation\": val_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf0561",
   "metadata": {},
   "source": [
    "# After changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d17063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for p in model.parameters():\n",
    "        num = p.numel()\n",
    "        all_params += num\n",
    "        if p.requires_grad:\n",
    "            trainable_params += num\n",
    "    percentage = 100.0 * trainable_params / all_params if all_params > 0 else 0.0\n",
    "    return trainable_params, all_params, percentage\n",
    "\n",
    "\n",
    "def get_model_sparsity(model, threshold: float = 1e-3) -> float:\n",
    "    total_elems = 0\n",
    "    small_elems = 0\n",
    "    for p in model.parameters():\n",
    "        if p is None:\n",
    "            continue\n",
    "        data = p.detach()\n",
    "        total_elems += data.numel()\n",
    "        small_elems += (data.abs() < threshold).sum().item()\n",
    "    if total_elems == 0:\n",
    "        return 0.0\n",
    "    return small_elems / total_elems\n",
    "\n",
    "def train_hira_model(\n",
    "    dataset_name: str = \"sst2\",\n",
    "    model_name: str = \"distilbert-base-uncased\",\n",
    "    r: int = 32,\n",
    "    lora_alpha: int = 32,\n",
    "    num_epochs: int = 3,\n",
    "    batch_size: int = 16,\n",
    "    learning_rate: float = 2e-5,\n",
    "    warmup_steps: int = 100,\n",
    "    max_length: int = 128,\n",
    "    output_dir: str = \"./results_hira\",\n",
    "):\n",
    "\n",
    "    device = torch.device(\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"[{dataset_name}][r={r}] Using device: {device}\")\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    num_labels = 2\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "    )\n",
    "    model = apply_hira_to_model(model, r=r, lora_alpha=lora_alpha)\n",
    "    model = model.to(device)\n",
    "\n",
    "    trainable_params, all_params, percentage = get_trainable_parameters(model)\n",
    "    print(\n",
    "        f\"[{dataset_name}][r={r}] Trainable params: {trainable_params:,} || \"\n",
    "        f\"All params: {all_params:,} || Trainable%: {percentage:.4f}%\"\n",
    "    )\n",
    "\n",
    "    if dataset_name == \"sst2\":\n",
    "        dataset = load_sst2_data(tokenizer, max_length)\n",
    "    elif dataset_name == \"imdb\":\n",
    "        dataset = load_imdb_data(tokenizer, max_length)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset_name: {dataset_name}\")\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    val_split_name = \"validation\" if \"validation\" in dataset else \"test\"\n",
    "    val_dataloader = DataLoader(\n",
    "        dataset[val_split_name],\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=learning_rate,\n",
    "    )\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    epoch_times = []\n",
    "    total_train_time = 0.0\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_f1 = 0.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_t = time.perf_counter()\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        progress_bar = tqdm(\n",
    "            train_dataloader,\n",
    "            desc=f\"[{dataset_name}][r={r}] Epoch {epoch + 1}/{num_epochs}\",\n",
    "        )\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        acc_metric = evaluate.load(\"accuracy\")\n",
    "        f1_metric = evaluate.load(\"f1\")\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            acc_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "            f1_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "\n",
    "        val_acc = acc_metric.compute()[\"accuracy\"]\n",
    "        val_f1 = f1_metric.compute()[\"f1\"]\n",
    "\n",
    "        end_t = time.perf_counter()\n",
    "        epoch_time = end_t - start_t\n",
    "        epoch_times.append(epoch_time)\n",
    "        total_train_time += epoch_time\n",
    "\n",
    "        print(\n",
    "            f\"[{dataset_name}][r={r}] Epoch {epoch + 1} | \"\n",
    "            f\"train_loss={avg_train_loss:.4f} | \"\n",
    "            f\"val_acc={val_acc:.4f} | \"\n",
    "            f\"val_f1={val_f1:.4f} | \"\n",
    "            f\"time/epoch={epoch_time:.2f}s\"\n",
    "        )\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_accuracy = val_acc\n",
    "            best_val_f1 = val_f1\n",
    "            if best_epoch == -1:\n",
    "                best_epoch = epoch + 1\n",
    "\n",
    "            save_path = os.path.join(output_dir, f\"best_model_r{r}.pt\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"accuracy\": best_val_accuracy,\n",
    "                },\n",
    "                save_path,\n",
    "            )\n",
    "            print(\n",
    "                f\"[{dataset_name}][r={r}] Saved best model with \"\n",
    "                f\"val_acc={best_val_accuracy:.4f} to {save_path}\"\n",
    "            )\n",
    "\n",
    "    avg_time_per_epoch = sum(epoch_times) / len(epoch_times)\n",
    "    print(\n",
    "        f\"[{dataset_name}][r={r}] Training completed! \"\n",
    "        f\"best_val_acc={best_val_accuracy:.4f}, \"\n",
    "        f\"avg_time/epoch={avg_time_per_epoch:.2f}s, \"\n",
    "        f\"converge_epoch={best_epoch}, \"\n",
    "        f\"trainable_params={trainable_params}, \"\n",
    "        f\"trainable_ratio={percentage:.4f}%\"\n",
    "    )\n",
    "\n",
    "    acc_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        acc_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "        f1_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "\n",
    "    test_acc = acc_metric.compute()[\"accuracy\"]\n",
    "    test_f1 = f1_metric.compute()[\"f1\"]\n",
    "    print(f\"[{dataset_name}][r={r}] Final test accuracy: {test_acc:.4f}, test_f1={test_f1:.4f}\")\n",
    "\n",
    "    sparsity = get_model_sparsity(model, threshold=1e-3)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"r\": r,\n",
    "        \"best_val_acc\": best_val_accuracy,\n",
    "        \"best_val_f1\": best_val_f1,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"avg_time_per_epoch\": avg_time_per_epoch,\n",
    "        \"total_train_time\": total_train_time,\n",
    "        \"converge_epoch\": best_epoch,\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"total_params\": all_params,\n",
    "        \"trainable_ratio\": percentage,   \n",
    "        \"sparsity\": sparsity,            \n",
    "    }\n",
    "\n",
    "\n",
    "def format_int_with_commas(x: int) -> str:\n",
    "    return f\"{x:,}\"\n",
    "\n",
    "\n",
    "def generate_summary_table(results):\n",
    "    results_sorted = sorted(\n",
    "        results,\n",
    "        key=lambda d: d[\"test_acc\"],\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    header = (\n",
    "        \"| Rank | Trainable Params / Total | Ratio | Val F1 | Val Acc | \"\n",
    "        \"Test F1 | Test Acc | Sparsity (<1e−3) | Train Time (s) |\\n\"\n",
    "    )\n",
    "    sep = (\n",
    "        \"| ---- | ------------------------ | ----- | ------ | ------- | \"\n",
    "        \"------- | -------- | ----------------- | -------------- |\\n\"\n",
    "    )\n",
    "\n",
    "    lines = [header, sep]\n",
    "    for rank, res in enumerate(results_sorted, start=1):\n",
    "        trainable = format_int_with_commas(res[\"trainable_params\"])\n",
    "        total = f\"{res['total_params']/1e6:.1f}M\"\n",
    "        ratio = f\"{res['trainable_ratio']:.2f}%\"\n",
    "        val_f1 = f\"{res['best_val_f1']:.4f}\"\n",
    "        val_acc = f\"{res['best_val_acc']:.4f}\"\n",
    "        test_f1 = f\"{res['test_f1']:.4f}\"\n",
    "        test_acc = f\"{res['test_acc']:.4f}\"\n",
    "        sparsity = f\"{res['sparsity']*100:.2f}%\"\n",
    "        train_time = f\"{res['total_train_time']:.2f}\"\n",
    "\n",
    "        line = (\n",
    "            f\"| {rank} | {trainable} / {total} | {ratio} | \"\n",
    "            f\"{val_f1} | {val_acc} | {test_f1} | {test_acc} | \"\n",
    "            f\"{sparsity} | {train_time} |\\n\"\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    table_md = \"\".join(lines)\n",
    "    print(\"\\nResult Summary Table:\\n\")\n",
    "    print(table_md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d20232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training HiRA on SST-2 with different ranks\n",
      "==================================================\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=2\n",
      "------------------------------\n",
      "[sst2][r=2] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=2] Trainable params: 24,612,098 || All params: 67,120,898 || Trainable%: 36.6683%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 1/10: 100%|██████████| 3368/3368 [04:55<00:00, 11.40it/s, loss=0.373] \n",
      "Downloading builder script: 6.79kB [00:00, 9.61MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 1 | train_loss=0.3480 | val_acc=0.9024 | val_f1=0.9131 | time/epoch=319.12s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9024 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 2/10: 100%|██████████| 3368/3368 [05:47<00:00,  9.70it/s, loss=0.102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 2 | train_loss=0.2189 | val_acc=0.9168 | val_f1=0.9262 | time/epoch=361.93s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9168 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 3/10: 100%|██████████| 3368/3368 [05:19<00:00, 10.55it/s, loss=0.028]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 3 | train_loss=0.1712 | val_acc=0.9265 | val_f1=0.9342 | time/epoch=334.22s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9265 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 4/10: 100%|██████████| 3368/3368 [05:04<00:00, 11.06it/s, loss=0.393]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 4 | train_loss=0.1414 | val_acc=0.9317 | val_f1=0.9390 | time/epoch=320.76s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9317 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 5/10: 100%|██████████| 3368/3368 [05:17<00:00, 10.61it/s, loss=0.591]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 5 | train_loss=0.1203 | val_acc=0.9330 | val_f1=0.9401 | time/epoch=333.44s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9330 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 6/10: 100%|██████████| 3368/3368 [05:15<00:00, 10.69it/s, loss=0.00773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 6 | train_loss=0.1079 | val_acc=0.9344 | val_f1=0.9411 | time/epoch=331.25s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9344 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 7/10: 100%|██████████| 3368/3368 [05:18<00:00, 10.58it/s, loss=0.349]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 7 | train_loss=0.0973 | val_acc=0.9348 | val_f1=0.9416 | time/epoch=334.46s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9348 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 8/10: 100%|██████████| 3368/3368 [05:20<00:00, 10.51it/s, loss=0.0243] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 8 | train_loss=0.0884 | val_acc=0.9361 | val_f1=0.9430 | time/epoch=336.72s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9361 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 9/10: 100%|██████████| 3368/3368 [05:13<00:00, 10.75it/s, loss=0.00744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 9 | train_loss=0.0850 | val_acc=0.9367 | val_f1=0.9435 | time/epoch=329.15s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9367 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 10/10: 100%|██████████| 3368/3368 [05:23<00:00, 10.40it/s, loss=0.0977] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 10 | train_loss=0.0818 | val_acc=0.9373 | val_f1=0.9441 | time/epoch=340.47s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9373 to ./results_hira/best_model_r2.pt\n",
      "[sst2][r=2] Training completed! best_val_acc=0.9373, avg_time/epoch=334.15s, converge_epoch=1, trainable_params=24612098, trainable_ratio=36.6683%\n",
      "[sst2][r=2] Final test accuracy: 0.9382, test_f1=0.9458\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=4\n",
      "------------------------------\n",
      "[sst2][r=4] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=4] Trainable params: 24,777,986 || All params: 67,286,786 || Trainable%: 36.8244%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 1/10: 100%|██████████| 3368/3368 [05:35<00:00, 10.05it/s, loss=0.101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 1 | train_loss=0.3418 | val_acc=0.9004 | val_f1=0.9111 | time/epoch=353.02s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9004 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 2/10: 100%|██████████| 3368/3368 [05:24<00:00, 10.38it/s, loss=0.0792] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 2 | train_loss=0.2167 | val_acc=0.9182 | val_f1=0.9273 | time/epoch=341.24s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9182 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 3/10: 100%|██████████| 3368/3368 [05:34<00:00, 10.06it/s, loss=0.012]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 3 | train_loss=0.1692 | val_acc=0.9266 | val_f1=0.9347 | time/epoch=351.44s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9266 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 4/10: 100%|██████████| 3368/3368 [05:19<00:00, 10.54it/s, loss=0.316]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 4 | train_loss=0.1401 | val_acc=0.9315 | val_f1=0.9387 | time/epoch=335.78s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9315 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 5/10: 100%|██████████| 3368/3368 [05:16<00:00, 10.65it/s, loss=0.0206] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 5 | train_loss=0.1215 | val_acc=0.9335 | val_f1=0.9403 | time/epoch=332.47s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9335 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 6/10: 100%|██████████| 3368/3368 [05:14<00:00, 10.70it/s, loss=0.109]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 6 | train_loss=0.1070 | val_acc=0.9350 | val_f1=0.9418 | time/epoch=330.67s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9350 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 7/10: 100%|██████████| 3368/3368 [05:16<00:00, 10.64it/s, loss=0.00793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 7 | train_loss=0.0966 | val_acc=0.9358 | val_f1=0.9426 | time/epoch=332.51s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9358 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 8/10: 100%|██████████| 3368/3368 [05:13<00:00, 10.76it/s, loss=0.0219] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 8 | train_loss=0.0904 | val_acc=0.9375 | val_f1=0.9442 | time/epoch=329.21s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9375 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 9/10: 100%|██████████| 3368/3368 [05:19<00:00, 10.54it/s, loss=0.00822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 9 | train_loss=0.0849 | val_acc=0.9366 | val_f1=0.9433 | time/epoch=336.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 10/10: 100%|██████████| 3368/3368 [05:24<00:00, 10.37it/s, loss=0.00689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 10 | train_loss=0.0808 | val_acc=0.9370 | val_f1=0.9438 | time/epoch=341.41s\n",
      "[sst2][r=4] Training completed! best_val_acc=0.9375, avg_time/epoch=338.41s, converge_epoch=1, trainable_params=24777986, trainable_ratio=36.8244%\n",
      "[sst2][r=4] Final test accuracy: 0.9382, test_f1=0.9459\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=8\n",
      "------------------------------\n",
      "[sst2][r=8] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=8] Trainable params: 25,109,762 || All params: 67,618,562 || Trainable%: 37.1344%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 1/10: 100%|██████████| 3368/3368 [30:20<00:00,  1.85it/s, loss=0.121]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 1 | train_loss=0.3449 | val_acc=0.9004 | val_f1=0.9097 | time/epoch=326.80s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9004 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 2/10: 100%|██████████| 3368/3368 [20:04<00:00,  2.80it/s, loss=0.36]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 2 | train_loss=0.2182 | val_acc=0.9176 | val_f1=0.9270 | time/epoch=304.32s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9176 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 3/10: 100%|██████████| 3368/3368 [05:39<00:00,  9.92it/s, loss=0.118]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 3 | train_loss=0.1714 | val_acc=0.9241 | val_f1=0.9321 | time/epoch=355.02s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9241 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 4/10: 100%|██████████| 3368/3368 [05:04<00:00, 11.04it/s, loss=0.0443] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 4 | train_loss=0.1411 | val_acc=0.9275 | val_f1=0.9359 | time/epoch=321.24s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9275 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 5/10: 100%|██████████| 3368/3368 [05:08<00:00, 10.91it/s, loss=0.00425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 5 | train_loss=0.1213 | val_acc=0.9321 | val_f1=0.9392 | time/epoch=324.63s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9321 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 6/10: 100%|██████████| 3368/3368 [05:18<00:00, 10.58it/s, loss=0.11]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 6 | train_loss=0.1089 | val_acc=0.9347 | val_f1=0.9418 | time/epoch=335.23s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9347 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 7/10: 100%|██████████| 3368/3368 [05:22<00:00, 10.46it/s, loss=0.744]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 7 | train_loss=0.0963 | val_acc=0.9353 | val_f1=0.9424 | time/epoch=340.79s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9353 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 8/10: 100%|██████████| 3368/3368 [05:25<00:00, 10.33it/s, loss=0.0421] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 8 | train_loss=0.0888 | val_acc=0.9361 | val_f1=0.9431 | time/epoch=342.71s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9361 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 9/10: 100%|██████████| 3368/3368 [05:22<00:00, 10.46it/s, loss=0.000541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 9 | train_loss=0.0851 | val_acc=0.9361 | val_f1=0.9432 | time/epoch=338.74s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9361 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 10/10: 100%|██████████| 3368/3368 [05:19<00:00, 10.55it/s, loss=0.00243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 10 | train_loss=0.0815 | val_acc=0.9363 | val_f1=0.9432 | time/epoch=335.66s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9363 to ./results_hira/best_model_r8.pt\n",
      "[sst2][r=8] Training completed! best_val_acc=0.9363, avg_time/epoch=332.51s, converge_epoch=1, trainable_params=25109762, trainable_ratio=37.1344%\n",
      "[sst2][r=8] Final test accuracy: 0.9387, test_f1=0.9462\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=16\n",
      "------------------------------\n",
      "[sst2][r=16] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 2dd09c47-c9e4-4c30-8eb7-5aad09983146)')' thrown while requesting HEAD https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=16] Trainable params: 25,773,314 || All params: 68,282,114 || Trainable%: 37.7453%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 1/10: 100%|██████████| 3368/3368 [05:06<00:00, 10.99it/s, loss=0.996] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 1 | train_loss=0.3456 | val_acc=0.9018 | val_f1=0.9128 | time/epoch=323.77s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9018 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 2/10: 100%|██████████| 3368/3368 [05:26<00:00, 10.33it/s, loss=0.672] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 2 | train_loss=0.2187 | val_acc=0.9174 | val_f1=0.9267 | time/epoch=342.33s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9174 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 3/10: 100%|██████████| 3368/3368 [05:24<00:00, 10.39it/s, loss=0.0777] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 3 | train_loss=0.1707 | val_acc=0.9275 | val_f1=0.9355 | time/epoch=341.72s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9275 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 4/10: 100%|██████████| 3368/3368 [05:30<00:00, 10.20it/s, loss=0.0636] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 4 | train_loss=0.1414 | val_acc=0.9298 | val_f1=0.9375 | time/epoch=347.25s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9298 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 5/10: 100%|██████████| 3368/3368 [05:24<00:00, 10.38it/s, loss=0.131]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 5 | train_loss=0.1212 | val_acc=0.9335 | val_f1=0.9405 | time/epoch=340.76s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9335 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 6/10: 100%|██████████| 3368/3368 [05:19<00:00, 10.53it/s, loss=0.00691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 6 | train_loss=0.1071 | val_acc=0.9341 | val_f1=0.9408 | time/epoch=336.11s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9341 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 7/10: 100%|██████████| 3368/3368 [05:22<00:00, 10.44it/s, loss=0.0108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 7 | train_loss=0.0972 | val_acc=0.9356 | val_f1=0.9426 | time/epoch=340.30s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9356 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 8/10: 100%|██████████| 3368/3368 [05:27<00:00, 10.30it/s, loss=0.0396] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 8 | train_loss=0.0911 | val_acc=0.9361 | val_f1=0.9429 | time/epoch=344.36s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9361 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 9/10: 100%|██████████| 3368/3368 [05:25<00:00, 10.33it/s, loss=0.0782] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 9 | train_loss=0.0848 | val_acc=0.9360 | val_f1=0.9429 | time/epoch=342.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 10/10: 100%|██████████| 3368/3368 [05:32<00:00, 10.14it/s, loss=0.173]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 10 | train_loss=0.0830 | val_acc=0.9367 | val_f1=0.9436 | time/epoch=348.33s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9367 to ./results_hira/best_model_r16.pt\n",
      "[sst2][r=16] Training completed! best_val_acc=0.9367, avg_time/epoch=340.71s, converge_epoch=1, trainable_params=25773314, trainable_ratio=37.7453%\n",
      "[sst2][r=16] Final test accuracy: 0.9381, test_f1=0.9458\n",
      "\n",
      "Result Summary Table:\n",
      "\n",
      "| Rank | Trainable Params / Total | Ratio | Val F1 | Val Acc | Test F1 | Test Acc | Sparsity (<1e−3) | Train Time (s) |\n",
      "| ---- | ------------------------ | ----- | ------ | ------- | ------- | -------- | ----------------- | -------------- |\n",
      "| 1 | 25,109,762 / 67.6M | 37.13% | 0.9432 | 0.9363 | 0.9462 | 0.9387 | 1.79% | 3325.13 |\n",
      "| 2 | 24,612,098 / 67.1M | 36.67% | 0.9441 | 0.9373 | 0.9458 | 0.9382 | 1.74% | 3341.53 |\n",
      "| 3 | 24,777,986 / 67.3M | 36.82% | 0.9442 | 0.9375 | 0.9459 | 0.9382 | 1.76% | 3384.06 |\n",
      "| 4 | 25,773,314 / 68.3M | 37.75% | 0.9436 | 0.9367 | 0.9458 | 0.9381 | 1.84% | 3407.09 |\n",
      "\n",
      "\n",
      "Summary over ranks:\n",
      "r=2: val_acc=0.9373, test_acc=0.9382, avg_time/epoch=334.15s, converge_epoch=1, trainable=24612098 (36.6683%)\n",
      "r=4: val_acc=0.9375, test_acc=0.9382, avg_time/epoch=338.41s, converge_epoch=1, trainable=24777986 (36.8244%)\n",
      "r=8: val_acc=0.9363, test_acc=0.9387, avg_time/epoch=332.51s, converge_epoch=1, trainable=25109762 (37.1344%)\n",
      "r=16: val_acc=0.9367, test_acc=0.9381, avg_time/epoch=340.71s, converge_epoch=1, trainable=25773314 (37.7453%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Training HiRA on SST-2 with different ranks\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = []\n",
    "for r in [2, 4, 8, 16]:\n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"HiRA with rank r={r}\")\n",
    "    print(\"-\" * 30)\n",
    "    res = train_hira_model(\n",
    "        dataset_name=\"sst2\",\n",
    "        model_name=\"distilbert-base-uncased\",\n",
    "        r=r,\n",
    "        lora_alpha=32,\n",
    "        num_epochs=10,        \n",
    "        batch_size=16,\n",
    "        learning_rate=2e-5,  \n",
    "        warmup_steps=100,\n",
    "        max_length=128,\n",
    "        output_dir=\"./results_hira\",\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "generate_summary_table(results)\n",
    "\n",
    "print(\"\\nSummary over ranks:\")\n",
    "for res in results:\n",
    "    print(\n",
    "        f\"r={res['r']}: \"\n",
    "        f\"val_acc={res['best_val_acc']:.4f}, \"\n",
    "        f\"test_acc={res['test_acc']:.4f}, \"\n",
    "        f\"avg_time/epoch={res['avg_time_per_epoch']:.2f}s, \"\n",
    "        f\"converge_epoch={res['converge_epoch']}, \"\n",
    "        f\"trainable={res['trainable_params']} ({res['trainable_ratio']:.4f}%)\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879aeb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result Summary Table:\n",
      "\n",
      "| Rank | Trainable Params / Total | Ratio | Val F1 | Val Acc | Test F1 | Test Acc | Sparsity (<1e−3) | Train Time (s) |\n",
      "| ---- | ------------------------ | ----- | ------ | ------- | ------- | -------- | ----------------- | -------------- |\n",
      "| 1 | 25,109,762 / 67.6M | 37.13% | 0.9432 | 0.9363 | 0.9462 | 0.9387 | 1.79% | 3325.13 |\n",
      "| 2 | 24,612,098 / 67.1M | 36.67% | 0.9441 | 0.9373 | 0.9458 | 0.9382 | 1.74% | 3341.53 |\n",
      "| 3 | 24,777,986 / 67.3M | 36.82% | 0.9442 | 0.9375 | 0.9459 | 0.9382 | 1.76% | 3384.06 |\n",
      "| 4 | 25,773,314 / 68.3M | 37.75% | 0.9436 | 0.9367 | 0.9458 | 0.9381 | 1.84% | 3407.09 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_summary_table(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474a4925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training HiRA on SST-2 with different ranks\n",
      "==================================================\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=2\n",
      "------------------------------\n",
      "[imdb][r=2] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=2] Trainable params: 24,612,098 || All params: 67,120,898 || Trainable%: 36.6683%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:26<00:00, 749.97 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:03<00:00, 770.62 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:03<00:00, 758.20 examples/s]\n",
      "[imdb][r=2] Epoch 1/10: 100%|██████████| 1250/1250 [04:33<00:00,  4.58it/s, loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 1 | train_loss=0.4822 | val_acc=0.8212 | val_f1=0.8158 | time/epoch=299.35s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8212 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 2/10: 100%|██████████| 1250/1250 [06:04<00:00,  3.43it/s, loss=0.431] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 2 | train_loss=0.3514 | val_acc=0.8300 | val_f1=0.8266 | time/epoch=378.34s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8300 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 3/10: 100%|██████████| 1250/1250 [05:34<00:00,  3.73it/s, loss=0.652] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 3 | train_loss=0.3002 | val_acc=0.8372 | val_f1=0.8379 | time/epoch=350.08s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8372 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 4/10: 100%|██████████| 1250/1250 [04:59<00:00,  4.17it/s, loss=0.182] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 4 | train_loss=0.2598 | val_acc=0.8428 | val_f1=0.8411 | time/epoch=315.13s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8428 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 5/10: 100%|██████████| 1250/1250 [05:20<00:00,  3.90it/s, loss=0.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 5 | train_loss=0.2271 | val_acc=0.8472 | val_f1=0.8489 | time/epoch=335.56s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8472 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 6/10: 100%|██████████| 1250/1250 [05:15<00:00,  3.96it/s, loss=0.163] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 6 | train_loss=0.2013 | val_acc=0.8472 | val_f1=0.8470 | time/epoch=331.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 7/10: 100%|██████████| 1250/1250 [05:15<00:00,  3.96it/s, loss=0.119] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 7 | train_loss=0.1740 | val_acc=0.8452 | val_f1=0.8435 | time/epoch=330.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 8/10: 100%|██████████| 1250/1250 [05:11<00:00,  4.01it/s, loss=0.49]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 8 | train_loss=0.1591 | val_acc=0.8480 | val_f1=0.8475 | time/epoch=327.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 9/10: 100%|██████████| 1250/1250 [05:12<00:00,  4.00it/s, loss=0.432] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 9 | train_loss=0.1454 | val_acc=0.8504 | val_f1=0.8508 | time/epoch=327.03s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8504 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 10/10: 100%|██████████| 1250/1250 [05:17<00:00,  3.94it/s, loss=0.167] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 10 | train_loss=0.1406 | val_acc=0.8492 | val_f1=0.8513 | time/epoch=333.76s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8492 to ./results_hira/best_model_r2.pt\n",
      "[imdb][r=2] Training completed! best_val_acc=0.8492, avg_time/epoch=332.88s, converge_epoch=1, trainable_params=24612098, trainable_ratio=36.6683%\n",
      "[imdb][r=2] Final test accuracy: 0.8460, test_f1=0.8523\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=4\n",
      "------------------------------\n",
      "[imdb][r=4] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=4] Trainable params: 24,777,986 || All params: 67,286,786 || Trainable%: 36.8244%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 1/10: 100%|██████████| 1250/1250 [05:53<00:00,  3.53it/s, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 1 | train_loss=0.4814 | val_acc=0.8192 | val_f1=0.8167 | time/epoch=371.73s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8192 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 2/10: 100%|██████████| 1250/1250 [06:08<00:00,  3.39it/s, loss=0.383] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 2 | train_loss=0.3510 | val_acc=0.8328 | val_f1=0.8321 | time/epoch=386.08s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8328 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 3/10: 100%|██████████| 1250/1250 [06:05<00:00,  3.42it/s, loss=0.173] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 3 | train_loss=0.3018 | val_acc=0.8400 | val_f1=0.8403 | time/epoch=382.79s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8400 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 4/10: 100%|██████████| 1250/1250 [05:47<00:00,  3.59it/s, loss=0.311] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 4 | train_loss=0.2607 | val_acc=0.8392 | val_f1=0.8376 | time/epoch=364.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 5/10: 100%|██████████| 1250/1250 [05:29<00:00,  3.80it/s, loss=0.504] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 5 | train_loss=0.2266 | val_acc=0.8428 | val_f1=0.8424 | time/epoch=344.92s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8428 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 6/10: 100%|██████████| 1250/1250 [05:16<00:00,  3.95it/s, loss=0.131] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 6 | train_loss=0.1976 | val_acc=0.8412 | val_f1=0.8411 | time/epoch=332.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 7/10: 100%|██████████| 1250/1250 [05:24<00:00,  3.85it/s, loss=0.151] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 7 | train_loss=0.1764 | val_acc=0.8456 | val_f1=0.8468 | time/epoch=340.96s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8456 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 8/10: 100%|██████████| 1250/1250 [05:33<00:00,  3.75it/s, loss=0.166] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 8 | train_loss=0.1588 | val_acc=0.8460 | val_f1=0.8475 | time/epoch=349.01s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8460 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 9/10: 100%|██████████| 1250/1250 [05:28<00:00,  3.81it/s, loss=0.17]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 9 | train_loss=0.1462 | val_acc=0.8448 | val_f1=0.8459 | time/epoch=344.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 10/10: 100%|██████████| 1250/1250 [05:32<00:00,  3.76it/s, loss=0.0692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 10 | train_loss=0.1393 | val_acc=0.8444 | val_f1=0.8455 | time/epoch=348.89s\n",
      "[imdb][r=4] Training completed! best_val_acc=0.8460, avg_time/epoch=356.52s, converge_epoch=1, trainable_params=24777986, trainable_ratio=36.8244%\n",
      "[imdb][r=4] Final test accuracy: 0.8472, test_f1=0.8526\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=8\n",
      "------------------------------\n",
      "[imdb][r=8] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=8] Trainable params: 25,109,762 || All params: 67,618,562 || Trainable%: 37.1344%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 1/10: 100%|██████████| 1250/1250 [05:31<00:00,  3.77it/s, loss=0.361] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 1 | train_loss=0.4819 | val_acc=0.8172 | val_f1=0.8165 | time/epoch=346.88s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8172 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 2/10: 100%|██████████| 1250/1250 [05:22<00:00,  3.88it/s, loss=0.467] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 2 | train_loss=0.3487 | val_acc=0.8308 | val_f1=0.8314 | time/epoch=337.78s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8308 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 3/10: 100%|██████████| 1250/1250 [05:19<00:00,  3.92it/s, loss=0.344] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 3 | train_loss=0.2968 | val_acc=0.8360 | val_f1=0.8373 | time/epoch=334.93s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8360 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 4/10: 100%|██████████| 1250/1250 [05:19<00:00,  3.91it/s, loss=0.442] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 4 | train_loss=0.2576 | val_acc=0.8412 | val_f1=0.8434 | time/epoch=334.71s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8412 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 5/10: 100%|██████████| 1250/1250 [05:17<00:00,  3.93it/s, loss=0.346] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 5 | train_loss=0.2241 | val_acc=0.8420 | val_f1=0.8428 | time/epoch=333.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 6/10: 100%|██████████| 1250/1250 [05:21<00:00,  3.89it/s, loss=0.322] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 6 | train_loss=0.1944 | val_acc=0.8412 | val_f1=0.8430 | time/epoch=336.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 7/10: 100%|██████████| 1250/1250 [05:18<00:00,  3.93it/s, loss=0.0956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 7 | train_loss=0.1697 | val_acc=0.8400 | val_f1=0.8390 | time/epoch=333.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 8/10: 100%|██████████| 1250/1250 [05:16<00:00,  3.95it/s, loss=0.612] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 8 | train_loss=0.1567 | val_acc=0.8404 | val_f1=0.8403 | time/epoch=331.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 9/10: 100%|██████████| 1250/1250 [05:16<00:00,  3.95it/s, loss=0.251] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 9 | train_loss=0.1452 | val_acc=0.8416 | val_f1=0.8420 | time/epoch=330.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 10/10: 100%|██████████| 1250/1250 [28:57<00:00,  1.39s/it, loss=0.0934]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 10 | train_loss=0.1365 | val_acc=0.8416 | val_f1=0.8422 | time/epoch=264.35s\n",
      "[imdb][r=8] Training completed! best_val_acc=0.8412, avg_time/epoch=328.50s, converge_epoch=1, trainable_params=25109762, trainable_ratio=37.1344%\n",
      "[imdb][r=8] Final test accuracy: 0.8448, test_f1=0.8507\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=16\n",
      "------------------------------\n",
      "[imdb][r=16] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=16] Trainable params: 25,773,314 || All params: 68,282,114 || Trainable%: 37.7453%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 1/10: 100%|██████████| 1250/1250 [29:10<00:00,  1.40s/it, loss=0.552]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 1 | train_loss=0.4907 | val_acc=0.8228 | val_f1=0.8200 | time/epoch=256.82s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8228 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 2/10: 100%|██████████| 1250/1250 [45:04<00:00,  2.16s/it, loss=0.542]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 2 | train_loss=0.3496 | val_acc=0.8332 | val_f1=0.8343 | time/epoch=252.57s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8332 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 3/10: 100%|██████████| 1250/1250 [37:40<00:00,  1.81s/it, loss=0.198]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 3 | train_loss=0.2992 | val_acc=0.8396 | val_f1=0.8381 | time/epoch=255.30s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8396 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 4/10: 100%|██████████| 1250/1250 [57:42<00:00,  2.77s/it, loss=0.142]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 4 | train_loss=0.2591 | val_acc=0.8392 | val_f1=0.8370 | time/epoch=249.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 5/10: 100%|██████████| 1250/1250 [56:46<00:00,  2.73s/it, loss=0.307]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 5 | train_loss=0.2251 | val_acc=0.8448 | val_f1=0.8469 | time/epoch=251.03s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8448 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 6/10: 100%|██████████| 1250/1250 [31:53<00:00,  1.53s/it, loss=0.346]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 6 | train_loss=0.1971 | val_acc=0.8444 | val_f1=0.8467 | time/epoch=249.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 7/10: 100%|██████████| 1250/1250 [53:09<00:00,  2.55s/it, loss=0.0767]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 7 | train_loss=0.1712 | val_acc=0.8440 | val_f1=0.8466 | time/epoch=253.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 8/10: 100%|██████████| 1250/1250 [28:20<00:00,  1.36s/it, loss=0.361]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 8 | train_loss=0.1549 | val_acc=0.8432 | val_f1=0.8447 | time/epoch=253.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 9/10: 100%|██████████| 1250/1250 [1:00:30<00:00,  2.90s/it, loss=0.151]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 9 | train_loss=0.1439 | val_acc=0.8444 | val_f1=0.8457 | time/epoch=248.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 10/10: 100%|██████████| 1250/1250 [52:38<00:00,  2.53s/it, loss=0.289]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 10 | train_loss=0.1355 | val_acc=0.8448 | val_f1=0.8453 | time/epoch=248.98s\n",
      "[imdb][r=16] Training completed! best_val_acc=0.8448, avg_time/epoch=251.93s, converge_epoch=1, trainable_params=25773314, trainable_ratio=37.7453%\n",
      "[imdb][r=16] Final test accuracy: 0.8424, test_f1=0.8483\n",
      "\n",
      "Result Summary Table:\n",
      "\n",
      "| Rank | Trainable Params / Total | Ratio | Val F1 | Val Acc | Test F1 | Test Acc | Sparsity (<1e−3) | Train Time (s) |\n",
      "| ---- | ------------------------ | ----- | ------ | ------- | ------- | -------- | ----------------- | -------------- |\n",
      "| 1 | 24,777,986 / 67.3M | 36.82% | 0.8475 | 0.8460 | 0.8526 | 0.8472 | 1.77% | 3565.19 |\n",
      "| 2 | 24,612,098 / 67.1M | 36.67% | 0.8513 | 0.8492 | 0.8523 | 0.8460 | 1.75% | 3328.82 |\n",
      "| 3 | 25,109,762 / 67.6M | 37.13% | 0.8434 | 0.8412 | 0.8507 | 0.8448 | 1.80% | 3285.02 |\n",
      "| 4 | 25,773,314 / 68.3M | 37.75% | 0.8469 | 0.8448 | 0.8483 | 0.8424 | 1.88% | 2519.27 |\n",
      "\n",
      "\n",
      "Summary over ranks:\n",
      "r=2: val_acc=0.8492, test_acc=0.8460, avg_time/epoch=332.88s, converge_epoch=1, trainable=24612098 (36.6683%)\n",
      "r=4: val_acc=0.8460, test_acc=0.8472, avg_time/epoch=356.52s, converge_epoch=1, trainable=24777986 (36.8244%)\n",
      "r=8: val_acc=0.8412, test_acc=0.8448, avg_time/epoch=328.50s, converge_epoch=1, trainable=25109762 (37.1344%)\n",
      "r=16: val_acc=0.8448, test_acc=0.8424, avg_time/epoch=251.93s, converge_epoch=1, trainable=25773314 (37.7453%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Training HiRA on SST-2 with different ranks\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "imdb_results = []\n",
    "for r in [2, 4, 8, 16]:\n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"HiRA with rank r={r}\")\n",
    "    print(\"-\" * 30)\n",
    "    res = train_hira_model(\n",
    "        dataset_name=\"imdb\",\n",
    "        model_name=\"distilbert-base-uncased\",\n",
    "        r=r,\n",
    "        lora_alpha=32,\n",
    "        num_epochs=10,        \n",
    "        batch_size=16,\n",
    "        learning_rate=2e-5,  \n",
    "        warmup_steps=100,\n",
    "        max_length=128,\n",
    "        output_dir=\"./results_hira\",\n",
    "    )\n",
    "    imdb_results.append(res)\n",
    "\n",
    "generate_summary_table(imdb_results)\n",
    "\n",
    "print(\"\\nSummary over ranks:\")\n",
    "for res in imdb_results:\n",
    "    print(\n",
    "        f\"r={res['r']}: \"\n",
    "        f\"val_acc={res['best_val_acc']:.4f}, \"\n",
    "        f\"test_acc={res['test_acc']:.4f}, \"\n",
    "        f\"avg_time/epoch={res['avg_time_per_epoch']:.2f}s, \"\n",
    "        f\"converge_epoch={res['converge_epoch']}, \"\n",
    "        f\"trainable={res['trainable_params']} ({res['trainable_ratio']:.4f}%)\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02ab46",
   "metadata": {},
   "source": [
    "# Before changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b58115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "\n",
    "def train_hira_model(\n",
    "    dataset_name: str = \"sst2\",           \n",
    "    model_name: str = \"distilbert-base-uncased\",\n",
    "    r: int = 32,                        \n",
    "    lora_alpha: int = 32,\n",
    "    num_epochs: int = 10,              \n",
    "    batch_size: int = 16,\n",
    "    learning_rate: float = 1e-3,\n",
    "    warmup_steps: int = 100,\n",
    "    max_length: int = 128,\n",
    "    output_dir: str = \"./results_hira\",\n",
    "):\n",
    "\n",
    "    device = torch.device(\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"[{dataset_name}][r={r}] Using device: {device}\")\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    num_labels = 2\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "    )\n",
    "    model = apply_hira_to_model(model, r=r, lora_alpha=lora_alpha)\n",
    "    model = model.to(device)\n",
    "\n",
    "    trainable_params, all_params, percentage = get_trainable_parameters(model)\n",
    "    print(\n",
    "        f\"[{dataset_name}][r={r}] Trainable params: {trainable_params:,} || \"\n",
    "        f\"All params: {all_params:,} || Trainable%: {percentage:.4f}%\"\n",
    "    )\n",
    "\n",
    "    if dataset_name == \"sst2\":\n",
    "        dataset = load_sst2_data(tokenizer, max_length)\n",
    "    elif dataset_name == \"imdb\":\n",
    "        dataset = load_imdb_data(tokenizer, max_length)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset_name: {dataset_name}\")\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        dataset[\"validation\"],\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=learning_rate,\n",
    "    )\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    epoch_times = []\n",
    "    best_val_accuracy = 0.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_t = time.perf_counter()\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        progress_bar = tqdm(\n",
    "            train_dataloader,\n",
    "            desc=f\"[{dataset_name}][r={r}] Epoch {epoch + 1}/{num_epochs}\",\n",
    "        )\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        model.eval()\n",
    "        metric = evaluate.load(\"accuracy\")\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "        val_acc = metric.compute()[\"accuracy\"]\n",
    "\n",
    "        end_t = time.perf_counter()\n",
    "        epoch_time = end_t - start_t\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        print(\n",
    "            f\"[{dataset_name}][r={r}] Epoch {epoch + 1} | \"\n",
    "            f\"train_loss={avg_train_loss:.4f} | \"\n",
    "            f\"val_acc={val_acc:.4f} | \"\n",
    "            f\"time/epoch={epoch_time:.2f}s\"\n",
    "        )\n",
    "\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            if best_epoch == -1:\n",
    "                best_epoch = epoch + 1 \n",
    "\n",
    "            save_path = os.path.join(output_dir, f\"best_model_r{r}.pt\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"accuracy\": best_val_accuracy,\n",
    "                },\n",
    "                save_path,\n",
    "            )\n",
    "            print(\n",
    "                f\"[{dataset_name}][r={r}] Saved best model with \"\n",
    "                f\"val_acc={best_val_accuracy:.4f} to {save_path}\"\n",
    "            )\n",
    "\n",
    "    avg_time_per_epoch = sum(epoch_times) / len(epoch_times)\n",
    "    print(\n",
    "        f\"[{dataset_name}][r={r}] Training completed! \"\n",
    "        f\"best_val_acc={best_val_accuracy:.4f}, \"\n",
    "        f\"avg_time/epoch={avg_time_per_epoch:.2f}s, \"\n",
    "        f\"converge_epoch={best_epoch}, \"\n",
    "        f\"trainable_params={trainable_params}, \"\n",
    "        f\"trainable_ratio={percentage:.4f}%\"\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "    test_acc = metric.compute()[\"accuracy\"]\n",
    "    print(f\"[{dataset_name}][r={r}] Final test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"r\": r,\n",
    "        \"best_val_acc\": best_val_accuracy,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"avg_time_per_epoch\": avg_time_per_epoch,\n",
    "        \"converge_epoch\": best_epoch,\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"trainable_ratio\": percentage,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c4463b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training HiRA on SST-2 with different ranks\n",
      "==================================================\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=2\n",
      "------------------------------\n",
      "[sst2][r=2] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=2] Trainable params: 24,612,098 || All params: 67,120,898 || Trainable%: 36.6683%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 53879/53879 [00:04<00:00, 12149.05 examples/s]\n",
      "Map: 100%|██████████| 6734/6734 [00:00<00:00, 11892.88 examples/s]\n",
      "Map: 100%|██████████| 6736/6736 [00:00<00:00, 12082.25 examples/s]\n",
      "[sst2][r=2] Epoch 1/10: 100%|██████████| 3368/3368 [05:29<00:00, 10.23it/s, loss=0.106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 1 | train_loss=0.2740 | val_acc=0.9180 | time/epoch=353.79s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9180 to ./results_hira_sst2_r2/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 2/10: 100%|██████████| 3368/3368 [05:41<00:00,  9.86it/s, loss=0.0809] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 2 | train_loss=0.1318 | val_acc=0.9252 | time/epoch=358.61s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9252 to ./results_hira_sst2_r2/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 3/10: 100%|██████████| 3368/3368 [05:39<00:00,  9.93it/s, loss=0.00314] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 3 | train_loss=0.0769 | val_acc=0.9275 | time/epoch=357.89s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9275 to ./results_hira_sst2_r2/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 4/10: 100%|██████████| 3368/3368 [05:29<00:00, 10.23it/s, loss=0.0408]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 4 | train_loss=0.0452 | val_acc=0.9275 | time/epoch=346.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 5/10: 100%|██████████| 3368/3368 [05:28<00:00, 10.25it/s, loss=2.57e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 5 | train_loss=0.0282 | val_acc=0.9298 | time/epoch=345.83s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9298 to ./results_hira_sst2_r2/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 6/10: 100%|██████████| 3368/3368 [05:30<00:00, 10.18it/s, loss=0.000182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 6 | train_loss=0.0180 | val_acc=0.9302 | time/epoch=348.16s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9302 to ./results_hira_sst2_r2/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 7/10: 100%|██████████| 3368/3368 [05:30<00:00, 10.19it/s, loss=0.000142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 7 | train_loss=0.0112 | val_acc=0.9289 | time/epoch=347.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 8/10: 100%|██████████| 3368/3368 [05:39<00:00,  9.92it/s, loss=0.000101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 8 | train_loss=0.0061 | val_acc=0.9308 | time/epoch=357.74s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9308 to ./results_hira_sst2_r2/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 9/10: 100%|██████████| 3368/3368 [05:44<00:00,  9.79it/s, loss=3.44e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 9 | train_loss=0.0047 | val_acc=0.9308 | time/epoch=362.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 10/10: 100%|██████████| 3368/3368 [05:44<00:00,  9.79it/s, loss=1.7e-8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=2] Epoch 10 | train_loss=0.0029 | val_acc=0.9317 | time/epoch=362.18s\n",
      "[sst2][r=2] Saved best model with val_acc=0.9317 to ./results_hira_sst2_r2/best_model_r2.pt\n",
      "[sst2][r=2] Training completed! best_val_acc=0.9317, avg_time/epoch=354.09s, converge_epoch=1, trainable_params=24612098, trainable_ratio=36.6683%\n",
      "[sst2][r=2] Final test accuracy: 0.9314\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=4\n",
      "------------------------------\n",
      "[sst2][r=4] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=4] Trainable params: 24,777,986 || All params: 67,286,786 || Trainable%: 36.8244%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 1/10: 100%|██████████| 3368/3368 [05:42<00:00,  9.83it/s, loss=0.278] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 1 | train_loss=0.2755 | val_acc=0.9208 | time/epoch=360.97s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9208 to ./results_hira_sst2_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 2/10: 100%|██████████| 3368/3368 [05:48<00:00,  9.67it/s, loss=0.0178] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 2 | train_loss=0.1334 | val_acc=0.9287 | time/epoch=366.02s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9287 to ./results_hira_sst2_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 3/10: 100%|██████████| 3368/3368 [05:47<00:00,  9.70it/s, loss=0.667]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 3 | train_loss=0.0809 | val_acc=0.9253 | time/epoch=364.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 4/10: 100%|██████████| 3368/3368 [05:59<00:00,  9.37it/s, loss=0.0154]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 4 | train_loss=0.0478 | val_acc=0.9278 | time/epoch=376.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 5/10: 100%|██████████| 3368/3368 [05:50<00:00,  9.60it/s, loss=0.00536] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 5 | train_loss=0.0288 | val_acc=0.9299 | time/epoch=369.61s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9299 to ./results_hira_sst2_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 6/10: 100%|██████████| 3368/3368 [06:11<00:00,  9.07it/s, loss=0.00525] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 6 | train_loss=0.0183 | val_acc=0.9308 | time/epoch=389.24s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9308 to ./results_hira_sst2_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 7/10: 100%|██████████| 3368/3368 [05:56<00:00,  9.45it/s, loss=1.59e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 7 | train_loss=0.0105 | val_acc=0.9320 | time/epoch=373.95s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9320 to ./results_hira_sst2_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 8/10: 100%|██████████| 3368/3368 [05:47<00:00,  9.68it/s, loss=0.644]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 8 | train_loss=0.0070 | val_acc=0.9326 | time/epoch=365.87s\n",
      "[sst2][r=4] Saved best model with val_acc=0.9326 to ./results_hira_sst2_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 9/10: 100%|██████████| 3368/3368 [05:39<00:00,  9.91it/s, loss=2.09e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 9 | train_loss=0.0051 | val_acc=0.9307 | time/epoch=358.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 10/10: 100%|██████████| 3368/3368 [05:51<00:00,  9.59it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=4] Epoch 10 | train_loss=0.0032 | val_acc=0.9318 | time/epoch=371.67s\n",
      "[sst2][r=4] Training completed! best_val_acc=0.9326, avg_time/epoch=369.75s, converge_epoch=1, trainable_params=24777986, trainable_ratio=36.8244%\n",
      "[sst2][r=4] Final test accuracy: 0.9317\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=8\n",
      "------------------------------\n",
      "[sst2][r=8] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=8] Trainable params: 25,109,762 || All params: 67,618,562 || Trainable%: 37.1344%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 1/10: 100%|██████████| 3368/3368 [05:53<00:00,  9.54it/s, loss=0.015] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 1 | train_loss=0.2795 | val_acc=0.9182 | time/epoch=371.01s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9182 to ./results_hira_sst2_r8/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 2/10: 100%|██████████| 3368/3368 [05:52<00:00,  9.56it/s, loss=0.0939] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 2 | train_loss=0.1370 | val_acc=0.9311 | time/epoch=370.40s\n",
      "[sst2][r=8] Saved best model with val_acc=0.9311 to ./results_hira_sst2_r8/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 3/10: 100%|██████████| 3368/3368 [05:50<00:00,  9.61it/s, loss=0.000691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 3 | train_loss=0.0794 | val_acc=0.9263 | time/epoch=368.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 4/10: 100%|██████████| 3368/3368 [05:51<00:00,  9.59it/s, loss=0.00608] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 4 | train_loss=0.0473 | val_acc=0.9283 | time/epoch=369.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 5/10: 100%|██████████| 3368/3368 [05:47<00:00,  9.69it/s, loss=0.0308]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 5 | train_loss=0.0297 | val_acc=0.9269 | time/epoch=365.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 6/10: 100%|██████████| 3368/3368 [05:50<00:00,  9.60it/s, loss=0.154]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 6 | train_loss=0.0180 | val_acc=0.9281 | time/epoch=369.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 7/10: 100%|██████████| 3368/3368 [05:50<00:00,  9.62it/s, loss=1.22e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 7 | train_loss=0.0120 | val_acc=0.9274 | time/epoch=368.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 8/10: 100%|██████████| 3368/3368 [06:00<00:00,  9.35it/s, loss=0.00605] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 8 | train_loss=0.0065 | val_acc=0.9296 | time/epoch=378.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 9/10: 100%|██████████| 3368/3368 [05:55<00:00,  9.47it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 9 | train_loss=0.0045 | val_acc=0.9296 | time/epoch=373.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 10/10: 100%|██████████| 3368/3368 [05:54<00:00,  9.50it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=8] Epoch 10 | train_loss=0.0034 | val_acc=0.9289 | time/epoch=372.78s\n",
      "[sst2][r=8] Training completed! best_val_acc=0.9311, avg_time/epoch=370.70s, converge_epoch=1, trainable_params=25109762, trainable_ratio=37.1344%\n",
      "[sst2][r=8] Final test accuracy: 0.9348\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=16\n",
      "------------------------------\n",
      "[sst2][r=16] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[sst2][r=16] Trainable params: 25,773,314 || All params: 68,282,114 || Trainable%: 37.7453%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 1/10: 100%|██████████| 3368/3368 [05:53<00:00,  9.54it/s, loss=0.116] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 1 | train_loss=0.2743 | val_acc=0.9214 | time/epoch=371.52s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9214 to ./results_hira_sst2_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 2/10: 100%|██████████| 3368/3368 [05:45<00:00,  9.75it/s, loss=0.0526]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 2 | train_loss=0.1329 | val_acc=0.9246 | time/epoch=363.69s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9246 to ./results_hira_sst2_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 3/10: 100%|██████████| 3368/3368 [05:51<00:00,  9.57it/s, loss=0.0117]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 3 | train_loss=0.0775 | val_acc=0.9298 | time/epoch=369.64s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9298 to ./results_hira_sst2_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 4/10: 100%|██████████| 3368/3368 [05:58<00:00,  9.40it/s, loss=0.00043] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 4 | train_loss=0.0456 | val_acc=0.9299 | time/epoch=377.20s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9299 to ./results_hira_sst2_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 5/10: 100%|██████████| 3368/3368 [05:56<00:00,  9.44it/s, loss=4.45e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 5 | train_loss=0.0278 | val_acc=0.9305 | time/epoch=375.78s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9305 to ./results_hira_sst2_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 6/10: 100%|██████████| 3368/3368 [06:08<00:00,  9.14it/s, loss=0.0781]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 6 | train_loss=0.0170 | val_acc=0.9307 | time/epoch=388.21s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9307 to ./results_hira_sst2_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 7/10: 100%|██████████| 3368/3368 [06:20<00:00,  8.86it/s, loss=3.58e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 7 | train_loss=0.0114 | val_acc=0.9295 | time/epoch=399.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 8/10: 100%|██████████| 3368/3368 [06:18<00:00,  8.90it/s, loss=0.0324]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 8 | train_loss=0.0063 | val_acc=0.9315 | time/epoch=398.23s\n",
      "[sst2][r=16] Saved best model with val_acc=0.9315 to ./results_hira_sst2_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 9/10: 100%|██████████| 3368/3368 [06:18<00:00,  8.89it/s, loss=0.00283] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 9 | train_loss=0.0047 | val_acc=0.9307 | time/epoch=398.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 10/10: 100%|██████████| 3368/3368 [06:17<00:00,  8.93it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sst2][r=16] Epoch 10 | train_loss=0.0028 | val_acc=0.9311 | time/epoch=396.70s\n",
      "[sst2][r=16] Training completed! best_val_acc=0.9315, avg_time/epoch=383.89s, converge_epoch=1, trainable_params=25773314, trainable_ratio=37.7453%\n",
      "[sst2][r=16] Final test accuracy: 0.9313\n",
      "\n",
      "Summary over ranks:\n",
      "r=2: val_acc=0.9317, test_acc=0.9314, avg_time/epoch=354.09s, converge_epoch=1, trainable=24612098 (36.6683%)\n",
      "r=4: val_acc=0.9326, test_acc=0.9317, avg_time/epoch=369.75s, converge_epoch=1, trainable=24777986 (36.8244%)\n",
      "r=8: val_acc=0.9311, test_acc=0.9348, avg_time/epoch=370.70s, converge_epoch=1, trainable=25109762 (37.1344%)\n",
      "r=16: val_acc=0.9315, test_acc=0.9313, avg_time/epoch=383.89s, converge_epoch=1, trainable=25773314 (37.7453%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Training HiRA on SST-2 with different ranks\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = []\n",
    "for r in [2, 4, 8, 16]:\n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"HiRA with rank r={r}\")\n",
    "    print(\"-\" * 30)\n",
    "    res = train_hira_model(\n",
    "        dataset_name='sst2',\n",
    "        r=r,\n",
    "        num_epochs=10,\n",
    "        batch_size=16,\n",
    "        learning_rate=1e-3,\n",
    "        max_length=128,\n",
    "        output_dir=f'./results_hira_sst2_r{r}',\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "print(\"\\nSummary over ranks:\")\n",
    "for res in results:\n",
    "    print(\n",
    "        f\"r={res['r']}: \"\n",
    "        f\"val_acc={res['best_val_acc']:.4f}, \"\n",
    "        f\"test_acc={res['test_acc']:.4f}, \"\n",
    "        f\"avg_time/epoch={res['avg_time_per_epoch']:.2f}s, \"\n",
    "        f\"converge_epoch={res['converge_epoch']}, \"\n",
    "        f\"trainable={res['trainable_params']} ({res['trainable_ratio']:.4f}%)\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57c27712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=2] Trainable params: 24,612,098 || All params: 67,120,898 || Trainable%: 36.6683%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:27<00:00, 740.22 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:03<00:00, 699.49 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:03<00:00, 682.79 examples/s]\n",
      "[imdb][r=2] Epoch 1/10: 100%|██████████| 2500/2500 [11:02<00:00,  3.77it/s, loss=0.441]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 1 | train_loss=0.3759 | val_acc=0.8572 | time/epoch=690.73s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8572 to ./results_hira_imdb_r2/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 2/10: 100%|██████████| 2500/2500 [10:58<00:00,  3.79it/s, loss=0.211]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 2 | train_loss=0.1880 | val_acc=0.8400 | time/epoch=690.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 3/10: 100%|██████████| 2500/2500 [10:46<00:00,  3.87it/s, loss=0.0151]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 3 | train_loss=0.0668 | val_acc=0.8476 | time/epoch=676.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 4/10: 100%|██████████| 2500/2500 [10:57<00:00,  3.80it/s, loss=0.0379]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 4 | train_loss=0.0277 | val_acc=0.8464 | time/epoch=687.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 5/10: 100%|██████████| 2500/2500 [11:14<00:00,  3.71it/s, loss=0.0274]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 5 | train_loss=0.0136 | val_acc=0.8468 | time/epoch=706.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 6/10: 100%|██████████| 2500/2500 [11:22<00:00,  3.67it/s, loss=1.91e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 6 | train_loss=0.0057 | val_acc=0.8472 | time/epoch=713.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 7/10: 100%|██████████| 2500/2500 [10:59<00:00,  3.79it/s, loss=3.13e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 7 | train_loss=0.0030 | val_acc=0.8476 | time/epoch=690.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 8/10: 100%|██████████| 2500/2500 [10:55<00:00,  3.82it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 8 | train_loss=0.0008 | val_acc=0.8496 | time/epoch=685.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 9/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.84it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 9 | train_loss=0.0002 | val_acc=0.8484 | time/epoch=681.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 10/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.84it/s, loss=2.98e-8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 10 | train_loss=0.0000 | val_acc=0.8496 | time/epoch=680.70s\n",
      "[imdb][r=2] Training completed! best_val_acc=0.8572, avg_time/epoch=690.27s, converge_epoch=1, trainable_params=24612098, trainable_ratio=36.6683%\n",
      "[imdb][r=2] Final test accuracy: 0.8572\n",
      "[imdb][r=4] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=4] Trainable params: 24,777,986 || All params: 67,286,786 || Trainable%: 36.8244%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 1/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.85it/s, loss=0.261]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 1 | train_loss=0.3785 | val_acc=0.8560 | time/epoch=680.38s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8560 to ./results_hira_imdb_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 2/10: 100%|██████████| 2500/2500 [10:49<00:00,  3.85it/s, loss=0.28]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 2 | train_loss=0.1879 | val_acc=0.8544 | time/epoch=680.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 3/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.84it/s, loss=0.000566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 3 | train_loss=0.0686 | val_acc=0.8580 | time/epoch=681.21s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8580 to ./results_hira_imdb_r4/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 4/10: 100%|██████████| 2500/2500 [10:49<00:00,  3.85it/s, loss=0.000998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 4 | train_loss=0.0296 | val_acc=0.8532 | time/epoch=680.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 5/10: 100%|██████████| 2500/2500 [10:51<00:00,  3.84it/s, loss=0.000314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 5 | train_loss=0.0137 | val_acc=0.8504 | time/epoch=681.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 6/10: 100%|██████████| 2500/2500 [10:48<00:00,  3.85it/s, loss=0.000556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 6 | train_loss=0.0068 | val_acc=0.8468 | time/epoch=678.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 7/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.84it/s, loss=0.0064]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 7 | train_loss=0.0036 | val_acc=0.8480 | time/epoch=681.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 8/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.84it/s, loss=4.47e-8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 8 | train_loss=0.0008 | val_acc=0.8540 | time/epoch=681.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 9/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.85it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 9 | train_loss=0.0000 | val_acc=0.8548 | time/epoch=680.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 10/10: 100%|██████████| 2500/2500 [10:51<00:00,  3.83it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 10 | train_loss=0.0000 | val_acc=0.8544 | time/epoch=682.23s\n",
      "[imdb][r=4] Training completed! best_val_acc=0.8580, avg_time/epoch=680.82s, converge_epoch=1, trainable_params=24777986, trainable_ratio=36.8244%\n",
      "[imdb][r=4] Final test accuracy: 0.8604\n",
      "[imdb][r=8] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=8] Trainable params: 25,109,762 || All params: 67,618,562 || Trainable%: 37.1344%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 1/10: 100%|██████████| 2500/2500 [10:50<00:00,  3.84it/s, loss=0.813] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 1 | train_loss=0.3872 | val_acc=0.8640 | time/epoch=681.09s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8640 to ./results_hira_imdb_r8/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 2/10: 100%|██████████| 2500/2500 [10:51<00:00,  3.84it/s, loss=0.456]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 2 | train_loss=0.1892 | val_acc=0.8560 | time/epoch=681.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 3/10: 100%|██████████| 2500/2500 [10:51<00:00,  3.84it/s, loss=0.329]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 3 | train_loss=0.0687 | val_acc=0.8484 | time/epoch=685.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 4/10: 100%|██████████| 2500/2500 [10:48<00:00,  3.85it/s, loss=0.000294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 4 | train_loss=0.0280 | val_acc=0.8424 | time/epoch=678.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 5/10: 100%|██████████| 2500/2500 [10:49<00:00,  3.85it/s, loss=0.000146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 5 | train_loss=0.0154 | val_acc=0.8424 | time/epoch=679.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 6/10: 100%|██████████| 2500/2500 [10:48<00:00,  3.86it/s, loss=1.8e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 6 | train_loss=0.0071 | val_acc=0.8428 | time/epoch=677.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 7/10: 100%|██████████| 2500/2500 [10:51<00:00,  3.84it/s, loss=1.68e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 7 | train_loss=0.0027 | val_acc=0.8480 | time/epoch=681.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 8/10: 100%|██████████| 2500/2500 [10:47<00:00,  3.86it/s, loss=2.98e-8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 8 | train_loss=0.0010 | val_acc=0.8384 | time/epoch=677.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 9/10: 100%|██████████| 2500/2500 [10:55<00:00,  3.82it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 9 | train_loss=0.0002 | val_acc=0.8440 | time/epoch=686.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 10/10: 100%|██████████| 2500/2500 [10:57<00:00,  3.80it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 10 | train_loss=0.0000 | val_acc=0.8444 | time/epoch=687.36s\n",
      "[imdb][r=8] Training completed! best_val_acc=0.8640, avg_time/epoch=681.78s, converge_epoch=1, trainable_params=25109762, trainable_ratio=37.1344%\n",
      "[imdb][r=8] Final test accuracy: 0.8552\n",
      "[imdb][r=16] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=16] Trainable params: 25,773,314 || All params: 68,282,114 || Trainable%: 37.7453%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 1/10: 100%|██████████| 2500/2500 [10:51<00:00,  3.84it/s, loss=0.101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 1 | train_loss=0.3840 | val_acc=0.8572 | time/epoch=681.52s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8572 to ./results_hira_imdb_r16/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 2/10: 100%|██████████| 2500/2500 [10:54<00:00,  3.82it/s, loss=0.117]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 2 | train_loss=0.1917 | val_acc=0.8540 | time/epoch=685.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 3/10: 100%|██████████| 2500/2500 [11:13<00:00,  3.71it/s, loss=0.264]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 3 | train_loss=0.0736 | val_acc=0.8392 | time/epoch=704.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 4/10: 100%|██████████| 2500/2500 [11:47<00:00,  3.53it/s, loss=0.428]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 4 | train_loss=0.0334 | val_acc=0.8264 | time/epoch=742.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 5/10: 100%|██████████| 2500/2500 [12:08<00:00,  3.43it/s, loss=0.00231] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 5 | train_loss=0.0131 | val_acc=0.8376 | time/epoch=766.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 6/10: 100%|██████████| 2500/2500 [12:20<00:00,  3.38it/s, loss=1.28e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 6 | train_loss=0.0066 | val_acc=0.8432 | time/epoch=774.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 7/10: 100%|██████████| 2500/2500 [12:02<00:00,  3.46it/s, loss=0.000275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 7 | train_loss=0.0040 | val_acc=0.8424 | time/epoch=755.74s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 8/10: 100%|██████████| 2500/2500 [11:53<00:00,  3.50it/s, loss=1.01e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 8 | train_loss=0.0012 | val_acc=0.8464 | time/epoch=745.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 9/10: 100%|██████████| 2500/2500 [12:25<00:00,  3.35it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 9 | train_loss=0.0000 | val_acc=0.8436 | time/epoch=778.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 10/10: 100%|██████████| 2500/2500 [11:52<00:00,  3.51it/s, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 10 | train_loss=0.0000 | val_acc=0.8436 | time/epoch=744.97s\n",
      "[imdb][r=16] Training completed! best_val_acc=0.8572, avg_time/epoch=737.97s, converge_epoch=1, trainable_params=25773314, trainable_ratio=37.7453%\n",
      "[imdb][r=16] Final test accuracy: 0.8504\n"
     ]
    }
   ],
   "source": [
    "for r in [2, 4, 8, 16]:\n",
    "    res = train_hira_model(\n",
    "        dataset_name=\"imdb\",\n",
    "        r=r,\n",
    "        num_epochs=10,\n",
    "        batch_size=8,\n",
    "        learning_rate=1e-3,\n",
    "        max_length=256,\n",
    "        output_dir=f\"./results_hira_imdb_r{r}\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b1e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

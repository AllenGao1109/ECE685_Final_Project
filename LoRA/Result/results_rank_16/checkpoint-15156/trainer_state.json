{
  "best_global_step": 15156,
  "best_metric": 0.9087952297059222,
  "best_model_checkpoint": "./results_rank_16/checkpoint-15156",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 15156,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 1.2852286100387573,
      "learning_rate": 1.988242280285036e-05,
      "loss": 0.6709,
      "step": 100
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 1.4687893390655518,
      "learning_rate": 1.9763657957244657e-05,
      "loss": 0.5064,
      "step": 200
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 3.000901937484741,
      "learning_rate": 1.9644893111638956e-05,
      "loss": 0.3288,
      "step": 300
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 1.0449343919754028,
      "learning_rate": 1.9526128266033254e-05,
      "loss": 0.3666,
      "step": 400
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 2.2960565090179443,
      "learning_rate": 1.9407363420427553e-05,
      "loss": 0.3243,
      "step": 500
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 1.177711009979248,
      "learning_rate": 1.9288598574821855e-05,
      "loss": 0.3347,
      "step": 600
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 1.5318046808242798,
      "learning_rate": 1.9169833729216154e-05,
      "loss": 0.3306,
      "step": 700
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 4.195043563842773,
      "learning_rate": 1.9051068883610453e-05,
      "loss": 0.3229,
      "step": 800
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 3.2872872352600098,
      "learning_rate": 1.893230403800475e-05,
      "loss": 0.3226,
      "step": 900
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 1.5544564723968506,
      "learning_rate": 1.881353919239905e-05,
      "loss": 0.3277,
      "step": 1000
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 2.5765304565429688,
      "learning_rate": 1.8694774346793352e-05,
      "loss": 0.3125,
      "step": 1100
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.042160153388977,
      "learning_rate": 1.857600950118765e-05,
      "loss": 0.3065,
      "step": 1200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 1.7116118669509888,
      "learning_rate": 1.845724465558195e-05,
      "loss": 0.3084,
      "step": 1300
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 1.6189018487930298,
      "learning_rate": 1.833847980997625e-05,
      "loss": 0.3055,
      "step": 1400
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 1.2151750326156616,
      "learning_rate": 1.8219714964370547e-05,
      "loss": 0.3127,
      "step": 1500
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.3112220764160156,
      "learning_rate": 1.8100950118764846e-05,
      "loss": 0.3197,
      "step": 1600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8758538758538759,
      "eval_f1": 0.8854794520547945,
      "eval_loss": 0.2962208390235901,
      "eval_runtime": 13.9984,
      "eval_samples_per_second": 481.056,
      "eval_steps_per_second": 15.073,
      "step": 1684
    },
    {
      "epoch": 1.009501187648456,
      "grad_norm": 2.0319035053253174,
      "learning_rate": 1.7982185273159148e-05,
      "loss": 0.2977,
      "step": 1700
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 3.0259718894958496,
      "learning_rate": 1.7863420427553447e-05,
      "loss": 0.3016,
      "step": 1800
    },
    {
      "epoch": 1.1282660332541568,
      "grad_norm": 2.271240234375,
      "learning_rate": 1.7744655581947745e-05,
      "loss": 0.2756,
      "step": 1900
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.570483684539795,
      "learning_rate": 1.7625890736342044e-05,
      "loss": 0.2919,
      "step": 2000
    },
    {
      "epoch": 1.2470308788598574,
      "grad_norm": 1.3244187831878662,
      "learning_rate": 1.7507125890736343e-05,
      "loss": 0.2858,
      "step": 2100
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 3.6426749229431152,
      "learning_rate": 1.738836104513064e-05,
      "loss": 0.2836,
      "step": 2200
    },
    {
      "epoch": 1.365795724465558,
      "grad_norm": 1.1052429676055908,
      "learning_rate": 1.7269596199524944e-05,
      "loss": 0.2854,
      "step": 2300
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 1.7136690616607666,
      "learning_rate": 1.7150831353919242e-05,
      "loss": 0.283,
      "step": 2400
    },
    {
      "epoch": 1.484560570071259,
      "grad_norm": 0.734663188457489,
      "learning_rate": 1.703206650831354e-05,
      "loss": 0.2827,
      "step": 2500
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 1.8040589094161987,
      "learning_rate": 1.691330166270784e-05,
      "loss": 0.3137,
      "step": 2600
    },
    {
      "epoch": 1.6033254156769596,
      "grad_norm": 2.4365689754486084,
      "learning_rate": 1.679453681710214e-05,
      "loss": 0.3012,
      "step": 2700
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 2.173704147338867,
      "learning_rate": 1.667577197149644e-05,
      "loss": 0.2938,
      "step": 2800
    },
    {
      "epoch": 1.7220902612826603,
      "grad_norm": 2.221111536026001,
      "learning_rate": 1.655700712589074e-05,
      "loss": 0.2806,
      "step": 2900
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 1.914533257484436,
      "learning_rate": 1.6438242280285038e-05,
      "loss": 0.2849,
      "step": 3000
    },
    {
      "epoch": 1.8408551068883612,
      "grad_norm": 3.0332674980163574,
      "learning_rate": 1.6319477434679337e-05,
      "loss": 0.2823,
      "step": 3100
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 2.4283394813537598,
      "learning_rate": 1.6200712589073636e-05,
      "loss": 0.2746,
      "step": 3200
    },
    {
      "epoch": 1.9596199524940618,
      "grad_norm": 3.151242256164551,
      "learning_rate": 1.6081947743467934e-05,
      "loss": 0.2866,
      "step": 3300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8841698841698842,
      "eval_f1": 0.8946799891979476,
      "eval_loss": 0.27993905544281006,
      "eval_runtime": 13.3497,
      "eval_samples_per_second": 504.431,
      "eval_steps_per_second": 15.806,
      "step": 3368
    },
    {
      "epoch": 2.019002375296912,
      "grad_norm": 2.0808329582214355,
      "learning_rate": 1.5963182897862236e-05,
      "loss": 0.2783,
      "step": 3400
    },
    {
      "epoch": 2.0783847980997625,
      "grad_norm": 3.5001256465911865,
      "learning_rate": 1.5844418052256535e-05,
      "loss": 0.2702,
      "step": 3500
    },
    {
      "epoch": 2.137767220902613,
      "grad_norm": 1.6706019639968872,
      "learning_rate": 1.5725653206650834e-05,
      "loss": 0.2929,
      "step": 3600
    },
    {
      "epoch": 2.197149643705463,
      "grad_norm": 2.0768227577209473,
      "learning_rate": 1.5606888361045133e-05,
      "loss": 0.2717,
      "step": 3700
    },
    {
      "epoch": 2.2565320665083135,
      "grad_norm": 1.7173612117767334,
      "learning_rate": 1.548812351543943e-05,
      "loss": 0.2724,
      "step": 3800
    },
    {
      "epoch": 2.315914489311164,
      "grad_norm": 1.6447395086288452,
      "learning_rate": 1.536935866983373e-05,
      "loss": 0.2866,
      "step": 3900
    },
    {
      "epoch": 2.375296912114014,
      "grad_norm": 1.4265400171279907,
      "learning_rate": 1.525059382422803e-05,
      "loss": 0.2693,
      "step": 4000
    },
    {
      "epoch": 2.4346793349168645,
      "grad_norm": 1.9899415969848633,
      "learning_rate": 1.5131828978622329e-05,
      "loss": 0.2754,
      "step": 4100
    },
    {
      "epoch": 2.494061757719715,
      "grad_norm": 1.5498954057693481,
      "learning_rate": 1.5013064133016628e-05,
      "loss": 0.2544,
      "step": 4200
    },
    {
      "epoch": 2.553444180522565,
      "grad_norm": 3.3616511821746826,
      "learning_rate": 1.4894299287410927e-05,
      "loss": 0.2597,
      "step": 4300
    },
    {
      "epoch": 2.6128266033254155,
      "grad_norm": 1.3870123624801636,
      "learning_rate": 1.4775534441805225e-05,
      "loss": 0.2809,
      "step": 4400
    },
    {
      "epoch": 2.6722090261282663,
      "grad_norm": 0.8114429116249084,
      "learning_rate": 1.4656769596199527e-05,
      "loss": 0.2605,
      "step": 4500
    },
    {
      "epoch": 2.731591448931116,
      "grad_norm": 3.1857659816741943,
      "learning_rate": 1.4538004750593826e-05,
      "loss": 0.2803,
      "step": 4600
    },
    {
      "epoch": 2.790973871733967,
      "grad_norm": 2.443141222000122,
      "learning_rate": 1.4419239904988125e-05,
      "loss": 0.2675,
      "step": 4700
    },
    {
      "epoch": 2.850356294536817,
      "grad_norm": 2.1868462562561035,
      "learning_rate": 1.4300475059382423e-05,
      "loss": 0.2621,
      "step": 4800
    },
    {
      "epoch": 2.9097387173396676,
      "grad_norm": 1.7721885442733765,
      "learning_rate": 1.4181710213776722e-05,
      "loss": 0.2608,
      "step": 4900
    },
    {
      "epoch": 2.969121140142518,
      "grad_norm": 2.250072717666626,
      "learning_rate": 1.4062945368171021e-05,
      "loss": 0.2859,
      "step": 5000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.888921888921889,
      "eval_f1": 0.8999197217018999,
      "eval_loss": 0.2749022841453552,
      "eval_runtime": 13.4458,
      "eval_samples_per_second": 500.824,
      "eval_steps_per_second": 15.693,
      "step": 5052
    },
    {
      "epoch": 3.0285035629453683,
      "grad_norm": 1.432992935180664,
      "learning_rate": 1.3944180522565323e-05,
      "loss": 0.2444,
      "step": 5100
    },
    {
      "epoch": 3.0878859857482186,
      "grad_norm": 2.1528892517089844,
      "learning_rate": 1.3825415676959622e-05,
      "loss": 0.264,
      "step": 5200
    },
    {
      "epoch": 3.147268408551069,
      "grad_norm": 3.5012505054473877,
      "learning_rate": 1.370665083135392e-05,
      "loss": 0.2601,
      "step": 5300
    },
    {
      "epoch": 3.2066508313539193,
      "grad_norm": 1.3416465520858765,
      "learning_rate": 1.358788598574822e-05,
      "loss": 0.2677,
      "step": 5400
    },
    {
      "epoch": 3.2660332541567696,
      "grad_norm": 0.9432293176651001,
      "learning_rate": 1.3469121140142518e-05,
      "loss": 0.2675,
      "step": 5500
    },
    {
      "epoch": 3.32541567695962,
      "grad_norm": 2.726430892944336,
      "learning_rate": 1.335035629453682e-05,
      "loss": 0.2564,
      "step": 5600
    },
    {
      "epoch": 3.3847980997624703,
      "grad_norm": 2.339442253112793,
      "learning_rate": 1.3231591448931119e-05,
      "loss": 0.2613,
      "step": 5700
    },
    {
      "epoch": 3.4441805225653206,
      "grad_norm": 2.0080440044403076,
      "learning_rate": 1.3112826603325417e-05,
      "loss": 0.2854,
      "step": 5800
    },
    {
      "epoch": 3.503562945368171,
      "grad_norm": 2.674633502960205,
      "learning_rate": 1.2994061757719716e-05,
      "loss": 0.241,
      "step": 5900
    },
    {
      "epoch": 3.5629453681710213,
      "grad_norm": 1.7380913496017456,
      "learning_rate": 1.2875296912114015e-05,
      "loss": 0.247,
      "step": 6000
    },
    {
      "epoch": 3.6223277909738716,
      "grad_norm": 1.3725155591964722,
      "learning_rate": 1.2756532066508314e-05,
      "loss": 0.2648,
      "step": 6100
    },
    {
      "epoch": 3.6817102137767224,
      "grad_norm": 3.083360195159912,
      "learning_rate": 1.2637767220902614e-05,
      "loss": 0.2651,
      "step": 6200
    },
    {
      "epoch": 3.7410926365795723,
      "grad_norm": 1.9859439134597778,
      "learning_rate": 1.2519002375296914e-05,
      "loss": 0.2575,
      "step": 6300
    },
    {
      "epoch": 3.800475059382423,
      "grad_norm": 1.0567331314086914,
      "learning_rate": 1.2400237529691213e-05,
      "loss": 0.2546,
      "step": 6400
    },
    {
      "epoch": 3.859857482185273,
      "grad_norm": 1.8889026641845703,
      "learning_rate": 1.2281472684085512e-05,
      "loss": 0.2724,
      "step": 6500
    },
    {
      "epoch": 3.9192399049881237,
      "grad_norm": 2.1978678703308105,
      "learning_rate": 1.216270783847981e-05,
      "loss": 0.2641,
      "step": 6600
    },
    {
      "epoch": 3.978622327790974,
      "grad_norm": 1.4914599657058716,
      "learning_rate": 1.204394299287411e-05,
      "loss": 0.2399,
      "step": 6700
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8915948915948916,
      "eval_f1": 0.9018289402904788,
      "eval_loss": 0.26294398307800293,
      "eval_runtime": 13.4049,
      "eval_samples_per_second": 502.355,
      "eval_steps_per_second": 15.741,
      "step": 6736
    },
    {
      "epoch": 4.038004750593824,
      "grad_norm": 3.686906576156616,
      "learning_rate": 1.192517814726841e-05,
      "loss": 0.267,
      "step": 6800
    },
    {
      "epoch": 4.097387173396674,
      "grad_norm": 1.8741860389709473,
      "learning_rate": 1.1806413301662708e-05,
      "loss": 0.2692,
      "step": 6900
    },
    {
      "epoch": 4.156769596199525,
      "grad_norm": 2.349005699157715,
      "learning_rate": 1.1687648456057009e-05,
      "loss": 0.25,
      "step": 7000
    },
    {
      "epoch": 4.216152019002375,
      "grad_norm": 2.8835339546203613,
      "learning_rate": 1.1568883610451308e-05,
      "loss": 0.2422,
      "step": 7100
    },
    {
      "epoch": 4.275534441805226,
      "grad_norm": 2.8384530544281006,
      "learning_rate": 1.1450118764845606e-05,
      "loss": 0.2518,
      "step": 7200
    },
    {
      "epoch": 4.334916864608076,
      "grad_norm": 1.6329926252365112,
      "learning_rate": 1.1331353919239907e-05,
      "loss": 0.2533,
      "step": 7300
    },
    {
      "epoch": 4.394299287410926,
      "grad_norm": 1.4189364910125732,
      "learning_rate": 1.1212589073634205e-05,
      "loss": 0.2497,
      "step": 7400
    },
    {
      "epoch": 4.453681710213777,
      "grad_norm": 2.0478644371032715,
      "learning_rate": 1.1093824228028504e-05,
      "loss": 0.243,
      "step": 7500
    },
    {
      "epoch": 4.513064133016627,
      "grad_norm": 1.8176366090774536,
      "learning_rate": 1.0975059382422803e-05,
      "loss": 0.2495,
      "step": 7600
    },
    {
      "epoch": 4.572446555819478,
      "grad_norm": 1.4048432111740112,
      "learning_rate": 1.0856294536817103e-05,
      "loss": 0.2654,
      "step": 7700
    },
    {
      "epoch": 4.631828978622328,
      "grad_norm": 2.434108018875122,
      "learning_rate": 1.0737529691211402e-05,
      "loss": 0.2609,
      "step": 7800
    },
    {
      "epoch": 4.6912114014251785,
      "grad_norm": 3.087113857269287,
      "learning_rate": 1.0618764845605702e-05,
      "loss": 0.2517,
      "step": 7900
    },
    {
      "epoch": 4.750593824228028,
      "grad_norm": 1.8218865394592285,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.2407,
      "step": 8000
    },
    {
      "epoch": 4.809976247030879,
      "grad_norm": 3.355170249938965,
      "learning_rate": 1.03812351543943e-05,
      "loss": 0.2391,
      "step": 8100
    },
    {
      "epoch": 4.869358669833729,
      "grad_norm": 1.1252191066741943,
      "learning_rate": 1.0262470308788599e-05,
      "loss": 0.2465,
      "step": 8200
    },
    {
      "epoch": 4.92874109263658,
      "grad_norm": 1.4013445377349854,
      "learning_rate": 1.0143705463182897e-05,
      "loss": 0.2521,
      "step": 8300
    },
    {
      "epoch": 4.98812351543943,
      "grad_norm": 2.232296943664551,
      "learning_rate": 1.00249406175772e-05,
      "loss": 0.2584,
      "step": 8400
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8932283932283932,
      "eval_f1": 0.9035287803569032,
      "eval_loss": 0.25931620597839355,
      "eval_runtime": 13.5613,
      "eval_samples_per_second": 496.559,
      "eval_steps_per_second": 15.559,
      "step": 8420
    },
    {
      "epoch": 5.04750593824228,
      "grad_norm": 4.114791393280029,
      "learning_rate": 9.906175771971496e-06,
      "loss": 0.2561,
      "step": 8500
    },
    {
      "epoch": 5.10688836104513,
      "grad_norm": 1.744184970855713,
      "learning_rate": 9.787410926365797e-06,
      "loss": 0.2568,
      "step": 8600
    },
    {
      "epoch": 5.166270783847981,
      "grad_norm": 3.170450210571289,
      "learning_rate": 9.668646080760096e-06,
      "loss": 0.2316,
      "step": 8700
    },
    {
      "epoch": 5.225653206650831,
      "grad_norm": 3.2567265033721924,
      "learning_rate": 9.549881235154394e-06,
      "loss": 0.2544,
      "step": 8800
    },
    {
      "epoch": 5.285035629453682,
      "grad_norm": 3.037078380584717,
      "learning_rate": 9.431116389548695e-06,
      "loss": 0.2522,
      "step": 8900
    },
    {
      "epoch": 5.344418052256532,
      "grad_norm": 2.5923328399658203,
      "learning_rate": 9.312351543942993e-06,
      "loss": 0.2395,
      "step": 9000
    },
    {
      "epoch": 5.403800475059382,
      "grad_norm": 3.197619915008545,
      "learning_rate": 9.193586698337294e-06,
      "loss": 0.2386,
      "step": 9100
    },
    {
      "epoch": 5.463182897862232,
      "grad_norm": 1.906660556793213,
      "learning_rate": 9.074821852731593e-06,
      "loss": 0.2591,
      "step": 9200
    },
    {
      "epoch": 5.522565320665083,
      "grad_norm": 1.2168463468551636,
      "learning_rate": 8.956057007125891e-06,
      "loss": 0.2282,
      "step": 9300
    },
    {
      "epoch": 5.581947743467934,
      "grad_norm": 2.387002944946289,
      "learning_rate": 8.837292161520192e-06,
      "loss": 0.2464,
      "step": 9400
    },
    {
      "epoch": 5.641330166270784,
      "grad_norm": 4.034393310546875,
      "learning_rate": 8.71852731591449e-06,
      "loss": 0.2466,
      "step": 9500
    },
    {
      "epoch": 5.7007125890736345,
      "grad_norm": 2.6481409072875977,
      "learning_rate": 8.599762470308789e-06,
      "loss": 0.2429,
      "step": 9600
    },
    {
      "epoch": 5.760095011876484,
      "grad_norm": 1.8728426694869995,
      "learning_rate": 8.48099762470309e-06,
      "loss": 0.247,
      "step": 9700
    },
    {
      "epoch": 5.819477434679335,
      "grad_norm": 3.184954881668091,
      "learning_rate": 8.362232779097388e-06,
      "loss": 0.253,
      "step": 9800
    },
    {
      "epoch": 5.878859857482185,
      "grad_norm": 1.6040208339691162,
      "learning_rate": 8.243467933491687e-06,
      "loss": 0.2466,
      "step": 9900
    },
    {
      "epoch": 5.938242280285036,
      "grad_norm": 1.5415112972259521,
      "learning_rate": 8.124703087885987e-06,
      "loss": 0.241,
      "step": 10000
    },
    {
      "epoch": 5.997624703087886,
      "grad_norm": 2.4345285892486572,
      "learning_rate": 8.005938242280286e-06,
      "loss": 0.2347,
      "step": 10100
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8970893970893971,
      "eval_f1": 0.9060848353435424,
      "eval_loss": 0.2530100345611572,
      "eval_runtime": 13.4413,
      "eval_samples_per_second": 500.994,
      "eval_steps_per_second": 15.698,
      "step": 10104
    },
    {
      "epoch": 6.0570071258907365,
      "grad_norm": 1.483203649520874,
      "learning_rate": 7.887173396674585e-06,
      "loss": 0.2434,
      "step": 10200
    },
    {
      "epoch": 6.116389548693586,
      "grad_norm": 1.8343921899795532,
      "learning_rate": 7.768408551068885e-06,
      "loss": 0.2445,
      "step": 10300
    },
    {
      "epoch": 6.175771971496437,
      "grad_norm": 2.4210121631622314,
      "learning_rate": 7.649643705463184e-06,
      "loss": 0.2486,
      "step": 10400
    },
    {
      "epoch": 6.235154394299287,
      "grad_norm": 1.530022382736206,
      "learning_rate": 7.5308788598574835e-06,
      "loss": 0.2458,
      "step": 10500
    },
    {
      "epoch": 6.294536817102138,
      "grad_norm": 2.2855186462402344,
      "learning_rate": 7.412114014251782e-06,
      "loss": 0.2496,
      "step": 10600
    },
    {
      "epoch": 6.353919239904988,
      "grad_norm": 4.913581848144531,
      "learning_rate": 7.293349168646081e-06,
      "loss": 0.2293,
      "step": 10700
    },
    {
      "epoch": 6.4133016627078385,
      "grad_norm": 3.5116562843322754,
      "learning_rate": 7.174584323040381e-06,
      "loss": 0.239,
      "step": 10800
    },
    {
      "epoch": 6.472684085510689,
      "grad_norm": 4.066747188568115,
      "learning_rate": 7.05581947743468e-06,
      "loss": 0.2542,
      "step": 10900
    },
    {
      "epoch": 6.532066508313539,
      "grad_norm": 2.2975385189056396,
      "learning_rate": 6.937054631828979e-06,
      "loss": 0.2433,
      "step": 11000
    },
    {
      "epoch": 6.591448931116389,
      "grad_norm": 2.280287981033325,
      "learning_rate": 6.818289786223279e-06,
      "loss": 0.2428,
      "step": 11100
    },
    {
      "epoch": 6.65083135391924,
      "grad_norm": 2.034374713897705,
      "learning_rate": 6.699524940617578e-06,
      "loss": 0.2511,
      "step": 11200
    },
    {
      "epoch": 6.710213776722091,
      "grad_norm": 0.7247146368026733,
      "learning_rate": 6.580760095011877e-06,
      "loss": 0.2203,
      "step": 11300
    },
    {
      "epoch": 6.7695961995249405,
      "grad_norm": 1.921205759048462,
      "learning_rate": 6.461995249406177e-06,
      "loss": 0.2371,
      "step": 11400
    },
    {
      "epoch": 6.828978622327791,
      "grad_norm": 1.6729662418365479,
      "learning_rate": 6.343230403800476e-06,
      "loss": 0.2271,
      "step": 11500
    },
    {
      "epoch": 6.888361045130641,
      "grad_norm": 2.787224769592285,
      "learning_rate": 6.2244655581947745e-06,
      "loss": 0.2271,
      "step": 11600
    },
    {
      "epoch": 6.947743467933492,
      "grad_norm": 5.249425888061523,
      "learning_rate": 6.105700712589074e-06,
      "loss": 0.2272,
      "step": 11700
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.896940896940897,
      "eval_f1": 0.9065193965517241,
      "eval_loss": 0.25068801641464233,
      "eval_runtime": 14.2893,
      "eval_samples_per_second": 471.262,
      "eval_steps_per_second": 14.766,
      "step": 11788
    },
    {
      "epoch": 7.007125890736342,
      "grad_norm": 2.814127206802368,
      "learning_rate": 5.986935866983374e-06,
      "loss": 0.2551,
      "step": 11800
    },
    {
      "epoch": 7.066508313539193,
      "grad_norm": 3.2870147228240967,
      "learning_rate": 5.868171021377672e-06,
      "loss": 0.2542,
      "step": 11900
    },
    {
      "epoch": 7.1258907363420425,
      "grad_norm": 1.38657808303833,
      "learning_rate": 5.749406175771972e-06,
      "loss": 0.2255,
      "step": 12000
    },
    {
      "epoch": 7.185273159144893,
      "grad_norm": 2.9868288040161133,
      "learning_rate": 5.6306413301662714e-06,
      "loss": 0.2405,
      "step": 12100
    },
    {
      "epoch": 7.244655581947743,
      "grad_norm": 2.161003351211548,
      "learning_rate": 5.511876484560571e-06,
      "loss": 0.2391,
      "step": 12200
    },
    {
      "epoch": 7.304038004750594,
      "grad_norm": 2.739422559738159,
      "learning_rate": 5.39311163895487e-06,
      "loss": 0.2361,
      "step": 12300
    },
    {
      "epoch": 7.363420427553444,
      "grad_norm": 3.00028920173645,
      "learning_rate": 5.2743467933491684e-06,
      "loss": 0.2641,
      "step": 12400
    },
    {
      "epoch": 7.422802850356295,
      "grad_norm": 2.8469488620758057,
      "learning_rate": 5.155581947743469e-06,
      "loss": 0.2283,
      "step": 12500
    },
    {
      "epoch": 7.4821852731591445,
      "grad_norm": 1.7286229133605957,
      "learning_rate": 5.0368171021377676e-06,
      "loss": 0.2183,
      "step": 12600
    },
    {
      "epoch": 7.541567695961995,
      "grad_norm": 2.2249395847320557,
      "learning_rate": 4.918052256532067e-06,
      "loss": 0.227,
      "step": 12700
    },
    {
      "epoch": 7.600950118764846,
      "grad_norm": 3.265888214111328,
      "learning_rate": 4.799287410926366e-06,
      "loss": 0.2279,
      "step": 12800
    },
    {
      "epoch": 7.660332541567696,
      "grad_norm": 2.0180654525756836,
      "learning_rate": 4.680522565320665e-06,
      "loss": 0.2421,
      "step": 12900
    },
    {
      "epoch": 7.719714964370546,
      "grad_norm": 2.1056275367736816,
      "learning_rate": 4.561757719714965e-06,
      "loss": 0.2254,
      "step": 13000
    },
    {
      "epoch": 7.779097387173397,
      "grad_norm": 1.782846450805664,
      "learning_rate": 4.4429928741092645e-06,
      "loss": 0.221,
      "step": 13100
    },
    {
      "epoch": 7.838479809976247,
      "grad_norm": 1.830758810043335,
      "learning_rate": 4.324228028503563e-06,
      "loss": 0.238,
      "step": 13200
    },
    {
      "epoch": 7.897862232779097,
      "grad_norm": 2.670644998550415,
      "learning_rate": 4.205463182897863e-06,
      "loss": 0.2433,
      "step": 13300
    },
    {
      "epoch": 7.957244655581948,
      "grad_norm": 1.5355863571166992,
      "learning_rate": 4.086698337292162e-06,
      "loss": 0.2298,
      "step": 13400
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8973863973863974,
      "eval_f1": 0.9071610909579471,
      "eval_loss": 0.24892722070217133,
      "eval_runtime": 13.5228,
      "eval_samples_per_second": 497.974,
      "eval_steps_per_second": 15.603,
      "step": 13472
    },
    {
      "epoch": 8.016627078384799,
      "grad_norm": 1.5815848112106323,
      "learning_rate": 3.967933491686461e-06,
      "loss": 0.2349,
      "step": 13500
    },
    {
      "epoch": 8.076009501187649,
      "grad_norm": 1.1869539022445679,
      "learning_rate": 3.849168646080761e-06,
      "loss": 0.2288,
      "step": 13600
    },
    {
      "epoch": 8.135391923990499,
      "grad_norm": 1.4265782833099365,
      "learning_rate": 3.73040380047506e-06,
      "loss": 0.2402,
      "step": 13700
    },
    {
      "epoch": 8.194774346793348,
      "grad_norm": 3.7341866493225098,
      "learning_rate": 3.6116389548693594e-06,
      "loss": 0.2456,
      "step": 13800
    },
    {
      "epoch": 8.2541567695962,
      "grad_norm": 1.8950861692428589,
      "learning_rate": 3.492874109263658e-06,
      "loss": 0.2273,
      "step": 13900
    },
    {
      "epoch": 8.31353919239905,
      "grad_norm": 3.4116315841674805,
      "learning_rate": 3.3741092636579577e-06,
      "loss": 0.2173,
      "step": 14000
    },
    {
      "epoch": 8.3729216152019,
      "grad_norm": 2.152860164642334,
      "learning_rate": 3.255344418052257e-06,
      "loss": 0.2422,
      "step": 14100
    },
    {
      "epoch": 8.43230403800475,
      "grad_norm": 1.9476957321166992,
      "learning_rate": 3.136579572446556e-06,
      "loss": 0.221,
      "step": 14200
    },
    {
      "epoch": 8.491686460807601,
      "grad_norm": 2.749030113220215,
      "learning_rate": 3.017814726840855e-06,
      "loss": 0.2506,
      "step": 14300
    },
    {
      "epoch": 8.551068883610451,
      "grad_norm": 1.3485767841339111,
      "learning_rate": 2.8990498812351547e-06,
      "loss": 0.2332,
      "step": 14400
    },
    {
      "epoch": 8.610451306413301,
      "grad_norm": 2.1362686157226562,
      "learning_rate": 2.7802850356294542e-06,
      "loss": 0.2288,
      "step": 14500
    },
    {
      "epoch": 8.669833729216151,
      "grad_norm": 2.4087488651275635,
      "learning_rate": 2.661520190023753e-06,
      "loss": 0.2349,
      "step": 14600
    },
    {
      "epoch": 8.729216152019003,
      "grad_norm": 4.528096675872803,
      "learning_rate": 2.5427553444180525e-06,
      "loss": 0.2512,
      "step": 14700
    },
    {
      "epoch": 8.788598574821853,
      "grad_norm": 2.427539825439453,
      "learning_rate": 2.4239904988123517e-06,
      "loss": 0.2488,
      "step": 14800
    },
    {
      "epoch": 8.847980997624703,
      "grad_norm": 3.1150946617126465,
      "learning_rate": 2.3052256532066512e-06,
      "loss": 0.246,
      "step": 14900
    },
    {
      "epoch": 8.907363420427554,
      "grad_norm": 3.2865302562713623,
      "learning_rate": 2.1864608076009504e-06,
      "loss": 0.241,
      "step": 15000
    },
    {
      "epoch": 8.966745843230404,
      "grad_norm": 2.139927864074707,
      "learning_rate": 2.0676959619952495e-06,
      "loss": 0.2133,
      "step": 15100
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9000594000594001,
      "eval_f1": 0.9087952297059222,
      "eval_loss": 0.2466604858636856,
      "eval_runtime": 13.3325,
      "eval_samples_per_second": 505.082,
      "eval_steps_per_second": 15.826,
      "step": 15156
    }
  ],
  "logging_steps": 100,
  "max_steps": 16840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.638906946048512e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}

{
  "best_global_step": 13472,
  "best_metric": 0.8999462076385153,
  "best_model_checkpoint": "./results_rank_4/checkpoint-13472",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 13472,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 1.282345175743103,
      "learning_rate": 1.988242280285036e-05,
      "loss": 0.674,
      "step": 100
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 1.1359684467315674,
      "learning_rate": 1.9763657957244657e-05,
      "loss": 0.6156,
      "step": 200
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 1.356876015663147,
      "learning_rate": 1.9644893111638956e-05,
      "loss": 0.4313,
      "step": 300
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 0.8025417923927307,
      "learning_rate": 1.9526128266033254e-05,
      "loss": 0.3776,
      "step": 400
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 2.1523211002349854,
      "learning_rate": 1.9407363420427553e-05,
      "loss": 0.3338,
      "step": 500
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 0.9553136825561523,
      "learning_rate": 1.9288598574821855e-05,
      "loss": 0.3451,
      "step": 600
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 1.1588259935379028,
      "learning_rate": 1.9169833729216154e-05,
      "loss": 0.3431,
      "step": 700
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 3.4806604385375977,
      "learning_rate": 1.9051068883610453e-05,
      "loss": 0.3343,
      "step": 800
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 2.4950010776519775,
      "learning_rate": 1.893230403800475e-05,
      "loss": 0.3375,
      "step": 900
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 1.2535125017166138,
      "learning_rate": 1.881353919239905e-05,
      "loss": 0.3458,
      "step": 1000
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 2.0559864044189453,
      "learning_rate": 1.8694774346793352e-05,
      "loss": 0.3301,
      "step": 1100
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 0.9269046783447266,
      "learning_rate": 1.857600950118765e-05,
      "loss": 0.3209,
      "step": 1200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 1.566057562828064,
      "learning_rate": 1.845724465558195e-05,
      "loss": 0.3233,
      "step": 1300
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 1.3236531019210815,
      "learning_rate": 1.833847980997625e-05,
      "loss": 0.3201,
      "step": 1400
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 1.1553831100463867,
      "learning_rate": 1.8219714964370547e-05,
      "loss": 0.3279,
      "step": 1500
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.2083282470703125,
      "learning_rate": 1.8100950118764846e-05,
      "loss": 0.3325,
      "step": 1600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.867983367983368,
      "eval_f1": 0.8780353958018933,
      "eval_loss": 0.309966504573822,
      "eval_runtime": 13.6764,
      "eval_samples_per_second": 492.381,
      "eval_steps_per_second": 15.428,
      "step": 1684
    },
    {
      "epoch": 1.009501187648456,
      "grad_norm": 1.6411194801330566,
      "learning_rate": 1.7982185273159148e-05,
      "loss": 0.3162,
      "step": 1700
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 2.7762670516967773,
      "learning_rate": 1.7863420427553447e-05,
      "loss": 0.3166,
      "step": 1800
    },
    {
      "epoch": 1.1282660332541568,
      "grad_norm": 2.1325430870056152,
      "learning_rate": 1.7744655581947745e-05,
      "loss": 0.2949,
      "step": 1900
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.2818368673324585,
      "learning_rate": 1.7625890736342044e-05,
      "loss": 0.3065,
      "step": 2000
    },
    {
      "epoch": 1.2470308788598574,
      "grad_norm": 1.087931752204895,
      "learning_rate": 1.7507125890736343e-05,
      "loss": 0.3004,
      "step": 2100
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 2.2326624393463135,
      "learning_rate": 1.738836104513064e-05,
      "loss": 0.2967,
      "step": 2200
    },
    {
      "epoch": 1.365795724465558,
      "grad_norm": 0.9120500087738037,
      "learning_rate": 1.7269596199524944e-05,
      "loss": 0.3041,
      "step": 2300
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 1.3637489080429077,
      "learning_rate": 1.7150831353919242e-05,
      "loss": 0.2988,
      "step": 2400
    },
    {
      "epoch": 1.484560570071259,
      "grad_norm": 0.7975828051567078,
      "learning_rate": 1.703206650831354e-05,
      "loss": 0.3018,
      "step": 2500
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 1.4422106742858887,
      "learning_rate": 1.691330166270784e-05,
      "loss": 0.3278,
      "step": 2600
    },
    {
      "epoch": 1.6033254156769596,
      "grad_norm": 2.1142807006835938,
      "learning_rate": 1.679453681710214e-05,
      "loss": 0.3218,
      "step": 2700
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 1.7479350566864014,
      "learning_rate": 1.667577197149644e-05,
      "loss": 0.3135,
      "step": 2800
    },
    {
      "epoch": 1.7220902612826603,
      "grad_norm": 1.0902378559112549,
      "learning_rate": 1.655700712589074e-05,
      "loss": 0.2997,
      "step": 2900
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 1.6671384572982788,
      "learning_rate": 1.6438242280285038e-05,
      "loss": 0.3058,
      "step": 3000
    },
    {
      "epoch": 1.8408551068883612,
      "grad_norm": 2.7676239013671875,
      "learning_rate": 1.6319477434679337e-05,
      "loss": 0.3021,
      "step": 3100
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 2.0489299297332764,
      "learning_rate": 1.6200712589073636e-05,
      "loss": 0.2893,
      "step": 3200
    },
    {
      "epoch": 1.9596199524940618,
      "grad_norm": 2.2795603275299072,
      "learning_rate": 1.6081947743467934e-05,
      "loss": 0.3049,
      "step": 3300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8765963765963766,
      "eval_f1": 0.8874746106973596,
      "eval_loss": 0.2944411635398865,
      "eval_runtime": 13.5894,
      "eval_samples_per_second": 495.535,
      "eval_steps_per_second": 15.527,
      "step": 3368
    },
    {
      "epoch": 2.019002375296912,
      "grad_norm": 1.5785102844238281,
      "learning_rate": 1.5963182897862236e-05,
      "loss": 0.2963,
      "step": 3400
    },
    {
      "epoch": 2.0783847980997625,
      "grad_norm": 2.9682722091674805,
      "learning_rate": 1.5844418052256535e-05,
      "loss": 0.2883,
      "step": 3500
    },
    {
      "epoch": 2.137767220902613,
      "grad_norm": 1.5537652969360352,
      "learning_rate": 1.5725653206650834e-05,
      "loss": 0.3097,
      "step": 3600
    },
    {
      "epoch": 2.197149643705463,
      "grad_norm": 1.8198432922363281,
      "learning_rate": 1.5606888361045133e-05,
      "loss": 0.2929,
      "step": 3700
    },
    {
      "epoch": 2.2565320665083135,
      "grad_norm": 1.40472412109375,
      "learning_rate": 1.548812351543943e-05,
      "loss": 0.2931,
      "step": 3800
    },
    {
      "epoch": 2.315914489311164,
      "grad_norm": 1.7591023445129395,
      "learning_rate": 1.536935866983373e-05,
      "loss": 0.3064,
      "step": 3900
    },
    {
      "epoch": 2.375296912114014,
      "grad_norm": 1.074165940284729,
      "learning_rate": 1.525059382422803e-05,
      "loss": 0.2918,
      "step": 4000
    },
    {
      "epoch": 2.4346793349168645,
      "grad_norm": 1.7618365287780762,
      "learning_rate": 1.5131828978622329e-05,
      "loss": 0.2953,
      "step": 4100
    },
    {
      "epoch": 2.494061757719715,
      "grad_norm": 1.39851975440979,
      "learning_rate": 1.5013064133016628e-05,
      "loss": 0.2757,
      "step": 4200
    },
    {
      "epoch": 2.553444180522565,
      "grad_norm": 2.4664790630340576,
      "learning_rate": 1.4894299287410927e-05,
      "loss": 0.2776,
      "step": 4300
    },
    {
      "epoch": 2.6128266033254155,
      "grad_norm": 1.4425771236419678,
      "learning_rate": 1.4775534441805225e-05,
      "loss": 0.2997,
      "step": 4400
    },
    {
      "epoch": 2.6722090261282663,
      "grad_norm": 0.8474358320236206,
      "learning_rate": 1.4656769596199527e-05,
      "loss": 0.2794,
      "step": 4500
    },
    {
      "epoch": 2.731591448931116,
      "grad_norm": 2.946733236312866,
      "learning_rate": 1.4538004750593826e-05,
      "loss": 0.3027,
      "step": 4600
    },
    {
      "epoch": 2.790973871733967,
      "grad_norm": 1.733982801437378,
      "learning_rate": 1.4419239904988125e-05,
      "loss": 0.2866,
      "step": 4700
    },
    {
      "epoch": 2.850356294536817,
      "grad_norm": 1.61752188205719,
      "learning_rate": 1.4300475059382423e-05,
      "loss": 0.2829,
      "step": 4800
    },
    {
      "epoch": 2.9097387173396676,
      "grad_norm": 1.403838872909546,
      "learning_rate": 1.4181710213776722e-05,
      "loss": 0.2842,
      "step": 4900
    },
    {
      "epoch": 2.969121140142518,
      "grad_norm": 2.108724594116211,
      "learning_rate": 1.4062945368171021e-05,
      "loss": 0.3052,
      "step": 5000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8794178794178794,
      "eval_f1": 0.8911236256369,
      "eval_loss": 0.2889595329761505,
      "eval_runtime": 13.4374,
      "eval_samples_per_second": 501.138,
      "eval_steps_per_second": 15.702,
      "step": 5052
    },
    {
      "epoch": 3.0285035629453683,
      "grad_norm": 1.1507052183151245,
      "learning_rate": 1.3944180522565323e-05,
      "loss": 0.2676,
      "step": 5100
    },
    {
      "epoch": 3.0878859857482186,
      "grad_norm": 1.8102550506591797,
      "learning_rate": 1.3825415676959622e-05,
      "loss": 0.286,
      "step": 5200
    },
    {
      "epoch": 3.147268408551069,
      "grad_norm": 2.7760937213897705,
      "learning_rate": 1.370665083135392e-05,
      "loss": 0.2816,
      "step": 5300
    },
    {
      "epoch": 3.2066508313539193,
      "grad_norm": 1.231481671333313,
      "learning_rate": 1.358788598574822e-05,
      "loss": 0.2911,
      "step": 5400
    },
    {
      "epoch": 3.2660332541567696,
      "grad_norm": 0.8304942846298218,
      "learning_rate": 1.3469121140142518e-05,
      "loss": 0.2896,
      "step": 5500
    },
    {
      "epoch": 3.32541567695962,
      "grad_norm": 2.2589375972747803,
      "learning_rate": 1.335035629453682e-05,
      "loss": 0.2754,
      "step": 5600
    },
    {
      "epoch": 3.3847980997624703,
      "grad_norm": 2.1033709049224854,
      "learning_rate": 1.3231591448931119e-05,
      "loss": 0.2824,
      "step": 5700
    },
    {
      "epoch": 3.4441805225653206,
      "grad_norm": 1.635717749595642,
      "learning_rate": 1.3112826603325417e-05,
      "loss": 0.3075,
      "step": 5800
    },
    {
      "epoch": 3.503562945368171,
      "grad_norm": 2.041245460510254,
      "learning_rate": 1.2994061757719716e-05,
      "loss": 0.2657,
      "step": 5900
    },
    {
      "epoch": 3.5629453681710213,
      "grad_norm": 1.4264169931411743,
      "learning_rate": 1.2875296912114015e-05,
      "loss": 0.2719,
      "step": 6000
    },
    {
      "epoch": 3.6223277909738716,
      "grad_norm": 1.4147223234176636,
      "learning_rate": 1.2756532066508314e-05,
      "loss": 0.2894,
      "step": 6100
    },
    {
      "epoch": 3.6817102137767224,
      "grad_norm": 2.333359956741333,
      "learning_rate": 1.2637767220902614e-05,
      "loss": 0.2875,
      "step": 6200
    },
    {
      "epoch": 3.7410926365795723,
      "grad_norm": 1.726984977722168,
      "learning_rate": 1.2519002375296914e-05,
      "loss": 0.2807,
      "step": 6300
    },
    {
      "epoch": 3.800475059382423,
      "grad_norm": 0.8480384945869446,
      "learning_rate": 1.2400237529691213e-05,
      "loss": 0.2739,
      "step": 6400
    },
    {
      "epoch": 3.859857482185273,
      "grad_norm": 1.5597975254058838,
      "learning_rate": 1.2281472684085512e-05,
      "loss": 0.2887,
      "step": 6500
    },
    {
      "epoch": 3.9192399049881237,
      "grad_norm": 1.6260395050048828,
      "learning_rate": 1.216270783847981e-05,
      "loss": 0.286,
      "step": 6600
    },
    {
      "epoch": 3.978622327790974,
      "grad_norm": 0.9855054020881653,
      "learning_rate": 1.204394299287411e-05,
      "loss": 0.2594,
      "step": 6700
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8825363825363826,
      "eval_f1": 0.8930358350236647,
      "eval_loss": 0.27930402755737305,
      "eval_runtime": 13.4779,
      "eval_samples_per_second": 499.633,
      "eval_steps_per_second": 15.655,
      "step": 6736
    },
    {
      "epoch": 4.038004750593824,
      "grad_norm": 3.680175304412842,
      "learning_rate": 1.192517814726841e-05,
      "loss": 0.292,
      "step": 6800
    },
    {
      "epoch": 4.097387173396674,
      "grad_norm": 1.7065842151641846,
      "learning_rate": 1.1806413301662708e-05,
      "loss": 0.2953,
      "step": 6900
    },
    {
      "epoch": 4.156769596199525,
      "grad_norm": 1.7876057624816895,
      "learning_rate": 1.1687648456057009e-05,
      "loss": 0.2724,
      "step": 7000
    },
    {
      "epoch": 4.216152019002375,
      "grad_norm": 2.059933662414551,
      "learning_rate": 1.1568883610451308e-05,
      "loss": 0.2629,
      "step": 7100
    },
    {
      "epoch": 4.275534441805226,
      "grad_norm": 2.232020854949951,
      "learning_rate": 1.1450118764845606e-05,
      "loss": 0.276,
      "step": 7200
    },
    {
      "epoch": 4.334916864608076,
      "grad_norm": 1.5886168479919434,
      "learning_rate": 1.1331353919239907e-05,
      "loss": 0.2747,
      "step": 7300
    },
    {
      "epoch": 4.394299287410926,
      "grad_norm": 1.128163456916809,
      "learning_rate": 1.1212589073634205e-05,
      "loss": 0.2734,
      "step": 7400
    },
    {
      "epoch": 4.453681710213777,
      "grad_norm": 1.413391351699829,
      "learning_rate": 1.1093824228028504e-05,
      "loss": 0.2656,
      "step": 7500
    },
    {
      "epoch": 4.513064133016627,
      "grad_norm": 1.3818193674087524,
      "learning_rate": 1.0975059382422803e-05,
      "loss": 0.2756,
      "step": 7600
    },
    {
      "epoch": 4.572446555819478,
      "grad_norm": 1.318656325340271,
      "learning_rate": 1.0856294536817103e-05,
      "loss": 0.2875,
      "step": 7700
    },
    {
      "epoch": 4.631828978622328,
      "grad_norm": 1.6766870021820068,
      "learning_rate": 1.0737529691211402e-05,
      "loss": 0.2887,
      "step": 7800
    },
    {
      "epoch": 4.6912114014251785,
      "grad_norm": 2.3621408939361572,
      "learning_rate": 1.0618764845605702e-05,
      "loss": 0.2714,
      "step": 7900
    },
    {
      "epoch": 4.750593824228028,
      "grad_norm": 1.5291848182678223,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.2634,
      "step": 8000
    },
    {
      "epoch": 4.809976247030879,
      "grad_norm": 2.654031753540039,
      "learning_rate": 1.03812351543943e-05,
      "loss": 0.2654,
      "step": 8100
    },
    {
      "epoch": 4.869358669833729,
      "grad_norm": 1.0888751745224,
      "learning_rate": 1.0262470308788599e-05,
      "loss": 0.2726,
      "step": 8200
    },
    {
      "epoch": 4.92874109263658,
      "grad_norm": 1.3274095058441162,
      "learning_rate": 1.0143705463182897e-05,
      "loss": 0.2767,
      "step": 8300
    },
    {
      "epoch": 4.98812351543943,
      "grad_norm": 1.6912163496017456,
      "learning_rate": 1.00249406175772e-05,
      "loss": 0.2811,
      "step": 8400
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8850608850608851,
      "eval_f1": 0.8954619124797407,
      "eval_loss": 0.27550190687179565,
      "eval_runtime": 13.417,
      "eval_samples_per_second": 501.901,
      "eval_steps_per_second": 15.726,
      "step": 8420
    },
    {
      "epoch": 5.04750593824228,
      "grad_norm": 2.982626438140869,
      "learning_rate": 9.906175771971496e-06,
      "loss": 0.2787,
      "step": 8500
    },
    {
      "epoch": 5.10688836104513,
      "grad_norm": 1.4429700374603271,
      "learning_rate": 9.787410926365797e-06,
      "loss": 0.2827,
      "step": 8600
    },
    {
      "epoch": 5.166270783847981,
      "grad_norm": 2.534411907196045,
      "learning_rate": 9.668646080760096e-06,
      "loss": 0.2577,
      "step": 8700
    },
    {
      "epoch": 5.225653206650831,
      "grad_norm": 2.9647324085235596,
      "learning_rate": 9.549881235154394e-06,
      "loss": 0.281,
      "step": 8800
    },
    {
      "epoch": 5.285035629453682,
      "grad_norm": 2.1543264389038086,
      "learning_rate": 9.431116389548695e-06,
      "loss": 0.275,
      "step": 8900
    },
    {
      "epoch": 5.344418052256532,
      "grad_norm": 2.1733102798461914,
      "learning_rate": 9.312351543942993e-06,
      "loss": 0.2672,
      "step": 9000
    },
    {
      "epoch": 5.403800475059382,
      "grad_norm": 2.4555728435516357,
      "learning_rate": 9.193586698337294e-06,
      "loss": 0.2637,
      "step": 9100
    },
    {
      "epoch": 5.463182897862232,
      "grad_norm": 1.7470450401306152,
      "learning_rate": 9.074821852731593e-06,
      "loss": 0.2831,
      "step": 9200
    },
    {
      "epoch": 5.522565320665083,
      "grad_norm": 1.0467430353164673,
      "learning_rate": 8.956057007125891e-06,
      "loss": 0.2566,
      "step": 9300
    },
    {
      "epoch": 5.581947743467934,
      "grad_norm": 2.3689544200897217,
      "learning_rate": 8.837292161520192e-06,
      "loss": 0.2673,
      "step": 9400
    },
    {
      "epoch": 5.641330166270784,
      "grad_norm": 3.8691623210906982,
      "learning_rate": 8.71852731591449e-06,
      "loss": 0.277,
      "step": 9500
    },
    {
      "epoch": 5.7007125890736345,
      "grad_norm": 1.7389887571334839,
      "learning_rate": 8.599762470308789e-06,
      "loss": 0.2659,
      "step": 9600
    },
    {
      "epoch": 5.760095011876484,
      "grad_norm": 1.4832910299301147,
      "learning_rate": 8.48099762470309e-06,
      "loss": 0.2713,
      "step": 9700
    },
    {
      "epoch": 5.819477434679335,
      "grad_norm": 2.391303777694702,
      "learning_rate": 8.362232779097388e-06,
      "loss": 0.276,
      "step": 9800
    },
    {
      "epoch": 5.878859857482185,
      "grad_norm": 1.4696952104568481,
      "learning_rate": 8.243467933491687e-06,
      "loss": 0.2723,
      "step": 9900
    },
    {
      "epoch": 5.938242280285036,
      "grad_norm": 1.072594165802002,
      "learning_rate": 8.124703087885987e-06,
      "loss": 0.2661,
      "step": 10000
    },
    {
      "epoch": 5.997624703087886,
      "grad_norm": 1.9150035381317139,
      "learning_rate": 8.005938242280286e-06,
      "loss": 0.2578,
      "step": 10100
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8868428868428868,
      "eval_f1": 0.8968039003250271,
      "eval_loss": 0.2720243036746979,
      "eval_runtime": 13.448,
      "eval_samples_per_second": 500.745,
      "eval_steps_per_second": 15.69,
      "step": 10104
    },
    {
      "epoch": 6.0570071258907365,
      "grad_norm": 1.3284668922424316,
      "learning_rate": 7.887173396674585e-06,
      "loss": 0.2676,
      "step": 10200
    },
    {
      "epoch": 6.116389548693586,
      "grad_norm": 1.9286525249481201,
      "learning_rate": 7.768408551068885e-06,
      "loss": 0.2691,
      "step": 10300
    },
    {
      "epoch": 6.175771971496437,
      "grad_norm": 1.9462696313858032,
      "learning_rate": 7.649643705463184e-06,
      "loss": 0.2774,
      "step": 10400
    },
    {
      "epoch": 6.235154394299287,
      "grad_norm": 1.4525129795074463,
      "learning_rate": 7.5308788598574835e-06,
      "loss": 0.2677,
      "step": 10500
    },
    {
      "epoch": 6.294536817102138,
      "grad_norm": 1.486259937286377,
      "learning_rate": 7.412114014251782e-06,
      "loss": 0.2723,
      "step": 10600
    },
    {
      "epoch": 6.353919239904988,
      "grad_norm": 3.9982612133026123,
      "learning_rate": 7.293349168646081e-06,
      "loss": 0.2528,
      "step": 10700
    },
    {
      "epoch": 6.4133016627078385,
      "grad_norm": 2.8813774585723877,
      "learning_rate": 7.174584323040381e-06,
      "loss": 0.2662,
      "step": 10800
    },
    {
      "epoch": 6.472684085510689,
      "grad_norm": 2.957777500152588,
      "learning_rate": 7.05581947743468e-06,
      "loss": 0.2789,
      "step": 10900
    },
    {
      "epoch": 6.532066508313539,
      "grad_norm": 1.9212141036987305,
      "learning_rate": 6.937054631828979e-06,
      "loss": 0.2687,
      "step": 11000
    },
    {
      "epoch": 6.591448931116389,
      "grad_norm": 1.7220159769058228,
      "learning_rate": 6.818289786223279e-06,
      "loss": 0.266,
      "step": 11100
    },
    {
      "epoch": 6.65083135391924,
      "grad_norm": 2.2826151847839355,
      "learning_rate": 6.699524940617578e-06,
      "loss": 0.2713,
      "step": 11200
    },
    {
      "epoch": 6.710213776722091,
      "grad_norm": 0.7581168413162231,
      "learning_rate": 6.580760095011877e-06,
      "loss": 0.2488,
      "step": 11300
    },
    {
      "epoch": 6.7695961995249405,
      "grad_norm": 1.6917312145233154,
      "learning_rate": 6.461995249406177e-06,
      "loss": 0.2618,
      "step": 11400
    },
    {
      "epoch": 6.828978622327791,
      "grad_norm": 1.598015308380127,
      "learning_rate": 6.343230403800476e-06,
      "loss": 0.2561,
      "step": 11500
    },
    {
      "epoch": 6.888361045130641,
      "grad_norm": 2.348494529724121,
      "learning_rate": 6.2244655581947745e-06,
      "loss": 0.2571,
      "step": 11600
    },
    {
      "epoch": 6.947743467933492,
      "grad_norm": 3.6778788566589355,
      "learning_rate": 6.105700712589074e-06,
      "loss": 0.25,
      "step": 11700
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8881793881793881,
      "eval_f1": 0.8987494957644211,
      "eval_loss": 0.27028152346611023,
      "eval_runtime": 13.4211,
      "eval_samples_per_second": 501.749,
      "eval_steps_per_second": 15.722,
      "step": 11788
    },
    {
      "epoch": 7.007125890736342,
      "grad_norm": 2.4107778072357178,
      "learning_rate": 5.986935866983374e-06,
      "loss": 0.2824,
      "step": 11800
    },
    {
      "epoch": 7.066508313539193,
      "grad_norm": 2.625138998031616,
      "learning_rate": 5.868171021377672e-06,
      "loss": 0.2815,
      "step": 11900
    },
    {
      "epoch": 7.1258907363420425,
      "grad_norm": 1.2966580390930176,
      "learning_rate": 5.749406175771972e-06,
      "loss": 0.2582,
      "step": 12000
    },
    {
      "epoch": 7.185273159144893,
      "grad_norm": 2.4275033473968506,
      "learning_rate": 5.6306413301662714e-06,
      "loss": 0.2643,
      "step": 12100
    },
    {
      "epoch": 7.244655581947743,
      "grad_norm": 1.4909493923187256,
      "learning_rate": 5.511876484560571e-06,
      "loss": 0.2642,
      "step": 12200
    },
    {
      "epoch": 7.304038004750594,
      "grad_norm": 1.7540521621704102,
      "learning_rate": 5.39311163895487e-06,
      "loss": 0.2577,
      "step": 12300
    },
    {
      "epoch": 7.363420427553444,
      "grad_norm": 2.2378318309783936,
      "learning_rate": 5.2743467933491684e-06,
      "loss": 0.287,
      "step": 12400
    },
    {
      "epoch": 7.422802850356295,
      "grad_norm": 2.5469460487365723,
      "learning_rate": 5.155581947743469e-06,
      "loss": 0.2574,
      "step": 12500
    },
    {
      "epoch": 7.4821852731591445,
      "grad_norm": 1.5579895973205566,
      "learning_rate": 5.0368171021377676e-06,
      "loss": 0.2444,
      "step": 12600
    },
    {
      "epoch": 7.541567695961995,
      "grad_norm": 2.6470377445220947,
      "learning_rate": 4.918052256532067e-06,
      "loss": 0.2555,
      "step": 12700
    },
    {
      "epoch": 7.600950118764846,
      "grad_norm": 2.850067138671875,
      "learning_rate": 4.799287410926366e-06,
      "loss": 0.2575,
      "step": 12800
    },
    {
      "epoch": 7.660332541567696,
      "grad_norm": 1.2482916116714478,
      "learning_rate": 4.680522565320665e-06,
      "loss": 0.2678,
      "step": 12900
    },
    {
      "epoch": 7.719714964370546,
      "grad_norm": 1.5017101764678955,
      "learning_rate": 4.561757719714965e-06,
      "loss": 0.2495,
      "step": 13000
    },
    {
      "epoch": 7.779097387173397,
      "grad_norm": 1.4729281663894653,
      "learning_rate": 4.4429928741092645e-06,
      "loss": 0.2493,
      "step": 13100
    },
    {
      "epoch": 7.838479809976247,
      "grad_norm": 1.549686074256897,
      "learning_rate": 4.324228028503563e-06,
      "loss": 0.2659,
      "step": 13200
    },
    {
      "epoch": 7.897862232779097,
      "grad_norm": 1.7757184505462646,
      "learning_rate": 4.205463182897863e-06,
      "loss": 0.2665,
      "step": 13300
    },
    {
      "epoch": 7.957244655581948,
      "grad_norm": 1.3746657371520996,
      "learning_rate": 4.086698337292162e-06,
      "loss": 0.2528,
      "step": 13400
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8895158895158896,
      "eval_f1": 0.8999462076385153,
      "eval_loss": 0.2684711217880249,
      "eval_runtime": 13.3911,
      "eval_samples_per_second": 502.872,
      "eval_steps_per_second": 15.757,
      "step": 13472
    }
  ],
  "logging_steps": 100,
  "max_steps": 16840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4494842633363456e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}

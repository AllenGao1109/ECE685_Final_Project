{
  "best_global_step": 13472,
  "best_metric": 0.8955384822752392,
  "best_model_checkpoint": "./results_rank_2/checkpoint-13472",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 13472,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 1.2853490114212036,
      "learning_rate": 1.988242280285036e-05,
      "loss": 0.6744,
      "step": 100
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 1.0698927640914917,
      "learning_rate": 1.9763657957244657e-05,
      "loss": 0.6281,
      "step": 200
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 1.1130250692367554,
      "learning_rate": 1.9644893111638956e-05,
      "loss": 0.4999,
      "step": 300
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 0.8679381608963013,
      "learning_rate": 1.9526128266033254e-05,
      "loss": 0.4046,
      "step": 400
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 2.0710906982421875,
      "learning_rate": 1.9407363420427553e-05,
      "loss": 0.3424,
      "step": 500
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 0.9174110889434814,
      "learning_rate": 1.9288598574821855e-05,
      "loss": 0.3514,
      "step": 600
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 1.0444583892822266,
      "learning_rate": 1.9169833729216154e-05,
      "loss": 0.3508,
      "step": 700
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 3.334552526473999,
      "learning_rate": 1.9051068883610453e-05,
      "loss": 0.341,
      "step": 800
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 2.183340072631836,
      "learning_rate": 1.893230403800475e-05,
      "loss": 0.3434,
      "step": 900
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 1.291877031326294,
      "learning_rate": 1.881353919239905e-05,
      "loss": 0.352,
      "step": 1000
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 1.9368641376495361,
      "learning_rate": 1.8694774346793352e-05,
      "loss": 0.3381,
      "step": 1100
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 0.9098852276802063,
      "learning_rate": 1.857600950118765e-05,
      "loss": 0.3269,
      "step": 1200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 1.543718934059143,
      "learning_rate": 1.845724465558195e-05,
      "loss": 0.3293,
      "step": 1300
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 1.1948552131652832,
      "learning_rate": 1.833847980997625e-05,
      "loss": 0.326,
      "step": 1400
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 1.1571314334869385,
      "learning_rate": 1.8219714964370547e-05,
      "loss": 0.3337,
      "step": 1500
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.1977319717407227,
      "learning_rate": 1.8100950118764846e-05,
      "loss": 0.3387,
      "step": 1600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8659043659043659,
      "eval_f1": 0.8763860369609856,
      "eval_loss": 0.31591853499412537,
      "eval_runtime": 13.4578,
      "eval_samples_per_second": 500.38,
      "eval_steps_per_second": 15.679,
      "step": 1684
    },
    {
      "epoch": 1.009501187648456,
      "grad_norm": 1.4621212482452393,
      "learning_rate": 1.7982185273159148e-05,
      "loss": 0.3236,
      "step": 1700
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 2.7078912258148193,
      "learning_rate": 1.7863420427553447e-05,
      "loss": 0.3235,
      "step": 1800
    },
    {
      "epoch": 1.1282660332541568,
      "grad_norm": 1.9722858667373657,
      "learning_rate": 1.7744655581947745e-05,
      "loss": 0.3012,
      "step": 1900
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.266865849494934,
      "learning_rate": 1.7625890736342044e-05,
      "loss": 0.3133,
      "step": 2000
    },
    {
      "epoch": 1.2470308788598574,
      "grad_norm": 0.9721113443374634,
      "learning_rate": 1.7507125890736343e-05,
      "loss": 0.3076,
      "step": 2100
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 1.831889033317566,
      "learning_rate": 1.738836104513064e-05,
      "loss": 0.303,
      "step": 2200
    },
    {
      "epoch": 1.365795724465558,
      "grad_norm": 0.8708266615867615,
      "learning_rate": 1.7269596199524944e-05,
      "loss": 0.3114,
      "step": 2300
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 1.2847740650177002,
      "learning_rate": 1.7150831353919242e-05,
      "loss": 0.3058,
      "step": 2400
    },
    {
      "epoch": 1.484560570071259,
      "grad_norm": 0.7902660369873047,
      "learning_rate": 1.703206650831354e-05,
      "loss": 0.3095,
      "step": 2500
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 1.2938202619552612,
      "learning_rate": 1.691330166270784e-05,
      "loss": 0.3336,
      "step": 2600
    },
    {
      "epoch": 1.6033254156769596,
      "grad_norm": 1.9959975481033325,
      "learning_rate": 1.679453681710214e-05,
      "loss": 0.3295,
      "step": 2700
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 1.6353219747543335,
      "learning_rate": 1.667577197149644e-05,
      "loss": 0.3202,
      "step": 2800
    },
    {
      "epoch": 1.7220902612826603,
      "grad_norm": 0.9482436776161194,
      "learning_rate": 1.655700712589074e-05,
      "loss": 0.3082,
      "step": 2900
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 1.5786861181259155,
      "learning_rate": 1.6438242280285038e-05,
      "loss": 0.3135,
      "step": 3000
    },
    {
      "epoch": 1.8408551068883612,
      "grad_norm": 2.664719820022583,
      "learning_rate": 1.6319477434679337e-05,
      "loss": 0.3096,
      "step": 3100
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 2.3015990257263184,
      "learning_rate": 1.6200712589073636e-05,
      "loss": 0.2961,
      "step": 3200
    },
    {
      "epoch": 1.9596199524940618,
      "grad_norm": 2.0838427543640137,
      "learning_rate": 1.6081947743467934e-05,
      "loss": 0.3134,
      "step": 3300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8708048708048708,
      "eval_f1": 0.8819538670284939,
      "eval_loss": 0.30125489830970764,
      "eval_runtime": 13.4116,
      "eval_samples_per_second": 502.101,
      "eval_steps_per_second": 15.733,
      "step": 3368
    },
    {
      "epoch": 2.019002375296912,
      "grad_norm": 1.36582612991333,
      "learning_rate": 1.5963182897862236e-05,
      "loss": 0.3037,
      "step": 3400
    },
    {
      "epoch": 2.0783847980997625,
      "grad_norm": 2.5701987743377686,
      "learning_rate": 1.5844418052256535e-05,
      "loss": 0.2961,
      "step": 3500
    },
    {
      "epoch": 2.137767220902613,
      "grad_norm": 1.4776725769042969,
      "learning_rate": 1.5725653206650834e-05,
      "loss": 0.3159,
      "step": 3600
    },
    {
      "epoch": 2.197149643705463,
      "grad_norm": 1.5349127054214478,
      "learning_rate": 1.5606888361045133e-05,
      "loss": 0.3034,
      "step": 3700
    },
    {
      "epoch": 2.2565320665083135,
      "grad_norm": 1.311239242553711,
      "learning_rate": 1.548812351543943e-05,
      "loss": 0.3021,
      "step": 3800
    },
    {
      "epoch": 2.315914489311164,
      "grad_norm": 1.625512719154358,
      "learning_rate": 1.536935866983373e-05,
      "loss": 0.3128,
      "step": 3900
    },
    {
      "epoch": 2.375296912114014,
      "grad_norm": 0.9506264925003052,
      "learning_rate": 1.525059382422803e-05,
      "loss": 0.3007,
      "step": 4000
    },
    {
      "epoch": 2.4346793349168645,
      "grad_norm": 1.6245992183685303,
      "learning_rate": 1.5131828978622329e-05,
      "loss": 0.3045,
      "step": 4100
    },
    {
      "epoch": 2.494061757719715,
      "grad_norm": 1.2992571592330933,
      "learning_rate": 1.5013064133016628e-05,
      "loss": 0.2822,
      "step": 4200
    },
    {
      "epoch": 2.553444180522565,
      "grad_norm": 2.050889015197754,
      "learning_rate": 1.4894299287410927e-05,
      "loss": 0.2851,
      "step": 4300
    },
    {
      "epoch": 2.6128266033254155,
      "grad_norm": 1.4018341302871704,
      "learning_rate": 1.4775534441805225e-05,
      "loss": 0.309,
      "step": 4400
    },
    {
      "epoch": 2.6722090261282663,
      "grad_norm": 0.895535945892334,
      "learning_rate": 1.4656769596199527e-05,
      "loss": 0.2874,
      "step": 4500
    },
    {
      "epoch": 2.731591448931116,
      "grad_norm": 2.9404430389404297,
      "learning_rate": 1.4538004750593826e-05,
      "loss": 0.3114,
      "step": 4600
    },
    {
      "epoch": 2.790973871733967,
      "grad_norm": 1.3963572978973389,
      "learning_rate": 1.4419239904988125e-05,
      "loss": 0.2954,
      "step": 4700
    },
    {
      "epoch": 2.850356294536817,
      "grad_norm": 1.4578039646148682,
      "learning_rate": 1.4300475059382423e-05,
      "loss": 0.292,
      "step": 4800
    },
    {
      "epoch": 2.9097387173396676,
      "grad_norm": 1.3253952264785767,
      "learning_rate": 1.4181710213776722e-05,
      "loss": 0.2928,
      "step": 4900
    },
    {
      "epoch": 2.969121140142518,
      "grad_norm": 2.172797203063965,
      "learning_rate": 1.4062945368171021e-05,
      "loss": 0.3131,
      "step": 5000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8752598752598753,
      "eval_f1": 0.887248322147651,
      "eval_loss": 0.29509690403938293,
      "eval_runtime": 13.3989,
      "eval_samples_per_second": 502.58,
      "eval_steps_per_second": 15.748,
      "step": 5052
    },
    {
      "epoch": 3.0285035629453683,
      "grad_norm": 1.1306192874908447,
      "learning_rate": 1.3944180522565323e-05,
      "loss": 0.2773,
      "step": 5100
    },
    {
      "epoch": 3.0878859857482186,
      "grad_norm": 1.4462039470672607,
      "learning_rate": 1.3825415676959622e-05,
      "loss": 0.295,
      "step": 5200
    },
    {
      "epoch": 3.147268408551069,
      "grad_norm": 2.5607829093933105,
      "learning_rate": 1.370665083135392e-05,
      "loss": 0.2903,
      "step": 5300
    },
    {
      "epoch": 3.2066508313539193,
      "grad_norm": 1.1862788200378418,
      "learning_rate": 1.358788598574822e-05,
      "loss": 0.3004,
      "step": 5400
    },
    {
      "epoch": 3.2660332541567696,
      "grad_norm": 0.7927536964416504,
      "learning_rate": 1.3469121140142518e-05,
      "loss": 0.2973,
      "step": 5500
    },
    {
      "epoch": 3.32541567695962,
      "grad_norm": 2.091179132461548,
      "learning_rate": 1.335035629453682e-05,
      "loss": 0.2834,
      "step": 5600
    },
    {
      "epoch": 3.3847980997624703,
      "grad_norm": 2.0414364337921143,
      "learning_rate": 1.3231591448931119e-05,
      "loss": 0.2916,
      "step": 5700
    },
    {
      "epoch": 3.4441805225653206,
      "grad_norm": 1.524362564086914,
      "learning_rate": 1.3112826603325417e-05,
      "loss": 0.3168,
      "step": 5800
    },
    {
      "epoch": 3.503562945368171,
      "grad_norm": 1.723397970199585,
      "learning_rate": 1.2994061757719716e-05,
      "loss": 0.2755,
      "step": 5900
    },
    {
      "epoch": 3.5629453681710213,
      "grad_norm": 1.3254832029342651,
      "learning_rate": 1.2875296912114015e-05,
      "loss": 0.2815,
      "step": 6000
    },
    {
      "epoch": 3.6223277909738716,
      "grad_norm": 1.2531968355178833,
      "learning_rate": 1.2756532066508314e-05,
      "loss": 0.2983,
      "step": 6100
    },
    {
      "epoch": 3.6817102137767224,
      "grad_norm": 2.0122127532958984,
      "learning_rate": 1.2637767220902614e-05,
      "loss": 0.2958,
      "step": 6200
    },
    {
      "epoch": 3.7410926365795723,
      "grad_norm": 1.6297378540039062,
      "learning_rate": 1.2519002375296914e-05,
      "loss": 0.2896,
      "step": 6300
    },
    {
      "epoch": 3.800475059382423,
      "grad_norm": 0.8014820218086243,
      "learning_rate": 1.2400237529691213e-05,
      "loss": 0.2821,
      "step": 6400
    },
    {
      "epoch": 3.859857482185273,
      "grad_norm": 1.4139323234558105,
      "learning_rate": 1.2281472684085512e-05,
      "loss": 0.2952,
      "step": 6500
    },
    {
      "epoch": 3.9192399049881237,
      "grad_norm": 1.5145204067230225,
      "learning_rate": 1.216270783847981e-05,
      "loss": 0.2942,
      "step": 6600
    },
    {
      "epoch": 3.978622327790974,
      "grad_norm": 0.8666114807128906,
      "learning_rate": 1.204394299287411e-05,
      "loss": 0.2675,
      "step": 6700
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8788238788238788,
      "eval_f1": 0.8893709327548807,
      "eval_loss": 0.28609874844551086,
      "eval_runtime": 13.4245,
      "eval_samples_per_second": 501.621,
      "eval_steps_per_second": 15.718,
      "step": 6736
    },
    {
      "epoch": 4.038004750593824,
      "grad_norm": 3.3956191539764404,
      "learning_rate": 1.192517814726841e-05,
      "loss": 0.3034,
      "step": 6800
    },
    {
      "epoch": 4.097387173396674,
      "grad_norm": 1.6662132740020752,
      "learning_rate": 1.1806413301662708e-05,
      "loss": 0.3041,
      "step": 6900
    },
    {
      "epoch": 4.156769596199525,
      "grad_norm": 1.619382619857788,
      "learning_rate": 1.1687648456057009e-05,
      "loss": 0.2806,
      "step": 7000
    },
    {
      "epoch": 4.216152019002375,
      "grad_norm": 2.0496954917907715,
      "learning_rate": 1.1568883610451308e-05,
      "loss": 0.2726,
      "step": 7100
    },
    {
      "epoch": 4.275534441805226,
      "grad_norm": 2.146679639816284,
      "learning_rate": 1.1450118764845606e-05,
      "loss": 0.2855,
      "step": 7200
    },
    {
      "epoch": 4.334916864608076,
      "grad_norm": 1.53102707862854,
      "learning_rate": 1.1331353919239907e-05,
      "loss": 0.2836,
      "step": 7300
    },
    {
      "epoch": 4.394299287410926,
      "grad_norm": 1.0070241689682007,
      "learning_rate": 1.1212589073634205e-05,
      "loss": 0.2821,
      "step": 7400
    },
    {
      "epoch": 4.453681710213777,
      "grad_norm": 1.243593454360962,
      "learning_rate": 1.1093824228028504e-05,
      "loss": 0.2753,
      "step": 7500
    },
    {
      "epoch": 4.513064133016627,
      "grad_norm": 1.3253017663955688,
      "learning_rate": 1.0975059382422803e-05,
      "loss": 0.2849,
      "step": 7600
    },
    {
      "epoch": 4.572446555819478,
      "grad_norm": 1.2750492095947266,
      "learning_rate": 1.0856294536817103e-05,
      "loss": 0.2957,
      "step": 7700
    },
    {
      "epoch": 4.631828978622328,
      "grad_norm": 1.4013853073120117,
      "learning_rate": 1.0737529691211402e-05,
      "loss": 0.2998,
      "step": 7800
    },
    {
      "epoch": 4.6912114014251785,
      "grad_norm": 2.1711843013763428,
      "learning_rate": 1.0618764845605702e-05,
      "loss": 0.2797,
      "step": 7900
    },
    {
      "epoch": 4.750593824228028,
      "grad_norm": 1.5610848665237427,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.2726,
      "step": 8000
    },
    {
      "epoch": 4.809976247030879,
      "grad_norm": 2.271390199661255,
      "learning_rate": 1.03812351543943e-05,
      "loss": 0.276,
      "step": 8100
    },
    {
      "epoch": 4.869358669833729,
      "grad_norm": 0.9621057510375977,
      "learning_rate": 1.0262470308788599e-05,
      "loss": 0.2833,
      "step": 8200
    },
    {
      "epoch": 4.92874109263658,
      "grad_norm": 1.3043345212936401,
      "learning_rate": 1.0143705463182897e-05,
      "loss": 0.2861,
      "step": 8300
    },
    {
      "epoch": 4.98812351543943,
      "grad_norm": 1.5969752073287964,
      "learning_rate": 1.00249406175772e-05,
      "loss": 0.2893,
      "step": 8400
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8816453816453816,
      "eval_f1": 0.8923700202565834,
      "eval_loss": 0.2823788523674011,
      "eval_runtime": 13.974,
      "eval_samples_per_second": 481.896,
      "eval_steps_per_second": 15.1,
      "step": 8420
    },
    {
      "epoch": 5.04750593824228,
      "grad_norm": 2.742215156555176,
      "learning_rate": 9.906175771971496e-06,
      "loss": 0.2863,
      "step": 8500
    },
    {
      "epoch": 5.10688836104513,
      "grad_norm": 1.2485027313232422,
      "learning_rate": 9.787410926365797e-06,
      "loss": 0.2919,
      "step": 8600
    },
    {
      "epoch": 5.166270783847981,
      "grad_norm": 2.4110658168792725,
      "learning_rate": 9.668646080760096e-06,
      "loss": 0.2681,
      "step": 8700
    },
    {
      "epoch": 5.225653206650831,
      "grad_norm": 2.753155469894409,
      "learning_rate": 9.549881235154394e-06,
      "loss": 0.2927,
      "step": 8800
    },
    {
      "epoch": 5.285035629453682,
      "grad_norm": 1.922422170639038,
      "learning_rate": 9.431116389548695e-06,
      "loss": 0.2837,
      "step": 8900
    },
    {
      "epoch": 5.344418052256532,
      "grad_norm": 1.9781129360198975,
      "learning_rate": 9.312351543942993e-06,
      "loss": 0.2788,
      "step": 9000
    },
    {
      "epoch": 5.403800475059382,
      "grad_norm": 2.2069478034973145,
      "learning_rate": 9.193586698337294e-06,
      "loss": 0.2738,
      "step": 9100
    },
    {
      "epoch": 5.463182897862232,
      "grad_norm": 1.606781244277954,
      "learning_rate": 9.074821852731593e-06,
      "loss": 0.2925,
      "step": 9200
    },
    {
      "epoch": 5.522565320665083,
      "grad_norm": 1.0199753046035767,
      "learning_rate": 8.956057007125891e-06,
      "loss": 0.266,
      "step": 9300
    },
    {
      "epoch": 5.581947743467934,
      "grad_norm": 2.228161096572876,
      "learning_rate": 8.837292161520192e-06,
      "loss": 0.2766,
      "step": 9400
    },
    {
      "epoch": 5.641330166270784,
      "grad_norm": 3.6129419803619385,
      "learning_rate": 8.71852731591449e-06,
      "loss": 0.2882,
      "step": 9500
    },
    {
      "epoch": 5.7007125890736345,
      "grad_norm": 1.6824907064437866,
      "learning_rate": 8.599762470308789e-06,
      "loss": 0.2756,
      "step": 9600
    },
    {
      "epoch": 5.760095011876484,
      "grad_norm": 1.3510305881500244,
      "learning_rate": 8.48099762470309e-06,
      "loss": 0.2817,
      "step": 9700
    },
    {
      "epoch": 5.819477434679335,
      "grad_norm": 2.0428407192230225,
      "learning_rate": 8.362232779097388e-06,
      "loss": 0.2857,
      "step": 9800
    },
    {
      "epoch": 5.878859857482185,
      "grad_norm": 1.4111747741699219,
      "learning_rate": 8.243467933491687e-06,
      "loss": 0.2819,
      "step": 9900
    },
    {
      "epoch": 5.938242280285036,
      "grad_norm": 0.9218354225158691,
      "learning_rate": 8.124703087885987e-06,
      "loss": 0.2742,
      "step": 10000
    },
    {
      "epoch": 5.997624703087886,
      "grad_norm": 1.7782870531082153,
      "learning_rate": 8.005938242280286e-06,
      "loss": 0.266,
      "step": 10100
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8823878823878823,
      "eval_f1": 0.8927120021674343,
      "eval_loss": 0.2794826328754425,
      "eval_runtime": 13.4196,
      "eval_samples_per_second": 501.803,
      "eval_steps_per_second": 15.723,
      "step": 10104
    },
    {
      "epoch": 6.0570071258907365,
      "grad_norm": 1.3355625867843628,
      "learning_rate": 7.887173396674585e-06,
      "loss": 0.2793,
      "step": 10200
    },
    {
      "epoch": 6.116389548693586,
      "grad_norm": 1.8627467155456543,
      "learning_rate": 7.768408551068885e-06,
      "loss": 0.2782,
      "step": 10300
    },
    {
      "epoch": 6.175771971496437,
      "grad_norm": 1.8722882270812988,
      "learning_rate": 7.649643705463184e-06,
      "loss": 0.2867,
      "step": 10400
    },
    {
      "epoch": 6.235154394299287,
      "grad_norm": 1.6365739107131958,
      "learning_rate": 7.5308788598574835e-06,
      "loss": 0.2776,
      "step": 10500
    },
    {
      "epoch": 6.294536817102138,
      "grad_norm": 1.3375296592712402,
      "learning_rate": 7.412114014251782e-06,
      "loss": 0.2795,
      "step": 10600
    },
    {
      "epoch": 6.353919239904988,
      "grad_norm": 3.8318593502044678,
      "learning_rate": 7.293349168646081e-06,
      "loss": 0.2635,
      "step": 10700
    },
    {
      "epoch": 6.4133016627078385,
      "grad_norm": 2.6397509574890137,
      "learning_rate": 7.174584323040381e-06,
      "loss": 0.2765,
      "step": 10800
    },
    {
      "epoch": 6.472684085510689,
      "grad_norm": 2.704075813293457,
      "learning_rate": 7.05581947743468e-06,
      "loss": 0.2904,
      "step": 10900
    },
    {
      "epoch": 6.532066508313539,
      "grad_norm": 2.040132761001587,
      "learning_rate": 6.937054631828979e-06,
      "loss": 0.2793,
      "step": 11000
    },
    {
      "epoch": 6.591448931116389,
      "grad_norm": 1.5494464635849,
      "learning_rate": 6.818289786223279e-06,
      "loss": 0.2747,
      "step": 11100
    },
    {
      "epoch": 6.65083135391924,
      "grad_norm": 2.118405818939209,
      "learning_rate": 6.699524940617578e-06,
      "loss": 0.2797,
      "step": 11200
    },
    {
      "epoch": 6.710213776722091,
      "grad_norm": 0.7886232137680054,
      "learning_rate": 6.580760095011877e-06,
      "loss": 0.2591,
      "step": 11300
    },
    {
      "epoch": 6.7695961995249405,
      "grad_norm": 1.5832674503326416,
      "learning_rate": 6.461995249406177e-06,
      "loss": 0.2704,
      "step": 11400
    },
    {
      "epoch": 6.828978622327791,
      "grad_norm": 1.6102063655853271,
      "learning_rate": 6.343230403800476e-06,
      "loss": 0.2687,
      "step": 11500
    },
    {
      "epoch": 6.888361045130641,
      "grad_norm": 2.262855291366577,
      "learning_rate": 6.2244655581947745e-06,
      "loss": 0.2693,
      "step": 11600
    },
    {
      "epoch": 6.947743467933492,
      "grad_norm": 3.126373052597046,
      "learning_rate": 6.105700712589074e-06,
      "loss": 0.2592,
      "step": 11700
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8837243837243838,
      "eval_f1": 0.8947439171931711,
      "eval_loss": 0.2775248885154724,
      "eval_runtime": 13.5325,
      "eval_samples_per_second": 497.615,
      "eval_steps_per_second": 15.592,
      "step": 11788
    },
    {
      "epoch": 7.007125890736342,
      "grad_norm": 2.1586263179779053,
      "learning_rate": 5.986935866983374e-06,
      "loss": 0.2945,
      "step": 11800
    },
    {
      "epoch": 7.066508313539193,
      "grad_norm": 2.4872846603393555,
      "learning_rate": 5.868171021377672e-06,
      "loss": 0.2923,
      "step": 11900
    },
    {
      "epoch": 7.1258907363420425,
      "grad_norm": 1.3534631729125977,
      "learning_rate": 5.749406175771972e-06,
      "loss": 0.2715,
      "step": 12000
    },
    {
      "epoch": 7.185273159144893,
      "grad_norm": 2.0300567150115967,
      "learning_rate": 5.6306413301662714e-06,
      "loss": 0.2746,
      "step": 12100
    },
    {
      "epoch": 7.244655581947743,
      "grad_norm": 1.3927569389343262,
      "learning_rate": 5.511876484560571e-06,
      "loss": 0.274,
      "step": 12200
    },
    {
      "epoch": 7.304038004750594,
      "grad_norm": 1.4908638000488281,
      "learning_rate": 5.39311163895487e-06,
      "loss": 0.2664,
      "step": 12300
    },
    {
      "epoch": 7.363420427553444,
      "grad_norm": 1.9141812324523926,
      "learning_rate": 5.2743467933491684e-06,
      "loss": 0.2943,
      "step": 12400
    },
    {
      "epoch": 7.422802850356295,
      "grad_norm": 2.485670804977417,
      "learning_rate": 5.155581947743469e-06,
      "loss": 0.2669,
      "step": 12500
    },
    {
      "epoch": 7.4821852731591445,
      "grad_norm": 1.5530643463134766,
      "learning_rate": 5.0368171021377676e-06,
      "loss": 0.2549,
      "step": 12600
    },
    {
      "epoch": 7.541567695961995,
      "grad_norm": 2.577425956726074,
      "learning_rate": 4.918052256532067e-06,
      "loss": 0.2668,
      "step": 12700
    },
    {
      "epoch": 7.600950118764846,
      "grad_norm": 2.5856523513793945,
      "learning_rate": 4.799287410926366e-06,
      "loss": 0.27,
      "step": 12800
    },
    {
      "epoch": 7.660332541567696,
      "grad_norm": 1.1331288814544678,
      "learning_rate": 4.680522565320665e-06,
      "loss": 0.279,
      "step": 12900
    },
    {
      "epoch": 7.719714964370546,
      "grad_norm": 1.3758153915405273,
      "learning_rate": 4.561757719714965e-06,
      "loss": 0.2574,
      "step": 13000
    },
    {
      "epoch": 7.779097387173397,
      "grad_norm": 1.3880412578582764,
      "learning_rate": 4.4429928741092645e-06,
      "loss": 0.2619,
      "step": 13100
    },
    {
      "epoch": 7.838479809976247,
      "grad_norm": 1.4404500722885132,
      "learning_rate": 4.324228028503563e-06,
      "loss": 0.2762,
      "step": 13200
    },
    {
      "epoch": 7.897862232779097,
      "grad_norm": 1.6045204401016235,
      "learning_rate": 4.205463182897863e-06,
      "loss": 0.276,
      "step": 13300
    },
    {
      "epoch": 7.957244655581948,
      "grad_norm": 1.1388068199157715,
      "learning_rate": 4.086698337292162e-06,
      "loss": 0.2613,
      "step": 13400
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8849123849123849,
      "eval_f1": 0.8955384822752392,
      "eval_loss": 0.276058167219162,
      "eval_runtime": 13.4333,
      "eval_samples_per_second": 501.292,
      "eval_steps_per_second": 15.707,
      "step": 13472
    }
  ],
  "logging_steps": 100,
  "max_steps": 16840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4482639448481792e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19244fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "class HiRALayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        r: int = 32,\n",
    "        lora_alpha: int = 32,\n",
    "        lora_dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "        self.lora_alpha = lora_alpha\n",
    "        self.scaling = lora_alpha / r\n",
    "        \n",
    "        self.lora_A = nn.Parameter(torch.zeros(in_features, r))\n",
    "        self.lora_B = nn.Parameter(torch.randn(r, out_features))\n",
    "        \n",
    "        nn.init.zeros_(self.lora_A)\n",
    "        nn.init.kaiming_uniform_(self.lora_B, a=0)\n",
    "        \n",
    "        self.lora_dropout = nn.Dropout(p=lora_dropout) if lora_dropout > 0 else nn.Identity()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, W0: torch.Tensor) -> torch.Tensor:\n",
    "        result = F.linear(x, W0)\n",
    "        \n",
    "        lora_update = self.lora_A @ self.lora_B  # [in_features, out_features]\n",
    "        \n",
    "        hadamard_update = W0.T * lora_update  # [in_features, out_features]\n",
    "        \n",
    "        result += self.lora_dropout(x @ hadamard_update) * self.scaling\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "class HiRALinear(nn.Module):\n",
    "    def __init__(self, linear_layer: nn.Linear, r: int = 32, lora_alpha: int = 32):\n",
    "        super().__init__()\n",
    "        self.linear = linear_layer\n",
    "        self.hira = HiRALayer(\n",
    "            in_features=linear_layer.in_features,\n",
    "            out_features=linear_layer.out_features,\n",
    "            r=r,\n",
    "            lora_alpha=lora_alpha\n",
    "        )\n",
    "        self.linear.weight.requires_grad = False\n",
    "        if self.linear.bias is not None:\n",
    "            self.linear.bias.requires_grad = False\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.hira(x, self.linear.weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2120ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc10860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/xielab/hl385/miniconda3/envs/ece685/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "import torch.nn as nn\n",
    "\n",
    "def apply_hira_to_model(model, r=32, lora_alpha=32, target_modules=['q_lin', 'k_lin', 'v_lin', 'out_lin', 'ffn.lin1', 'ffn.lin2']):\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if any(target in name for target in target_modules):\n",
    "                parent_name = '.'.join(name.split('.')[:-1])\n",
    "                attr_name = name.split('.')[-1]\n",
    "                \n",
    "                if parent_name:\n",
    "                    parent_module = model.get_submodule(parent_name)\n",
    "                else:\n",
    "                    parent_module = model\n",
    "                \n",
    "                hira_layer = HiRALinear(module, r=r, lora_alpha=lora_alpha)\n",
    "                setattr(parent_module, attr_name, hira_layer)\n",
    "                \n",
    "                print(f\"Applied HiRA to: {name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    return trainable_params, all_params, 100 * trainable_params / all_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c764b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def load_sst2_data(tokenizer, max_length=128):\n",
    "    \"\"\"8:1:1 \"\"\"\n",
    "    raw = load_dataset(\"glue\", \"sst2\")  # 有 train / validation / test[web:110]\n",
    "\n",
    "    train_valid = raw[\"train\"]\n",
    "    train_valid = train_valid.shuffle(seed=42)\n",
    "    n = len(train_valid)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val = int(0.1 * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_dataset = train_valid.select(range(n_train))\n",
    "    val_dataset   = train_valid.select(range(n_train, n_train + n_val))\n",
    "    test_dataset  = train_valid.select(range(n_train + n_val, n))\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        enc = tokenizer(\n",
    "            examples[\"sentence\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        enc[\"labels\"] = examples[\"label\"]\n",
    "        return enc\n",
    "\n",
    "    train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "    val_dataset   = val_dataset.map(preprocess_function,   batched=True, remove_columns=val_dataset.column_names)\n",
    "    test_dataset  = test_dataset.map(preprocess_function,  batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "    return {\n",
    "        \"train\": train_dataset,\n",
    "        \"validation\": val_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def load_imdb_data(tokenizer, max_length=256):\n",
    "\n",
    "    raw = load_dataset(\"imdb\")  \n",
    "\n",
    "    train_full = raw[\"train\"]               \n",
    "    train_full = train_full.shuffle(seed=42)\n",
    "    n = len(train_full)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val = int(0.1 * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_dataset = train_full.select(range(n_train))\n",
    "    val_dataset   = train_full.select(range(n_train, n_train + n_val))\n",
    "    test_dataset  = train_full.select(range(n_train + n_val, n))\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        enc = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        enc[\"labels\"] = examples[\"label\"]\n",
    "        return enc\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=train_dataset.column_names,\n",
    "    )\n",
    "    val_dataset = val_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=val_dataset.column_names,\n",
    "    )\n",
    "    test_dataset = test_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=test_dataset.column_names,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train\": train_dataset,\n",
    "        \"validation\": val_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf0561",
   "metadata": {},
   "source": [
    "# After changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d17063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Checkpoint directory configuration\n",
    "CHECKPOINT_DIR = \"/hpc/group/xielab/hl385/LoRA\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for p in model.parameters():\n",
    "        num = p.numel()\n",
    "        all_params += num\n",
    "        if p.requires_grad:\n",
    "            trainable_params += num\n",
    "    percentage = 100.0 * trainable_params / all_params if all_params > 0 else 0.0\n",
    "    return trainable_params, all_params, percentage\n",
    "\n",
    "\n",
    "def get_model_sparsity(model, threshold: float = 1e-3) -> float:\n",
    "    total_elems = 0\n",
    "    small_elems = 0\n",
    "    for p in model.parameters():\n",
    "        if p is None:\n",
    "            continue\n",
    "        data = p.detach()\n",
    "        total_elems += data.numel()\n",
    "        small_elems += (data.abs() < threshold).sum().item()\n",
    "    if total_elems == 0:\n",
    "        return 0.0\n",
    "    return small_elems / total_elems\n",
    "\n",
    "def train_hira_model(\n",
    "    dataset_name: str = \"sst2\",\n",
    "    model_name: str = \"distilbert-base-uncased\",\n",
    "    r: int = 32,\n",
    "    lora_alpha: int = 32,\n",
    "    num_epochs: int = 30,\n",
    "    batch_size: int = 16,\n",
    "    learning_rate: float = 5e-4,\n",
    "    weight_decay: float = 0.01,\n",
    "    warmup_steps: int = 100,\n",
    "    logging_steps: int = 100,\n",
    "    max_length: int = 128,\n",
    "    early_stop_patience: int = 3,\n",
    "    output_dir: str = \"./results_hira\",\n",
    "    resume_from_checkpoint: bool = False,\n",
    "):\n",
    "\n",
    "    device = torch.device(\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"[{dataset_name}][r={r}] Using device: {device}\")\n",
    "\n",
    "    # Check for existing checkpoint\n",
    "    checkpoint_path = os.path.join(output_dir, f\"checkpoint_r{r}.pt\")\n",
    "    start_epoch = 0\n",
    "    if resume_from_checkpoint and os.path.exists(checkpoint_path):\n",
    "        print(f\"[{dataset_name}][r={r}] Found checkpoint: {checkpoint_path}\")\n",
    "        print(f\"[{dataset_name}][r={r}] Resuming training from checkpoint...\\n\")\n",
    "    else:\n",
    "        checkpoint_path = None\n",
    "\n",
    "    # Reset peak GPU memory stats\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    num_labels = 2\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "    )\n",
    "    model = apply_hira_to_model(model, r=r, lora_alpha=lora_alpha)\n",
    "    model = model.to(device)\n",
    "\n",
    "    trainable_params, all_params, percentage = get_trainable_parameters(model)\n",
    "    print(\n",
    "        f\"[{dataset_name}][r={r}] Trainable params: {trainable_params:,} || \"\n",
    "        f\"All params: {all_params:,} || Trainable%: {percentage:.4f}%\"\n",
    "    )\n",
    "\n",
    "    if dataset_name == \"sst2\":\n",
    "        dataset = load_sst2_data(tokenizer, max_length)\n",
    "    elif dataset_name == \"imdb\":\n",
    "        dataset = load_imdb_data(tokenizer, max_length)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset_name: {dataset_name}\")\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    val_split_name = \"validation\" if \"validation\" in dataset else \"test\"\n",
    "    val_dataloader = DataLoader(\n",
    "        dataset[val_split_name],\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load checkpoint if resuming\n",
    "    if checkpoint_path is not None:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"]\n",
    "        best_val_f1 = checkpoint[\"best_val_f1\"]\n",
    "        best_val_accuracy = checkpoint[\"best_val_accuracy\"]\n",
    "        best_epoch = checkpoint[\"best_epoch\"]\n",
    "        print(f\"[{dataset_name}][r={r}] Resumed from epoch {start_epoch}\")\n",
    "        print(f\"[{dataset_name}][r={r}] Best F1 so far: {best_val_f1:.4f} at epoch {best_epoch}\\n\")\n",
    "    else:\n",
    "        best_val_accuracy = 0.0\n",
    "        best_val_f1 = 0.0\n",
    "        best_epoch = 0\n",
    "\n",
    "    epoch_times = []\n",
    "    total_train_time = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    early_stopped = False\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        start_t = time.perf_counter()\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        progress_bar = tqdm(\n",
    "            train_dataloader,\n",
    "            desc=f\"[{dataset_name}][r={r}] Epoch {epoch + 1}/{num_epochs}\",\n",
    "        )\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "            \n",
    "            # Log loss every logging_steps\n",
    "            if (step + 1) % logging_steps == 0:\n",
    "                avg_loss = total_loss / (step + 1)\n",
    "                print(f\"  Step {step + 1}/{len(train_dataloader)} | avg_loss={avg_loss:.4f}\")\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # Validation\n",
    "        acc_metric = evaluate.load(\"accuracy\")\n",
    "        f1_metric = evaluate.load(\"f1\")\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            acc_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "            f1_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "        val_acc = acc_metric.compute()[\"accuracy\"]\n",
    "        val_f1 = f1_metric.compute()[\"f1\"]\n",
    "\n",
    "        end_t = time.perf_counter()\n",
    "        epoch_time = end_t - start_t\n",
    "        epoch_times.append(epoch_time)\n",
    "        total_train_time += epoch_time\n",
    "\n",
    "        print(\n",
    "            f\"[{dataset_name}][r={r}] Epoch {epoch + 1} | \"\n",
    "            f\"train_loss={avg_train_loss:.4f} | \"\n",
    "            f\"val_acc={val_acc:.4f} | \"\n",
    "            f\"val_f1={val_f1:.4f} | \"\n",
    "            f\"time={epoch_time:.2f}s\"\n",
    "        )\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_accuracy = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "            epochs_without_improvement = 0\n",
    "\n",
    "            save_path = os.path.join(CHECKPOINT_DIR, f\"best_model_hira_{dataset_name}_r{r}.pt\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"val_f1\": best_val_f1,\n",
    "                    \"val_accuracy\": best_val_accuracy,\n",
    "                },\n",
    "                save_path,\n",
    "            )\n",
    "            print(\n",
    "                f\"[{dataset_name}][r={r}] Saved best model with \"\n",
    "                f\"val_f1={best_val_f1:.4f} at epoch {best_epoch}\"\n",
    "            )\n",
    "        else:\n",
    "            # F1 did not exceed best_val_f1\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Early stopping: stop when no improvement for patience epochs\n",
    "        if epochs_without_improvement >= early_stop_patience:\n",
    "            early_stopped = True\n",
    "            print(\n",
    "                f\"\\n[Early Stopping] No improvement over best F1 for {early_stop_patience} consecutive epochs. Stopping training.\"\n",
    "            )\n",
    "            print(f\"[Best Model] Best F1: {best_val_f1:.4f} at epoch {best_epoch}\\n\")\n",
    "            break\n",
    "        # Save checkpoint to CHECKPOINT_DIR\n",
    "        checkpoint_save_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_hira_{dataset_name}_r{r}.pt\")\n",
    "        checkpoint_save_path = os.path.join(output_dir, f\"checkpoint_r{r}.pt\")\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"best_val_f1\": best_val_f1,\n",
    "                \"best_val_accuracy\": best_val_accuracy,\n",
    "                \"best_epoch\": best_epoch,\n",
    "            },\n",
    "            checkpoint_save_path,\n",
    "        )\n",
    "    \n",
    "    avg_time_per_epoch = sum(epoch_times) / len(epoch_times) if epoch_times else 0.0\n",
    "    \n",
    "    # Get peak GPU memory\n",
    "    peak_gpu_memory_mb = 0.0\n",
    "    if torch.cuda.is_available():\n",
    "        peak_gpu_memory_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "    \n",
    "    print(\n",
    "        f\"[{dataset_name}][r={r}] Training completed! \"\n",
    "        f\"best_val_acc={best_val_accuracy:.4f}, \"\n",
    "        f\"best_val_f1={best_val_f1:.4f}, \"\n",
    "        f\"avg_time/epoch={avg_time_per_epoch:.2f}s, \"\n",
    "        f\"best_epoch={best_epoch}, \"\n",
    "        f\"early_stopped={early_stopped}, \"\n",
    "        f\"peak_gpu_memory={peak_gpu_memory_mb:.2f}MB, \"\n",
    "        f\"trainable_params={trainable_params}, \"\n",
    "        f\"trainable_ratio={percentage:.4f}%\"\n",
    "    )\n",
    "\n",
    "    best_model_path = os.path.join(CHECKPOINT_DIR, f\"best_model_hira_{dataset_name}_r{r}.pt\")\n",
    "    best_model_path = os.path.join(output_dir, f\"best_model_r{r}.pt\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        print(f\"[{dataset_name}][r={r}] Loaded best model from {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"[{dataset_name}][r={r}] Warning: Best model not found, using current model\")\n",
    "\n",
    "    # Test evaluation\n",
    "    acc_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        acc_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "        f1_metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "\n",
    "    test_acc = acc_metric.compute()[\"accuracy\"]\n",
    "    test_f1 = f1_metric.compute()[\"f1\"]\n",
    "    print(f\"[{dataset_name}][r={r}] Final test accuracy: {test_acc:.4f}, test_f1={test_f1:.4f}\")\n",
    "\n",
    "    sparsity = get_model_sparsity(model, threshold=1e-3)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"rank\": r,\n",
    "        \"final_test_accuracy\": test_acc,\n",
    "        \"final_test_f1\": test_f1,\n",
    "        \"final_val_accuracy\": best_val_accuracy,\n",
    "        \"final_val_f1\": best_val_f1,\n",
    "        \"total_parameters\": all_params,\n",
    "        \"trainable_parameters\": trainable_params,\n",
    "        \"trainable_percentage\": percentage,\n",
    "        \"total_training_time\": total_train_time,\n",
    "        \"average_epoch_time\": avg_time_per_epoch,\n",
    "        \"best_f1_epoch\": best_epoch,\n",
    "        \"best_val_f1\": best_val_f1,\n",
    "        \"peak_gpu_memory_mb\": peak_gpu_memory_mb,\n",
    "        \"sparsity\": sparsity,\n",
    "        \"early_stopped\": early_stopped,\n",
    "    }\n",
    "        \"early_stopped\": early_stopped,\n",
    "\n",
    "def generate_summary_table(results, save_prefix=\"HiRA\"):\n",
    "    \"\"\"Generate and save summary table with all metrics\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    for result in results:\n",
    "        summary_data.append({\n",
    "            \"Rank\": result[\"rank\"],\n",
    "            \"Test Acc\": f\"{result['final_test_accuracy']:.4f}\",\n",
    "            \"Test F1\": f\"{result['final_test_f1']:.4f}\",\n",
    "            \"Val Acc\": f\"{result['final_val_accuracy']:.4f}\",\n",
    "            \"Val F1\": f\"{result['final_val_f1']:.4f}\",\n",
    "            \"Best Val F1\": f\"{result['best_val_f1']:.4f}\",\n",
    "            \"Best F1 Epoch\": result['best_f1_epoch'],\n",
    "            \"Trainable Params\": f\"{result['trainable_parameters']:,}\",\n",
    "            \"Trainable %\": f\"{result['trainable_percentage']:.2f}%\",\n",
    "            \"Total Time (s)\": f\"{result['total_training_time']:.2f}\",\n",
    "            \"Avg Epoch (s)\": f\"{result['average_epoch_time']:.2f}\",\n",
    "            \"Early Stopped\": \"Yes\" if result['early_stopped'] else \"No\",\n",
    "            \"Peak GPU (MB)\": f\"{result['peak_gpu_memory_mb']:.2f}\",\n",
    "            \"Sparsity (<1e-3)\": f\"{result['sparsity']*100:.2f}%\",\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BENCHMARK SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    # Save summary to CSV\n",
    "    csv_filename = f\"{save_prefix}_benchmark_summary.csv\"\n",
    "    summary_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\n✓ Summary saved to '{csv_filename}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "\n",
    "    return summary_df\n",
    "    print(\"=\"*80)    return summary_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a4925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training HiRA on SST-2 with different ranks\n",
      "==================================================\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=2\n",
      "------------------------------\n",
      "[imdb][r=2] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=2] Trainable params: 24,612,098 || All params: 67,120,898 || Trainable%: 36.6683%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:26<00:00, 749.97 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:03<00:00, 770.62 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:03<00:00, 758.20 examples/s]\n",
      "[imdb][r=2] Epoch 1/10: 100%|██████████| 1250/1250 [04:33<00:00,  4.58it/s, loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 1 | train_loss=0.4822 | val_acc=0.8212 | val_f1=0.8158 | time/epoch=299.35s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8212 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 2/10: 100%|██████████| 1250/1250 [06:04<00:00,  3.43it/s, loss=0.431] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 2 | train_loss=0.3514 | val_acc=0.8300 | val_f1=0.8266 | time/epoch=378.34s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8300 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 3/10: 100%|██████████| 1250/1250 [05:34<00:00,  3.73it/s, loss=0.652] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 3 | train_loss=0.3002 | val_acc=0.8372 | val_f1=0.8379 | time/epoch=350.08s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8372 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 4/10: 100%|██████████| 1250/1250 [04:59<00:00,  4.17it/s, loss=0.182] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 4 | train_loss=0.2598 | val_acc=0.8428 | val_f1=0.8411 | time/epoch=315.13s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8428 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 5/10: 100%|██████████| 1250/1250 [05:20<00:00,  3.90it/s, loss=0.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 5 | train_loss=0.2271 | val_acc=0.8472 | val_f1=0.8489 | time/epoch=335.56s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8472 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 6/10: 100%|██████████| 1250/1250 [05:15<00:00,  3.96it/s, loss=0.163] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 6 | train_loss=0.2013 | val_acc=0.8472 | val_f1=0.8470 | time/epoch=331.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 7/10: 100%|██████████| 1250/1250 [05:15<00:00,  3.96it/s, loss=0.119] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 7 | train_loss=0.1740 | val_acc=0.8452 | val_f1=0.8435 | time/epoch=330.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 8/10: 100%|██████████| 1250/1250 [05:11<00:00,  4.01it/s, loss=0.49]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 8 | train_loss=0.1591 | val_acc=0.8480 | val_f1=0.8475 | time/epoch=327.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 9/10: 100%|██████████| 1250/1250 [05:12<00:00,  4.00it/s, loss=0.432] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 9 | train_loss=0.1454 | val_acc=0.8504 | val_f1=0.8508 | time/epoch=327.03s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8504 to ./results_hira/best_model_r2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 10/10: 100%|██████████| 1250/1250 [05:17<00:00,  3.94it/s, loss=0.167] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=2] Epoch 10 | train_loss=0.1406 | val_acc=0.8492 | val_f1=0.8513 | time/epoch=333.76s\n",
      "[imdb][r=2] Saved best model with val_acc=0.8492 to ./results_hira/best_model_r2.pt\n",
      "[imdb][r=2] Training completed! best_val_acc=0.8492, avg_time/epoch=332.88s, converge_epoch=1, trainable_params=24612098, trainable_ratio=36.6683%\n",
      "[imdb][r=2] Final test accuracy: 0.8460, test_f1=0.8523\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=4\n",
      "------------------------------\n",
      "[imdb][r=4] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=4] Trainable params: 24,777,986 || All params: 67,286,786 || Trainable%: 36.8244%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 1/10: 100%|██████████| 1250/1250 [05:53<00:00,  3.53it/s, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 1 | train_loss=0.4814 | val_acc=0.8192 | val_f1=0.8167 | time/epoch=371.73s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8192 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 2/10: 100%|██████████| 1250/1250 [06:08<00:00,  3.39it/s, loss=0.383] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 2 | train_loss=0.3510 | val_acc=0.8328 | val_f1=0.8321 | time/epoch=386.08s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8328 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 3/10: 100%|██████████| 1250/1250 [06:05<00:00,  3.42it/s, loss=0.173] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 3 | train_loss=0.3018 | val_acc=0.8400 | val_f1=0.8403 | time/epoch=382.79s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8400 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 4/10: 100%|██████████| 1250/1250 [05:47<00:00,  3.59it/s, loss=0.311] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 4 | train_loss=0.2607 | val_acc=0.8392 | val_f1=0.8376 | time/epoch=364.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 5/10: 100%|██████████| 1250/1250 [05:29<00:00,  3.80it/s, loss=0.504] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 5 | train_loss=0.2266 | val_acc=0.8428 | val_f1=0.8424 | time/epoch=344.92s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8428 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 6/10: 100%|██████████| 1250/1250 [05:16<00:00,  3.95it/s, loss=0.131] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 6 | train_loss=0.1976 | val_acc=0.8412 | val_f1=0.8411 | time/epoch=332.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 7/10: 100%|██████████| 1250/1250 [05:24<00:00,  3.85it/s, loss=0.151] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 7 | train_loss=0.1764 | val_acc=0.8456 | val_f1=0.8468 | time/epoch=340.96s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8456 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 8/10: 100%|██████████| 1250/1250 [05:33<00:00,  3.75it/s, loss=0.166] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 8 | train_loss=0.1588 | val_acc=0.8460 | val_f1=0.8475 | time/epoch=349.01s\n",
      "[imdb][r=4] Saved best model with val_acc=0.8460 to ./results_hira/best_model_r4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 9/10: 100%|██████████| 1250/1250 [05:28<00:00,  3.81it/s, loss=0.17]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 9 | train_loss=0.1462 | val_acc=0.8448 | val_f1=0.8459 | time/epoch=344.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 10/10: 100%|██████████| 1250/1250 [05:32<00:00,  3.76it/s, loss=0.0692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=4] Epoch 10 | train_loss=0.1393 | val_acc=0.8444 | val_f1=0.8455 | time/epoch=348.89s\n",
      "[imdb][r=4] Training completed! best_val_acc=0.8460, avg_time/epoch=356.52s, converge_epoch=1, trainable_params=24777986, trainable_ratio=36.8244%\n",
      "[imdb][r=4] Final test accuracy: 0.8472, test_f1=0.8526\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=8\n",
      "------------------------------\n",
      "[imdb][r=8] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=8] Trainable params: 25,109,762 || All params: 67,618,562 || Trainable%: 37.1344%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 1/10: 100%|██████████| 1250/1250 [05:31<00:00,  3.77it/s, loss=0.361] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 1 | train_loss=0.4819 | val_acc=0.8172 | val_f1=0.8165 | time/epoch=346.88s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8172 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 2/10: 100%|██████████| 1250/1250 [05:22<00:00,  3.88it/s, loss=0.467] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 2 | train_loss=0.3487 | val_acc=0.8308 | val_f1=0.8314 | time/epoch=337.78s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8308 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 3/10: 100%|██████████| 1250/1250 [05:19<00:00,  3.92it/s, loss=0.344] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 3 | train_loss=0.2968 | val_acc=0.8360 | val_f1=0.8373 | time/epoch=334.93s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8360 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 4/10: 100%|██████████| 1250/1250 [05:19<00:00,  3.91it/s, loss=0.442] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 4 | train_loss=0.2576 | val_acc=0.8412 | val_f1=0.8434 | time/epoch=334.71s\n",
      "[imdb][r=8] Saved best model with val_acc=0.8412 to ./results_hira/best_model_r8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 5/10: 100%|██████████| 1250/1250 [05:17<00:00,  3.93it/s, loss=0.346] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 5 | train_loss=0.2241 | val_acc=0.8420 | val_f1=0.8428 | time/epoch=333.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 6/10: 100%|██████████| 1250/1250 [05:21<00:00,  3.89it/s, loss=0.322] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 6 | train_loss=0.1944 | val_acc=0.8412 | val_f1=0.8430 | time/epoch=336.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 7/10: 100%|██████████| 1250/1250 [05:18<00:00,  3.93it/s, loss=0.0956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 7 | train_loss=0.1697 | val_acc=0.8400 | val_f1=0.8390 | time/epoch=333.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 8/10: 100%|██████████| 1250/1250 [05:16<00:00,  3.95it/s, loss=0.612] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 8 | train_loss=0.1567 | val_acc=0.8404 | val_f1=0.8403 | time/epoch=331.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 9/10: 100%|██████████| 1250/1250 [05:16<00:00,  3.95it/s, loss=0.251] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 9 | train_loss=0.1452 | val_acc=0.8416 | val_f1=0.8420 | time/epoch=330.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 10/10: 100%|██████████| 1250/1250 [28:57<00:00,  1.39s/it, loss=0.0934]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=8] Epoch 10 | train_loss=0.1365 | val_acc=0.8416 | val_f1=0.8422 | time/epoch=264.35s\n",
      "[imdb][r=8] Training completed! best_val_acc=0.8412, avg_time/epoch=328.50s, converge_epoch=1, trainable_params=25109762, trainable_ratio=37.1344%\n",
      "[imdb][r=8] Final test accuracy: 0.8448, test_f1=0.8507\n",
      "\n",
      "------------------------------\n",
      "HiRA with rank r=16\n",
      "------------------------------\n",
      "[imdb][r=16] Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied HiRA to: distilbert.transformer.layer.0.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.0.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.1.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.2.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.3.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.4.ffn.lin2\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.q_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.k_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.v_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.attention.out_lin\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin1\n",
      "Applied HiRA to: distilbert.transformer.layer.5.ffn.lin2\n",
      "[imdb][r=16] Trainable params: 25,773,314 || All params: 68,282,114 || Trainable%: 37.7453%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 1/10: 100%|██████████| 1250/1250 [29:10<00:00,  1.40s/it, loss=0.552]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 1 | train_loss=0.4907 | val_acc=0.8228 | val_f1=0.8200 | time/epoch=256.82s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8228 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 2/10: 100%|██████████| 1250/1250 [45:04<00:00,  2.16s/it, loss=0.542]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 2 | train_loss=0.3496 | val_acc=0.8332 | val_f1=0.8343 | time/epoch=252.57s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8332 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 3/10: 100%|██████████| 1250/1250 [37:40<00:00,  1.81s/it, loss=0.198]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 3 | train_loss=0.2992 | val_acc=0.8396 | val_f1=0.8381 | time/epoch=255.30s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8396 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 4/10: 100%|██████████| 1250/1250 [57:42<00:00,  2.77s/it, loss=0.142]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 4 | train_loss=0.2591 | val_acc=0.8392 | val_f1=0.8370 | time/epoch=249.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 5/10: 100%|██████████| 1250/1250 [56:46<00:00,  2.73s/it, loss=0.307]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 5 | train_loss=0.2251 | val_acc=0.8448 | val_f1=0.8469 | time/epoch=251.03s\n",
      "[imdb][r=16] Saved best model with val_acc=0.8448 to ./results_hira/best_model_r16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 6/10: 100%|██████████| 1250/1250 [31:53<00:00,  1.53s/it, loss=0.346]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 6 | train_loss=0.1971 | val_acc=0.8444 | val_f1=0.8467 | time/epoch=249.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 7/10: 100%|██████████| 1250/1250 [53:09<00:00,  2.55s/it, loss=0.0767]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 7 | train_loss=0.1712 | val_acc=0.8440 | val_f1=0.8466 | time/epoch=253.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 8/10: 100%|██████████| 1250/1250 [28:20<00:00,  1.36s/it, loss=0.361]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 8 | train_loss=0.1549 | val_acc=0.8432 | val_f1=0.8447 | time/epoch=253.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 9/10: 100%|██████████| 1250/1250 [1:00:30<00:00,  2.90s/it, loss=0.151]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 9 | train_loss=0.1439 | val_acc=0.8444 | val_f1=0.8457 | time/epoch=248.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 10/10: 100%|██████████| 1250/1250 [52:38<00:00,  2.53s/it, loss=0.289]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[imdb][r=16] Epoch 10 | train_loss=0.1355 | val_acc=0.8448 | val_f1=0.8453 | time/epoch=248.98s\n",
      "[imdb][r=16] Training completed! best_val_acc=0.8448, avg_time/epoch=251.93s, converge_epoch=1, trainable_params=25773314, trainable_ratio=37.7453%\n",
      "[imdb][r=16] Final test accuracy: 0.8424, test_f1=0.8483\n",
      "\n",
      "Result Summary Table:\n",
      "\n",
      "| Rank | Trainable Params / Total | Ratio | Val F1 | Val Acc | Test F1 | Test Acc | Sparsity (<1e−3) | Train Time (s) |\n",
      "| ---- | ------------------------ | ----- | ------ | ------- | ------- | -------- | ----------------- | -------------- |\n",
      "| 1 | 24,777,986 / 67.3M | 36.82% | 0.8475 | 0.8460 | 0.8526 | 0.8472 | 1.77% | 3565.19 |\n",
      "| 2 | 24,612,098 / 67.1M | 36.67% | 0.8513 | 0.8492 | 0.8523 | 0.8460 | 1.75% | 3328.82 |\n",
      "| 3 | 25,109,762 / 67.6M | 37.13% | 0.8434 | 0.8412 | 0.8507 | 0.8448 | 1.80% | 3285.02 |\n",
      "| 4 | 25,773,314 / 68.3M | 37.75% | 0.8469 | 0.8448 | 0.8483 | 0.8424 | 1.88% | 2519.27 |\n",
      "\n",
      "\n",
      "Summary over ranks:\n",
      "r=2: val_acc=0.8492, test_acc=0.8460, avg_time/epoch=332.88s, converge_epoch=1, trainable=24612098 (36.6683%)\n",
      "r=4: val_acc=0.8460, test_acc=0.8472, avg_time/epoch=356.52s, converge_epoch=1, trainable=24777986 (36.8244%)\n",
      "r=8: val_acc=0.8412, test_acc=0.8448, avg_time/epoch=328.50s, converge_epoch=1, trainable=25109762 (37.1344%)\n",
      "r=16: val_acc=0.8448, test_acc=0.8424, avg_time/epoch=251.93s, converge_epoch=1, trainable=25773314 (37.7453%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Training HiRA on IMDB with different ranks\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "imdb_results = []\n",
    "for r in [2, 4, 8, 16]:\n",
    "    print(\"\\n\" + \"-\" * 30)\n",
    "    print(f\"HiRA with rank r={r}\")\n",
    "    print(\"-\" * 30)\n",
    "    res = train_hira_model(\n",
    "        dataset_name=\"imdb\",\n",
    "        model_name=\"distilbert-base-uncased\",\n",
    "        r=r,\n",
    "        lora_alpha=32,\n",
    "        num_epochs=30,        \n",
    "        batch_size=32,\n",
    "        learning_rate=5e-4,\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=100,\n",
    "        logging_steps=100,\n",
    "        max_length=256,\n",
    "        early_stop_patience=3,\n",
    "        output_dir=\"./results_hira_imdb\",\n",
    "        resume_from_checkpoint=False,\n",
    "    )\n",
    "    imdb_results.append(res)\n",
    "\n",
    "# Generate and save summary table\n",
    "generate_summary_table(imdb_results, save_prefix=\"HiRA_IMDB\")\n",
    "\n",
    "print(\"\\nSummary over ranks:\")\n",
    "for res in imdb_results:\n",
    "    print(\n",
    "        f\"Rank={res['rank']}, \"\n",
    "        f\"Test Acc={res['final_test_accuracy']:.4f}, \"\n",
    "        f\"Test F1={res['final_test_f1']:.4f}, \"\n",
    "        f\"Val Acc={res['final_val_accuracy']:.4f}, \"\n",
    "        f\"Val F1={res['final_val_f1']:.4f}, \"\n",
    "        f\"Best Val F1={res['best_val_f1']:.4f}, \"\n",
    "        f\"Best F1 Epoch={res['best_f1_epoch']}, \"\n",
    "        f\"Trainable Params={res['trainable_parameters']:,}, \"\n",
    "        f\"Trainable %={res['trainable_percentage']:.2f}%, \"\n",
    "        f\"Total Time (s)={res['total_training_time']:.2f}, \"\n",
    "        f\"Avg Epoch (s)={res['average_epoch_time']:.2f}, \"\n",
    "        f\"Early Stopped={'Yes' if res['early_stopped'] else 'No'}, \"\n",
    "        f\"Peak GPU (MB)={res['peak_gpu_memory_mb']:.2f}, \"\n",
    "        f\"Sparsity (<1e-3)={res['sparsity']*100:.2f}%\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece685",
   "language": "python",
   "name": "ece685"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
